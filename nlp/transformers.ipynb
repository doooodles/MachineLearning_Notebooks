{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transformers.ipynb","provenance":[],"collapsed_sections":["swDUGQDm7dfe","SmfNEG-_1j0r"],"mount_file_id":"1dAycfA3ldhHktD80zKUNXalR0QuSCadC","authorship_tag":"ABX9TyML7lHJO6R47ZXtQY3BuaWC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"swDUGQDm7dfe"},"source":["# Transformers\n","\n","Paper: [Attention is all you need](https://arxiv.org/abs/1706.03762)\n","\n","Resources:\n","- [The Illustrated Transformer\n","](https://jalammar.github.io/illustrated-transformer/)\n","- [Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)\n","- [TF Docs: Transformer model for language understanding\n","](https://www.tensorflow.org/text/tutorials/transformer)\n","\n","#### Summary\n","- Network based only on attention, without recurrence or convolutions.\n","- Addresses long sequence dependence problem of recurrent models with single encoder hidden state.\n","- Position information is included separately \n","\n","### Approach\n","\n","- Until done:\n","    1. Read the paper\n","    2. Try to implement until stuck\n","    3. Check resources\n","    4. Go to 1.\n","The end product will look a lot like the TF example, *but* I'll learn a lot along the way.\n","\n","### Results\n","- Tried both Portugese to English from the TF docs and Russian to English.\n","- The Russian to English did not perform as well given the time allocated for training and may need additional hyperparameter tuning.\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tims457/ml_notebooks/blob/main/nlp/transformers.ipynb)\n"]},{"cell_type":"code","metadata":{"id":"CGY6wp3dAJOq"},"source":["import tensorflow as tf\n","import numpy as np\n","import tensorflow_datasets as tfds\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Zg0LYfqACrO"},"source":["# Attention model\n","\n","### Notation\n","- $Q$ = Query\n","- $K$ = Key, dimension $d_k$ = 64\n","- $V$ = Value, dimension $d_v$ = 64\n","- $n$ = input sequence length\n","- $m$ = output sequence length\n","- $d_\\text{model}$ = model dimension = 512\n","- $d_{ff}$ = inner layer dimension = 2048\n","- $h$ = heads\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Yt2vmmu7Ntjy"},"source":["## Attention\n","\n","### Basics\n","- Deals with problem of relationships between elements of a long sequence experienced by recurrent models.\n","- Pass all hidden states (all encoder output) to decoder.\n","- Decoder scores each of the encoder hidden states, applies a softmax to the score, then multiplies the score times the hidden state from the encoder. This increases the value of states that scored higher.\n","- Rather than having a single hidden state from a recurrent sequence, the decoder has *all* the hidden states and a score (or attention) value for each of them to weight their importance.\n","- Self-attention means the network is learning to associate the relationships between input elements. \n","\n","<img src=\"https://www.researchgate.net/publication/333078019/figure/fig1/AS:758304078839808@1557805189409/left-Scaled-Dot-Product-Attention-right-Multi-Head-Attention.png\" height=300 />"]},{"cell_type":"markdown","metadata":{"id":"N9EJUz9cK5fq"},"source":["## Multi-head attention\n","- Query, Key, Value (Q,K,V) for each of the encoder input vector created by the embedding.\n","- Attention value is the softmax of Query x Key scaled by the dimension $d_k$ then multiplied by Value\n","\n","$$\\text{Attention(Q,K,V)} = \\text{softmax}_k(\\frac{QK^T}{\\sqrt{d_k}})V$$\n","\n","- Multiple heads - number of attention layers running in parallel\n","- By starting with multiple heads (8 in this case) the encoder and decoder are really multiple encoders and decoders operating in parallel. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"19f35FemNUHx"},"source":[""]},{"cell_type":"code","metadata":{"id":"YdGIapvC0VNx"},"source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","# Attention\n","# sec 3.2.1\n","def scaled_dot_product_attention(q, k, v, mask):\n","    # get dimensions of the input, cast from tensor to float\n","    d_k = tf.cast(tf.shape(k)[-1], tf.float32)\n","    \n","    # compute queries x keys and scale by dimension\n","    attention_logits = tf.matmul(q, k, transpose_b=True)\n","    \n","    scaled_attention_logits = attention_logits / tf.math.sqrt(d_k)\n","    # print(f\"scaled attention shape {scaled_attention_logits.shape}\")\n","\n","    # apply decoder mask\n","    if mask is not None:\n","        scaled_attention_logits += (mask * -1e9)\n","\n","    # normalize all scores\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n","    # print(f\"attention shape {attention_weights.shape}\")\n","\n","    # times value\n","    output = tf.matmul(attention_weights, v)\n","    # print(f\"output shape {output.shape}\")\n","\n","    return output, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fq0feSF1aa-o","executionInfo":{"status":"ok","timestamp":1624123270577,"user_tz":360,"elapsed":63,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"e676b2d6-cfd4-4eb8-ba2e-d9ee1e5d1ae8"},"source":["def print_out(q, k, v):\n","    temp_out, temp_attn = scaled_dot_product_attention(q, k, v, None)\n","    print('Attention weights are:')\n","    print(np.round(temp_attn, decimals=2))\n","    print('Output is:')\n","    print(np.round(temp_out, decimals=2))\n","\n","temp_k = tf.constant([[10, 0, 0],\n","                      [0, 10, 0],\n","                      [0, 0, 10],\n","                      [0, 0, 10]], dtype=tf.float32)  # (4, 3)\n","\n","temp_v = tf.constant([[1, 0],\n","                      [10, 0],\n","                      [100, 5],\n","                      [1000, 6]], dtype=tf.float32)  # (4, 2)\n","\n","\n","# The dot product attention is selecting the key that aligns with the \n","# query and then returning the associated value.\n","temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n","print_out(temp_q, temp_k, temp_v)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Attention weights are:\n","[[0. 1. 0. 0.]]\n","Output is:\n","[[10.  0.]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B1fsCrjh02cu"},"source":["Use the `scaled_dot_product_attention` layer to get a handle on how the model is selecting query-key pairs and computing their value.\n"]},{"cell_type":"code","metadata":{"id":"fcjJuOdxAHt7"},"source":["# sec 3.2.2\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        assert self.d_model % self.num_heads == 0 \n","\n","        self.depth = self.d_model  // num_heads\n","\n","        self.wq = layers.Dense(d_model)\n","        self.wk = layers.Dense(d_model)\n","        self.wv = layers.Dense(d_model)\n","\n","        self.dense = layers.Dense(d_model)\n","\n","    def split_heads(self, x, batch_size):\n","        \"\"\"\n","        The inputs need to be reshaped in order to be fed into the attention portion.\n","        The model dimension d_k get split into heads x depth.\n","        Then transposed to (batch_size, num_heads, seq_len, depth)\n","\n","        \"\"\"\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    # forward computation\n","    def call(self, v, k, q, mask):\n","        batch_size = tf.shape(q)[0]\n","\n","        q = self.wq(q) # (batch_size, seq_len, d_model)\n","        k = self.wk(k)\n","        v = self.wv(v)\n","\n","        q = self.split_heads(q, batch_size) # (batch_size, num_heads, seq_len_q, depth)\n","        k = self.split_heads(k, batch_size)\n","        v = self.split_heads(v, batch_size)\n","\n","        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n","        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n","        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n","\n","        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n","\n","        concat_attention = tf.reshape(scaled_attention,\n","                                    (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n","\n","        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n","\n","        return output, attention_weights\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ZXWw8OQrT2T","executionInfo":{"status":"ok","timestamp":1624123270579,"user_tz":360,"elapsed":61,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"806beebd-073b-493c-cb10-f502967fa32c"},"source":["tf.random.set_seed(42)\n","mha = MultiHeadAttention(512, 8)\n","\n","x = tf.ones((1,60, 512))\n","out, attn = mha(x,k=x,q=x, mask=None)\n","out.shape, attn.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"txzzj49L_30r"},"source":["# Data\n","- Used English-German and English-French dataset. 4.5 million and 36 million sentences respectively\n","- 37000 word English-German vocab\n","- 32000 word English-French vocab\n","- Instead let's use the TF dataset for Russian to English"]},{"cell_type":"code","metadata":{"id":"xcFqTEr83YFW"},"source":["examples, metadata = tfds.load('ted_hrlr_translate/ru_to_en', with_info=True,\n","                               as_supervised=True)\n","train_examples, val_examples = examples['train'], examples['validation']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zkFVV1l956It","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624123270915,"user_tz":360,"elapsed":19,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"9c3251d9-7515-4921-f32b-acf0fd8f3ec7"},"source":["#print  examples\n","for ru, en in train_examples.take(1):\n","  print(\"Russian: \", ru.numpy().decode('utf-8'))\n","  print(\"English:   \", en.numpy().decode('utf-8'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Russian:  к : успех , перемены возможны только с оружием в руках .\n","English:    c : success , the change is only coming through the barrel of the gun .\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7M6umRAu6e9t"},"source":["### Tokenization\n","- There's no tokenizer for the `ted hrlr` Russian to English set that I can find so I have to make one.\n","- The Google docs example for attention said they used a sub-word version built with Bert.\n","- I'll just use the example here https://www.tensorflow.org/text/guide/subwords_tokenizer"]},{"cell_type":"code","metadata":{"id":"TioATfFL8tdX"},"source":["!pip install -q -U tensorflow-text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WFL54Yfg614k"},"source":["\n","import tensorflow_text as text\n","from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab\n","\n","train_en = train_examples.map(lambda ru, en: en)\n","train_ru = train_examples.map(lambda ru, en: ru)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fjtfi7DkPM09"},"source":["This section will generate the English and Russain vocabulary, but it takes a long time so use the included `txt` files."]},{"cell_type":"code","metadata":{"id":"wFxzKMJi8xbD"},"source":["bert_tokenizer_params=dict(lower_case=True)\n","reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n","\n","\n","# bert_vocab_args = dict(\n","#     # The target vocabulary size\n","#     vocab_size = 8000,\n","#     # Reserved tokens that must be included in the vocabulary\n","#     reserved_tokens=reserved_tokens,\n","#     # Arguments for `text.BertTokenizer`\n","#     bert_tokenizer_params=bert_tokenizer_params,\n","#     # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n","#     learn_params={},\n","# )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"plzF-nFw9Bps"},"source":["# %%time\n","# en_vocab = bert_vocab.bert_vocab_from_dataset(\n","#     train_en.batch(1000).prefetch(2),\n","#     **bert_vocab_args\n","# )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t2Hkjven9CSD"},"source":["# print(en_vocab[:10])\n","# print(en_vocab[100:110])\n","# print(en_vocab[1000:1010])\n","# print(en_vocab[-10:])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QDzCJsx-9CeJ"},"source":["# %%time\n","# ru_vocab = bert_vocab.bert_vocab_from_dataset(\n","#     train_ru.batch(1000).prefetch(2),\n","#     **bert_vocab_args\n","# )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NobcBT1P9CmQ"},"source":["# print(ru_vocab[:10])\n","# print(ru_vocab[100:110])\n","# print(ru_vocab[1000:1010])\n","# print(ru_vocab[-10:])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jSajpI4T9CuF"},"source":["# def write_vocab_file(filepath, vocab):\n","#   with open(filepath, 'w') as f:\n","#     for token in vocab:\n","#       print(token, file=f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gYVqjS_b9C1J"},"source":["# write_vocab_file('en_vocab.txt', en_vocab)\n","# write_vocab_file('ru_vocab.txt', ru_vocab)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n0pWFxlt9DDS"},"source":["# copying this module from the TF docs.\n","\n","import pathlib\n","import re\n","\n","START = tf.argmax(tf.constant(reserved_tokens) == \"[START]\")\n","END = tf.argmax(tf.constant(reserved_tokens) == \"[END]\")\n","\n","def cleanup_text(reserved_tokens, token_txt):\n","  # Drop the reserved tokens, except for \"[UNK]\".\n","  bad_tokens = [re.escape(tok) for tok in reserved_tokens if tok != \"[UNK]\"]\n","  bad_token_re = \"|\".join(bad_tokens)\n","\n","  bad_cells = tf.strings.regex_full_match(token_txt, bad_token_re)\n","  result = tf.ragged.boolean_mask(token_txt, ~bad_cells)\n","\n","  # Join them into strings.\n","  result = tf.strings.reduce_join(result, separator=' ', axis=-1)\n","\n","  return result\n","\n","def add_start_end(ragged):\n","  count = ragged.bounding_shape()[0]\n","  starts = tf.fill([count,1], START)\n","  ends = tf.fill([count,1], END)\n","  return tf.concat([starts, ragged, ends], axis=1)\n","\n","class CustomTokenizer(tf.Module):\n","  def __init__(self, reserved_tokens, vocab_path):\n","    self.tokenizer = text.BertTokenizer(vocab_path, lower_case=True)\n","    self._reserved_tokens = reserved_tokens\n","    self._vocab_path = tf.saved_model.Asset(vocab_path)\n","\n","    vocab = pathlib.Path(vocab_path).read_text().splitlines()\n","    self.vocab = tf.Variable(vocab)\n","\n","    ## Create the signatures for export:   \n","\n","    # Include a tokenize signature for a batch of strings. \n","    self.tokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None], dtype=tf.string))\n","\n","    # Include `detokenize` and `lookup` signatures for:\n","    #   * `Tensors` with shapes [tokens] and [batch, tokens]\n","    #   * `RaggedTensors` with shape [batch, tokens]\n","    self.detokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int64))\n","    self.detokenize.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int64))\n","\n","    self.lookup.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int64))\n","    self.lookup.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int64))\n","\n","    # These `get_*` methods take no arguments\n","    self.get_vocab_size.get_concrete_function()\n","    self.get_vocab_path.get_concrete_function()\n","    self.get_reserved_tokens.get_concrete_function()\n","\n","  @tf.function\n","  def tokenize(self, strings):\n","    enc = self.tokenizer.tokenize(strings)\n","    # Merge the `word` and `word-piece` axes.\n","    enc = enc.merge_dims(-2,-1)\n","    enc = add_start_end(enc)\n","    return enc\n","\n","  @tf.function\n","  def detokenize(self, tokenized):\n","    words = self.tokenizer.detokenize(tokenized)\n","    return cleanup_text(self._reserved_tokens, words)\n","\n","  @tf.function\n","  def lookup(self, token_ids):\n","    return tf.gather(self.vocab, token_ids)\n","\n","  @tf.function\n","  def get_vocab_size(self):\n","    return tf.shape(self.vocab)[0]\n","\n","  @tf.function\n","  def get_vocab_path(self):\n","    return self._vocab_path\n","\n","  @tf.function\n","  def get_reserved_tokens(self):\n","    return tf.constant(self._reserved_tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GubNU_HK_dX7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624123276943,"user_tz":360,"elapsed":3271,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"5440e25f-fba1-4d6a-8e89-34f6f2909705"},"source":["tokenizers = tf.Module()\n","tokenizers.ru = CustomTokenizer(reserved_tokens, 'ru_vocab.txt')\n","tokenizers.en = CustomTokenizer(reserved_tokens, 'en_vocab.txt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Q_bxYzmM_il8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624123278894,"user_tz":360,"elapsed":1959,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"3138d17d-4572-4901-8621-d15b14b1feca"},"source":["model_name = 'ted_hrlr_translate_ru_en_converter'\n","tf.saved_model.save(tokenizers, model_name);"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Assets written to: ted_hrlr_translate_ru_en_converter/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: ted_hrlr_translate_ru_en_converter/assets\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"cmLu95UP_oLK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624123280146,"user_tz":360,"elapsed":1256,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"7bfb0cb5-1199-4609-a175-99c0480a9b72"},"source":["reloaded_tokenizers = tf.saved_model.load(model_name)\n","reloaded_tokenizers.en.get_vocab_size().numpy()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7796"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"AN7GpSbX_rhe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624123280931,"user_tz":360,"elapsed":789,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"b2627f89-dd28-4788-f83a-ac1448e8d831"},"source":["tokens = reloaded_tokenizers.en.tokenize(['Hello TensorFlow!'])\n","print(tokens.numpy())\n","\n","round_trip = reloaded_tokenizers.en.detokenize(tokens)\n","print(round_trip.numpy()[0].decode('utf-8'))\n","\n","print(tokenizers.en.lookup(tokens))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[   2 3372 2214  691  952 2669    4    3]]\n","hello tensorflow !\n","<tf.RaggedTensor [[b'[START]', b'hello', b'tens', b'##or', b'##f', b'##low', b'!', b'[END]']]>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"icVKXWT4ymXS"},"source":["Make the pipeline"]},{"cell_type":"code","metadata":{"id":"Dm7Eby5PyjWZ"},"source":["def tokenize_pairs(ru, en):\n","    ru = tokenizers.ru.tokenize(ru)\n","    # Convert from ragged to dense, padding with zeros.\n","    ru = ru.to_tensor()\n","\n","    en = tokenizers.en.tokenize(en)\n","    # Convert from ragged to dense, padding with zeros.\n","    en = en.to_tensor()\n","    return ru, en"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3PzlFybPyrRD"},"source":["BUFFER_SIZE = 20000\n","BATCH_SIZE = 32 # reduced for memory"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"40Y0Y2qOyrzw"},"source":["def make_batches(ds):\n","  return (\n","      ds\n","      .cache()\n","      .shuffle(BUFFER_SIZE)\n","      .batch(BATCH_SIZE)\n","      .map(tokenize_pairs, num_parallel_calls=tf.data.AUTOTUNE)\n","      .prefetch(tf.data.AUTOTUNE))\n","\n","\n","train_batches = make_batches(train_examples)\n","val_batches = make_batches(val_examples)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XRZUv6RPzklZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624123283112,"user_tz":360,"elapsed":1508,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"dbfbdebb-5022-4da7-8c0e-ff108fb7315f"},"source":["list(train_batches.take(2).as_numpy_iterator())"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(array([[   2,   70, 3322, ...,    0,    0,    0],\n","         [   2, 1017,  148, ...,    0,    0,    0],\n","         [   2,  107,  181, ...,    0,    0,    0],\n","         ...,\n","         [   2,  469,   88, ...,    0,    0,    0],\n","         [   2,   79,  368, ...,    0,    0,    0],\n","         [   2,   10,  678, ...,    0,    0,    0]]),\n","  array([[   2,   38,   38, ...,    0,    0,    0],\n","         [   2,   85,  108, ...,    0,    0,    0],\n","         [   2,   47, 6750, ...,    0,    0,    0],\n","         ...,\n","         [   2,  102,   84, ...,    0,    0,    0],\n","         [   2,   85,  108, ...,    0,    0,    0],\n","         [   2,   10,  365, ...,    0,    0,    0]])),\n"," (array([[   2,   86, 2857, ...,    0,    0,    0],\n","         [   2,  163,   14, ...,    0,    0,    0],\n","         [   2,  333,  131, ...,  548,   16,    3],\n","         ...,\n","         [   2,   40,   40, ...,    0,    0,    0],\n","         [   2,  471,  231, ...,    0,    0,    0],\n","         [   2,  435,   14, ...,    0,    0,    0]]),\n","  array([[   2, 3164,   89, ...,    0,    0,    0],\n","         [   2,   89,   94, ...,    0,    0,    0],\n","         [   2,   90,    9, ..., 1061,   16,    3],\n","         ...,\n","         [   2,   38,   38, ...,    0,    0,    0],\n","         [   2,  108,   99, ...,    0,    0,    0],\n","         [   2,   92,  138, ...,    0,    0,    0]]))]"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"GQlcI-Y91k3P"},"source":["## Position encoding\n","\n","We ditched the recurrent structure due to the long gradient problem, but the position of words in the sequence is still valuable.\n","\n","The embedding groups words by meaning, and adding the positional encoding adds absolute and relative position information.\n","\n","$$ PE_{(pos, 2i)}=sin(pos/10000^{2i/d_{model}})$$\n","$$ PE_{(pos, 2i+1)}=cos(pos/10000^{2i/d_{model}})$$"]},{"cell_type":"code","metadata":{"id":"QMNqzpIF1NBx"},"source":["def get_angles(pos, i , d_model):\n","    angle_rates = 1 / np.power(10000, (2*(i//2)) / np.float32(d_model))\n","    return pos * angle_rates\n","\n","def positional_encoding(position, d_model):\n","    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n","                            np.arange(d_model)[np.newaxis,:],\n","                            d_model)\n","    # sin to even i\n","    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","\n","    # cos to odd indices 2i+1\n","    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","\n","    pos_encoding = angle_rads[np.newaxis, ...]\n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":463},"id":"84r-xeHW3IH_","executionInfo":{"status":"ok","timestamp":1624126543012,"user_tz":360,"elapsed":17,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"1e2bdf5b-22ba-44b8-935e-c2298d71f84a"},"source":["n, d = 25, 512\n","pos_encoding = positional_encoding(n, d)\n","print(pos_encoding.shape)\n","pos_encoding = pos_encoding[0]\n","\n","# Juggle the dimensions for the plot\n","pos_encoding = tf.reshape(pos_encoding, (n, d//2, 2))\n","pos_encoding = tf.transpose(pos_encoding, (2, 1, 0))\n","pos_encoding = tf.reshape(pos_encoding, (d, n))\n","\n","import matplotlib.pyplot as plt\n","plt.figure(figsize=(10,7))\n","plt.pcolormesh(pos_encoding[:20,:], cmap='RdBu')\n","plt.ylabel('Depth')\n","plt.xlabel('Position')\n","plt.colorbar()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1, 25, 512)\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x504 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"PPn5VkRy2ZOv"},"source":["## Masking\n","\n","Two types of masking are required. One is for the tokenized inputs which are padding with zeros. This is the padding mask. The other is to mask other tokens in the sequence that the model is trying to learn. This is the look ahead mask."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVOkOKn178UL","executionInfo":{"status":"ok","timestamp":1623885428727,"user_tz":360,"elapsed":39,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"6813c207-4bbf-44f4-c223-ce731706ccfc"},"source":["def create_padding_mask(seq):\n","    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","\n","    # adding dimensions for attention logits compabitility\n","    return seq[:, tf.newaxis, tf.newaxis, :] #(batch_size, 1, 1, seq_len)\n","\n","x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n","create_padding_mask(x)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n","array([[[[0., 0., 1., 1., 0.]]],\n","\n","\n","       [[[0., 0., 0., 1., 1.]]],\n","\n","\n","       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UP5HctVp9Um3","executionInfo":{"status":"ok","timestamp":1623885428728,"user_tz":360,"elapsed":30,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"e1e59428-4211-41d4-f88b-7a11287ce1ef"},"source":["def create_look_ahead_mask(size):\n","    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n","    return mask  # (seq_len, seq_len)\n","\n","x = tf.random.uniform((1, 3))\n","temp = create_look_ahead_mask(x.shape[1])\n","temp"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n","array([[0., 1., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 0.]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8LhbGTM4-SA1","executionInfo":{"status":"ok","timestamp":1623885428729,"user_tz":360,"elapsed":23,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"f4a27ed0-e33a-4732-fb16-66d798026e04"},"source":["a = tf.ones((3,3))\n","tf.linalg.band_part(a, 0, 0)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n","array([[1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"SmfNEG-_1j0r"},"source":["## Embedding\n","- Learned embeddings convert tokens to vectors of dimension $d_\\text{model}$"]},{"cell_type":"markdown","metadata":{"id":"EwkWYTQ1A0jg"},"source":["# Model"]},{"cell_type":"markdown","metadata":{"id":"BRRLenCxtfMw"},"source":["## Encoder\n","- 6 layers\n","- 2 sub-layers per layer\n","    - Embedd\n","    - Position encoding\n","    - Multi-head self attention\n","    - FC Feed-forward\n","    - Residual connections around each sub-layer\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"LJBow0-_1RiP"},"source":["# The encoder and decoder also contain a feed forward section with two dense\n","# layers and relu activation between\n","def point_wise_feed_forward_network(d_model, d_ff):\n","    return tf.keras.Sequential([layers.Dense(d_ff, activation='relu'),\n","                                layers.Dense(d_model)])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_QfqTCVrj9FX"},"source":["class EncoderLayer(layers.Layer):\n","    def __init__(self, d_model, num_heads, d_ff, dropout_rate=0.1):\n","        super(EncoderLayer, self).__init__()\n","\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = point_wise_feed_forward_network(d_model, d_ff)\n","\n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = layers.Dropout(dropout_rate)\n","        self.dropout2 = layers.Dropout(dropout_rate)\n","\n","    def call(self, x, training, mask):\n","        attn_out, _ = self.mha(x, x, x, mask) # (batch_size, input_seq_len, d_model)\n","        attn_out = self.dropout1(attn_out, training=training)\n","        out1 = self.layernorm1(x + attn_out)\n","\n","        ff_out = self.ffn(out1)\n","        ff_out = self.dropout2(ff_out, training=training)\n","        out2 = self.layernorm2(out1 + ff_out) # (batch_size, input_seq_len, d_model)\n","\n","        return out2\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DgJvMyUtLAdu","executionInfo":{"status":"ok","timestamp":1623885428889,"user_tz":360,"elapsed":11,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"d86c322f-4159-4e58-faad-f73ed0ea105e"},"source":["tf.random.set_seed(42)\n","sample_encoder_layer = EncoderLayer(512, 8, 2048)\n","\n","sample_encoder_layer_output = sample_encoder_layer(\n","    tf.random.uniform((64, 43, 512)), False, None)\n","\n","sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([64, 43, 512])"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"vDuyHtLXj9AH"},"source":["class Encoder(layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads, d_ff, input_vocab_size,\n","                 maximum_position_encoding, dropout_rate=0.1):\n","        super(Encoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.embedding = layers.Embedding(input_vocab_size, d_model)\n","        self.pos_encoding = positional_encoding(maximum_position_encoding,\n","                                                self.d_model)\n","        \n","        self.enc_layers = [EncoderLayer(d_model, num_heads, d_ff, dropout_rate)\n","                            for i in range(num_layers)]\n","        self.dropout = layers.Dropout(dropout_rate)\n","\n","    def call(self, x, training, mask):\n","        \n","        seq_len = tf.shape(x)[1]\n","        \n","        # prep inputs with embedding and pos encoding\n","        x = self.embedding(x) # (batch_size, input_seq_len, d_model)\n","        # embedding layer weights are multiplied by sqrt(d_model) sec 3.4\n","        x *= tf.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","        \n","\n","        x = self.dropout(x, training=training)\n","        # now go through all the encoding layers\n","        for i in range(self.num_layers):\n","            x = self.enc_layers[i](x, training, mask)\n","\n","        return x # (batch_size, input_seq_len, d_model)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7P_7olzrj85P","executionInfo":{"status":"ok","timestamp":1623885429033,"user_tz":360,"elapsed":152,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"8814891d-7df9-4b76-e1ac-c689be49ef1d"},"source":["tf.random.set_seed(42)\n","sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8,\n","                         d_ff=2048, input_vocab_size=8500,\n","                         maximum_position_encoding=10000)\n","temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n","sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n","\n","print(sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(64, 62, 512)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-F8ZPl9w0g02"},"source":["## Decoder\n","- 6 layers\n","- Same 2 layers as Encoder but with a third layer between\n","    - Middle layer performs multi-head attention on output from Encoder\n","    - Same residual connections"]},{"cell_type":"code","metadata":{"id":"tuuFQ_GHmXGL"},"source":["class DecoderLayer(layers.Layer):\n","    def __init__(self, d_model, num_heads, d_ff, dropout_rate=0.1):\n","        super(DecoderLayer, self).__init__()\n","\n","        self.mmha = MultiHeadAttention(d_model, num_heads)\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = point_wise_feed_forward_network(d_model, d_ff)\n","\n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = layers.Dropout(dropout_rate)\n","        self.dropout2 = layers.Dropout(dropout_rate)\n","        self.dropout3 = layers.Dropout(dropout_rate)\n","\n","    def call(self, x, encoder_out, training, look_ahead_mask, padding_mask):\n","        mask_attn_out, attn_weights_block1 = self.mmha(x, x, x, look_ahead_mask) # (batch_size, target_seq_len, d_model)\n","        mask_attn_out = self.dropout1(mask_attn_out, training=training)\n","        out1 = self.layernorm1(mask_attn_out + x)\n","\n","        attn_out, attn_weights_block2 = self.mha(encoder_out, encoder_out, \n","                                                 out1, padding_mask)\n","        attn_out = self.dropout2(attn_out, training=training)\n","        out2 = self.layernorm2(attn_out + out1)\n","\n","        ff_out = self.ffn(out2)\n","        ff_out = self.dropout3(ff_out, training=training)\n","        out3 = self.layernorm3(ff_out + out2) # (batch_size, target_seq_len, d_model)\n","\n","        return out3, attn_weights_block1, attn_weights_block2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F4dTu2D5mXNJ"},"source":["class Decoder(layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads, d_ff, target_vocab_size,\n","                 maximum_position_encoding, dropout_rate=0.1):\n","        super(Decoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.embedding = layers.Embedding(target_vocab_size, d_model)\n","        self.pos_encoding = positional_encoding(maximum_position_encoding,\n","                                                d_model)\n","        \n","        self.dec_layers = [DecoderLayer(d_model, num_heads, d_ff, dropout_rate)\n","                            for i in range(num_layers)]\n","        self.dropout = layers.Dropout(dropout_rate)\n","\n","    def call(self, x, enc_output, training,  \n","             look_ahead_mask, padding_mask):\n","        \n","        seq_len = tf.shape(x)[1]\n","        attn_weights = {}\n","        \n","        # prep inputs with embedding and pos encoding\n","        x = self.embedding(x) # (batch_size, input_seq_len, d_model)\n","        # embedding layer weights are multiplied by sqrt(d_model) sec 3.4\n","        x *= tf.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","\n","        x = self.dropout(x, training=training)\n","\n","        # now go through all the encoding layers\n","        for i in range(self.num_layers):\n","            x, block1, block2 = self.dec_layers[i](x, enc_output, training, \n","                                                   look_ahead_mask,padding_mask)\n","            attn_weights[f'decoder_layer{i+1}_block1'] = block1\n","            attn_weights[f'decoder_layer{i+1}_block2'] = block2\n","\n","        return x, attn_weights # (batch_size, input_seq_len, d_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yMbNCs5fmXUJ","executionInfo":{"status":"ok","timestamp":1623885429218,"user_tz":360,"elapsed":192,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"189ea5c3-123e-4a90-cfcd-66cb825345fc"},"source":["tf.random.set_seed(42)\n","sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8,\n","                         d_ff=2048, target_vocab_size=8000,\n","                         maximum_position_encoding=5000)\n","temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n","\n","output, attn = sample_decoder(temp_input,\n","                              enc_output=sample_encoder_output,\n","                              training=False,\n","                              look_ahead_mask=None,\n","                              padding_mask=None)\n","\n","output.shape, attn['decoder_layer2_block2'].shape\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"ZsDVHDjNmXiN"},"source":["# Transformer\n","Finally construct the full transformer."]},{"cell_type":"code","metadata":{"id":"36gPZPqGeCFH"},"source":["class Transformer(tf.keras.Model):\n","    def __init__(self, num_layers, d_model, num_heads, d_ff, input_vocab_size,\n","                 target_vocab_size, pe_input, pe_target, dropout_rate=0.1):\n","        super(Transformer, self).__init__()\n","    \n","        self.encoder = Encoder(num_layers, d_model, num_heads, d_ff, \n","                            input_vocab_size, pe_input, dropout_rate)\n","        \n","        self.decoder = Decoder(num_layers, d_model, num_heads, d_ff, \n","                            input_vocab_size, pe_target, dropout_rate)\n","        \n","        self.final_layer = layers.Dense(target_vocab_size)\n","\n","    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask,\n","             dec_padding_mask):\n","        # (batch_size, inp_seq_len, d_model)\n","        enc_output = self.encoder(inp, training, enc_padding_mask)\n","\n","        dec_output, attention_weights  = self.decoder(tar, enc_output, training, \n","                                                look_ahead_mask,dec_padding_mask)\n","        \n","        # (batch_size, tar_seq_len, target_vocab_size)\n","        final_output = self.final_layer(dec_output)\n","\n","        return final_output, attention_weights\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_vXPBqt8eCVZ","executionInfo":{"status":"ok","timestamp":1623885429873,"user_tz":360,"elapsed":529,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"c4473199-46d9-4868-d7c5-ee02681e1594"},"source":["tf.random.set_seed(42)\n","sample_transformer = Transformer(\n","    num_layers=2, d_model=512, num_heads=8, d_ff=2048,\n","    input_vocab_size=8500, target_vocab_size=8000,\n","    pe_input=10000, pe_target=6000)\n","\n","temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n","temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n","\n","fn_out, _ = sample_transformer(temp_input, temp_target, training=False,\n","                               enc_padding_mask=None,\n","                               look_ahead_mask=None,\n","                               dec_padding_mask=None)\n","\n","fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([64, 36, 8000])"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"Pj-VpGSNADa9"},"source":["# Train\n","\n"]},{"cell_type":"markdown","metadata":{"id":"OYmgpx8_eCj8"},"source":["Hyperparameters"]},{"cell_type":"code","metadata":{"id":"9iFP1Ebef5gc"},"source":["num_layers = 4\n","d_model = 128\n","d_ff = 512\n","num_heads = 8\n","dropout_rate = 0.1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-U9XOspyAF1s"},"source":["## Optimizer\n","- Adam $\\beta_1$ = 0.9, $\\beta_2$ = 0.98 and $\\epsilon$ = $10^{-9}$\n","- Custom learning rate scheduler\n","    - increase learning rate linearly for `warm_up_steps` then decrease it proportionally according to the step number."]},{"cell_type":"code","metadata":{"id":"XMNOUryoeCrs"},"source":["# learning rate scheduler, sec 5.3\n","class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(self, d_model, warmup_steps = 4000):\n","        super(CustomSchedule, self).__init__()\n","        \n","        self.d_model = tf.cast(d_model, dtype=tf.float32)\n","        self.warmup_steps = warmup_steps\n","\n","    def __call__(self, step):\n","        lr = tf.math.rsqrt(self.d_model) * tf.math.minimum(tf.math.rsqrt(step), \n","                                                           step*self.warmup_steps**-1.5)\n","\n","        return lr\n","learning_rate = CustomSchedule(d_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"id":"lurX5yLAW9aJ","executionInfo":{"status":"ok","timestamp":1623885430027,"user_tz":360,"elapsed":160,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"60537911-f5d9-405b-973b-430ca984f400"},"source":["temp_learning_rate_schedule = CustomSchedule(d_model)\n","\n","plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n","plt.ylabel(\"Learning Rate\")\n","plt.xlabel(\"Train Step\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 0, 'Train Step')"]},"metadata":{"tags":[]},"execution_count":45},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"0Hl_BmT-hP51"},"source":["optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n","                                     epsilon=1e-9)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_OQBEWzusNUG"},"source":["## Loss\n","The target sequences are padded so a mask needs to be applied to accurately calculate the loss.\n"]},{"cell_type":"code","metadata":{"id":"CLAGjViusrWy"},"source":["loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z2x5harEteEE"},"source":["def loss_function(real, pred):\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    loss_ = loss_object(real, pred)\n","\n","    mask = tf.cast(mask, dtype=loss_.dtype)\n","    loss_ *= mask\n","\n","    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n","\n","def accuracy_function(real, pred):\n","    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n","\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    accuracies = tf.math.logical_and(mask, accuracies)\n","\n","    accuracies = tf.cast(accuracies, dtype=tf.float32)\n","    mask = tf.cast(mask, dtype=tf.float32)\n","    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"njZBWdyNuZVy"},"source":["train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"becb-Io_ujkQ"},"source":["## Training and checkpoints\n","The targets for each input are the inputs shifted by one. The true output is always passed to the model at the next timestep regardless of what the model predicted at the current timestep. So the model at timestep $t$ is not hindered by the model's performance at $t-1$."]},{"cell_type":"code","metadata":{"id":"R3GQoY7PVcfr"},"source":["# examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n","#                                as_supervised=True)\n","# train_examples, val_examples = examples['train'], examples['validation']\n","\n","# model_name = \"ted_hrlr_translate_pt_en_converter\"\n","# tf.keras.utils.get_file(\n","#     f\"{model_name}.zip\",\n","#     f\"https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip\",\n","#     cache_dir='.', cache_subdir='', extract=True\n","# )\n","\n","# tokenizers = tf.saved_model.load(model_name)\n","\n","# def tokenize_pairs(pt, en):\n","#     pt = tokenizers.pt.tokenize(pt)\n","#     # Convert from ragged to dense, padding with zeros.\n","#     pt = pt.to_tensor()\n","\n","#     en = tokenizers.en.tokenize(en)\n","#     # Convert from ragged to dense, padding with zeros.\n","#     en = en.to_tensor()\n","#     return pt, en\n","# def make_batches(ds):\n","#   return (\n","#       ds\n","#       .cache()\n","#     #   .shuffle(BUFFER_SIZE)\n","#       .batch(BATCH_SIZE)\n","#       .map(tokenize_pairs, num_parallel_calls=tf.data.AUTOTUNE)\n","#       .prefetch(tf.data.AUTOTUNE))\n","\n","# train_batches = make_batches(train_examples)\n","# val_batches = make_batches(val_examples)\n","\n","# tokenizers.ru = tokenizers.pt\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ufgL2_q7aYt-","executionInfo":{"status":"ok","timestamp":1623885430153,"user_tz":360,"elapsed":9,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"c8ecf7cb-e958-41a6-8aa9-03758d16b4b2"},"source":["for pt_examples, en_examples in train_examples.batch(3).take(1):\n","    for pt in pt_examples.numpy():\n","        print(pt.decode('utf-8'))\n","\n","    print()\n","\n","    for en in en_examples.numpy():\n","        print(en.decode('utf-8'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["к : успех , перемены возможны только с оружием в руках .\n","документация и методика практического обучения также доступна и выпущена creative commons .\n","( видео ) диди пиклз : сейчас четыре часа утра .\n","\n","c : success , the change is only coming through the barrel of the gun .\n","the documentation and the hands-on teaching methodology is also open-source and released as the creative commons .\n","( video ) didi pickles : it 's four o'clock in the morning .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lo-SwvM6agyU","executionInfo":{"status":"ok","timestamp":1623885430731,"user_tz":360,"elapsed":585,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"997795fe-366c-4709-f7ac-aafa0c3c4fc7"},"source":["encoded = tokenizers.en.tokenize(en_examples)\n","\n","for row in encoded.to_list():\n","    print(row)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2, 41, 28, 1103, 14, 84, 243, 93, 200, 389, 218, 84, 6405, 87, 84, 2473, 16, 3]\n","[2, 84, 3914, 464, 85, 84, 702, 15, 104, 1495, 2346, 2024, 93, 187, 435, 15, 942, 85, 2533, 111, 84, 1068, 5725, 16, 3]\n","[2, 10, 400, 11, 168, 379, 1026, 1125, 28, 90, 9, 57, 316, 53, 9, 2501, 89, 84, 813, 16, 3]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ddJk7htDalET","executionInfo":{"status":"ok","timestamp":1623885431070,"user_tz":360,"elapsed":343,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"4bc2fe8e-e3c2-45b7-823f-7f3422c50f76"},"source":["round_trip = tokenizers.en.detokenize(encoded)\n","for line in round_trip.numpy():\n","    print(line.decode('utf-8'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["c : success , the change is only coming through the barrel of the gun .\n","the documentation and the hands - on teaching methodology is also open - source and released as the creative commons .\n","( video ) didi pickles : it ' s four o ' clock in the morning .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bfGkqWV5ao5T","executionInfo":{"status":"ok","timestamp":1623885431071,"user_tz":360,"elapsed":12,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"08133cdf-4464-400f-c014-479c536354ce"},"source":["tokens = tokenizers.en.lookup(encoded)\n","tokens"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.RaggedTensor [[b'[START]', b'c', b':', b'success', b',', b'the', b'change', b'is', b'only', b'coming', b'through', b'the', b'barrel', b'of', b'the', b'gun', b'.', b'[END]'], [b'[START]', b'the', b'document', b'##ation', b'and', b'the', b'hands', b'-', b'on', b'teaching', b'method', b'##ology', b'is', b'also', b'open', b'-', b'source', b'and', b'released', b'as', b'the', b'creative', b'commons', b'.', b'[END]'], [b'[START]', b'(', b'video', b')', b'did', b'##i', b'pick', b'##les', b':', b'it', b\"'\", b's', b'four', b'o', b\"'\", b'clock', b'in', b'the', b'morning', b'.', b'[END]']]>"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"id":"SnEY-bjiuluu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623885686874,"user_tz":360,"elapsed":306,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"8b717241-cb22-46df-d565-4b18e631f6f3"},"source":["# create the transformer\n","tf.random.set_seed(42)\n","\n","transformer = Transformer(num_layers = num_layers, \n","                          d_model = d_model,\n","                          num_heads = num_heads, \n","                          d_ff = d_ff,\n","                          input_vocab_size=tokenizers.ru.get_vocab_size(),\n","                          target_vocab_size = tokenizers.en.get_vocab_size(),\n","                          pe_input=1000,\n","                          pe_target=1000,\n","                          dropout_rate=dropout_rate)\n","\n","temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n","temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n","\n","fn_out, _ = sample_transformer(temp_input, temp_target, training=False,\n","                               enc_padding_mask=None,\n","                               look_ahead_mask=None,\n","                               dec_padding_mask=None)\n","\n","fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([64, 36, 8000])"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"code","metadata":{"id":"hlNWQ1Xeulrz"},"source":["def create_masks(inp, tar):\n","    # Encoder padding mask\n","    enc_padding_mask = create_padding_mask(inp)\n","\n","    # Used in the 2nd attention block in the decoder.\n","    # This padding mask is used to mask the encoder outputs.\n","    dec_padding_mask = create_padding_mask(inp)\n","\n","    # Used in the 1st attention block in the decoder.\n","    # It is used to pad and mask future tokens in the input received by\n","    # the decoder.\n","    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n","    dec_target_padding_mask = create_padding_mask(tar)\n","    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n","\n","    return enc_padding_mask, combined_mask, dec_padding_mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bk5xd30iC06e"},"source":["!rm -rf ./checkpoints/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gDFDcugCulpY"},"source":["checkpoint_path = \"./checkpoints/train\"\n","\n","# Keyword arguments are set as attributes of this object, \n","# and are saved with the checkpoint. Values must be trackable objects.\n","ckpt = tf.train.Checkpoint(transformer=transformer,\n","                           optimizer=optimizer)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n","\n","# if a checkpoint exists, restore the latest checkpoint.\n","if ckpt_manager.latest_checkpoint:\n","    ckpt.restore(ckpt_manager.latest_checkpoint)\n","    print('Latest checkpoint restored!!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_jy8jAkfulm8"},"source":["# The @tf.function trace-compiles train_step into a TF graph for faster\n","# execution. The function specializes to the precise shape of the argument\n","# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n","# batch sizes (the last batch is smaller), use input_signature to specify\n","# more generic shapes.\n","\n","train_step_signature = [\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","]\n","\n","\n","@tf.function(input_signature=train_step_signature)\n","def train_step(inp, tar):\n","    tar_inp = tar[:, :-1]\n","    tar_real = tar[:, 1:]\n","\n","    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n","\n","    with tf.GradientTape() as tape:\n","        predictions, _ = transformer(inp, tar_inp,\n","                                        True,\n","                                        enc_padding_mask,\n","                                        combined_mask,\n","                                        dec_padding_mask)\n","        # print(inp)\n","        # print(tar_inp)\n","        # print(predictions)\n","        \n","        loss = loss_function(tar_real, predictions)\n","\n","        # if batch % 200 ==0:\n","        #     ru_sent = tokenizers.ru.detokenize(inp)\n","        #     ru_sent = ru_sent.numpy()[0].decode('utf-8')\n","        #     print(ru_sent)\n","\n","        #     en_sent = tokenizers.en.detokenize(tar)\n","        #     print(en_sent.numpy()[0].decode('utf-8'))\n","\n","        #     text, _, _ = evaluate(ru_sent, max_length=40)\n","        #     print(text)\n","        #     print()\n","\n","    \n","    gradients = tape.gradient(loss, transformer.trainable_variables)\n","    # print(gradients[0])\n","    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n","\n","    train_loss(loss)\n","    train_accuracy(accuracy_function(tar_real, predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Yq74gDPVulkM","executionInfo":{"status":"error","timestamp":1623897525181,"user_tz":360,"elapsed":11838037,"user":{"displayName":"Tim Sullivan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDOmSXGsobJcA9UOtHRwU-sWjSZffSAqqvuM2IHQ=s64","userId":"11783081476684672772"}},"outputId":"fc0868d1-2ab0-4c86-8c14-ea3aa72c5698"},"source":["import time\n","\n","EPOCHS = 20\n","step = 0\n","for epoch in range(EPOCHS):\n","    start = time.time()\n","\n","    train_loss.reset_states()\n","    train_accuracy.reset_states()\n","\n","    # inp -> russian, tar -> english\n","    for (batch, (inp, tar)) in enumerate(train_batches):\n","        train_step(inp, tar)\n","\n","        if batch % 50 == 0:\n","            print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n","\n","    ckpt_save_path = ckpt_manager.save()\n","    \n","    print(f'Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}')\n","    print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n","    print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["так вот , этот подход делает возможным такие вещи как — прочесывание всех доступных данных из самых разных источников для определения ключевых закономерностеи и сведения их воедино . то , что невозможно было сделать раньше .\n","now this approach makes possible things like combing through all available data from very different sources , identifying key relationships and putting them in one place , something that ' s been nearly impossible to do before .\n","tf.Tensor(\n","[[   2 1759 4613 4613 4613 4613 4613 4613 4613 4613 4613 4613 4613 4613\n","  4613 4613 4613 4613 4613 4613 4613 4613 4613 4613 4613 4613 4613 4613\n","  4613 4613 4613 4613 4613 4613 4613 4613 4613 4613 4613 4613 4613]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b'loss perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived perceived', shape=(), dtype=string)\n","\n","Epoch 1 Batch 0 Loss 8.9408 Accuracy 0.0013\n","Epoch 1 Batch 50 Loss 8.8433 Accuracy 0.0166\n","Epoch 1 Batch 100 Loss 8.7305 Accuracy 0.0293\n","Epoch 1 Batch 150 Loss 8.6003 Accuracy 0.0348\n","хорошо , понятно , что всегда наидутся люди которые скажут , что та или иная картина была неправильно прибрана . итак мы можем провести с вами небольшои эксперимент .\n","ok , i mean , i can see there are always people that like reacting that one or another picture has n ' t been properly tidied up . so we can make a short test with you .\n","tf.Tensor([[2 3]], shape=(1, 2), dtype=int64)\n","tf.Tensor(b'', shape=(), dtype=string)\n","\n","Epoch 1 Batch 200 Loss 8.4423 Accuracy 0.0371\n","Epoch 1 Batch 250 Loss 8.2604 Accuracy 0.0381\n","Epoch 1 Batch 300 Loss 8.0640 Accuracy 0.0389\n","Epoch 1 Batch 350 Loss 7.8648 Accuracy 0.0407\n","прошли годы , и многие приключения , о которых я фантазировала ребенком — путешествия и прокладывание пути сквозь миры , отличающиеся от моего — стали реальными , благодаря моеи работе фотографа - документалиста .\n","years have passed , but many of the adventures i fantasized about as a child — traveling and weaving my way between worlds other than my own — have become realities through my work as a documentary photographer .\n","tf.Tensor(\n","[[ 2 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n","  14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b', , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,', shape=(), dtype=string)\n","\n","Epoch 1 Batch 400 Loss 7.6770 Accuracy 0.0480\n","Epoch 1 Batch 450 Loss 7.5166 Accuracy 0.0558\n","Epoch 1 Batch 500 Loss 7.3738 Accuracy 0.0633\n","Epoch 1 Batch 550 Loss 7.2470 Accuracy 0.0713\n","они в списке мировых долгожителеи .\n","they ' re the world ' s oldest living thing .\n","tf.Tensor([[ 2 85 85 84 14 85 84 14 85 84 16  3]], shape=(1, 12), dtype=int64)\n","tf.Tensor(b'and and the , and the , and the .', shape=(), dtype=string)\n","\n","Epoch 1 Batch 600 Loss 7.1321 Accuracy 0.0792\n","Epoch 1 Batch 650 Loss 7.0207 Accuracy 0.0869\n","Epoch 1 Batch 700 Loss 6.9209 Accuracy 0.0934\n","Epoch 1 Batch 750 Loss 6.8281 Accuracy 0.0995\n","это феодализм : один владелец , много рабочих .\n","this is feudalism : one owner , many workers .\n","tf.Tensor(\n","[[  2  85  47   9  57  84  39 157  14  85  84 157  14  85  84 157  14  85\n","   84 157  14  85  84  39  39 157  16   3]], shape=(1, 28), dtype=int64)\n","tf.Tensor(b\"and i ' s the a world , and the world , and the world , and the world , and the a a world .\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 800 Loss 6.7403 Accuracy 0.1053\n","Epoch 1 Batch 850 Loss 6.6603 Accuracy 0.1107\n","Epoch 1 Batch 900 Loss 6.5861 Accuracy 0.1158\n","Epoch 1 Batch 950 Loss 6.5169 Accuracy 0.1205\n","у меня от этого столько энергии , что мне нужно наити для нее выход .\n","this gives me so much energy , and i ' ve got to have an outlet for all that energy .\n","tf.Tensor(\n","[[  2  47   9  57  39 157  14  85  47   9  57  39 157  14  85  47   9  57\n","   39 157  16   3]], shape=(1, 22), dtype=int64)\n","WARNING:tensorflow:5 out of the last 27 calls to <function CustomTokenizer.lookup at 0x7f9fc81a1290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 27 calls to <function CustomTokenizer.lookup at 0x7f9fc81a1290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["tf.Tensor(b\"i ' s a world , and i ' s a world , and i ' s a world .\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 1000 Loss 6.4512 Accuracy 0.1250\n","Epoch 1 Batch 1050 Loss 6.3912 Accuracy 0.1291\n","Epoch 1 Batch 1100 Loss 6.3349 Accuracy 0.1332\n","Epoch 1 Batch 1150 Loss 6.2813 Accuracy 0.1371\n","и он усугубляет положение , сказав : « вообще - то нигде » .\n","` ` and he makes it worse by saying , ` ` actually , i do n ' t have a place . ' ' ' '\n","tf.Tensor(\n","[[ 2 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n","  38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b'` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` ` `', shape=(), dtype=string)\n","\n","Epoch 1 Batch 1200 Loss 6.2298 Accuracy 0.1410\n","Epoch 1 Batch 1250 Loss 6.1840 Accuracy 0.1445\n","Epoch 1 Batch 1300 Loss 6.1397 Accuracy 0.1477\n","Epoch 1 Batch 1350 Loss 6.0965 Accuracy 0.1509\n","с тех пор я решил , что не вправе утешать умирающих при помощи лжи .\n","from that moment forward , i decided it was not my place to comfort the dying with my lies .\n","tf.Tensor(\n","[[  2  47   9  51  39 210  87  84 157  14  47   9  51 139  86 110  39 210\n","   87  84 157  16   3]], shape=(1, 23), dtype=int64)\n","WARNING:tensorflow:6 out of the last 29 calls to <function CustomTokenizer.lookup at 0x7f9fc81a1290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 29 calls to <function CustomTokenizer.lookup at 0x7f9fc81a1290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["tf.Tensor(b\"i ' m a lot of the world , i ' m going to be a lot of the world .\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 1400 Loss 6.0563 Accuracy 0.1539\n","Epoch 1 Batch 1450 Loss 6.0176 Accuracy 0.1569\n","Epoch 1 Batch 1500 Loss 5.9833 Accuracy 0.1594\n","Epoch 1 Batch 1550 Loss 5.9491 Accuracy 0.1620\n","взгляните на это , это не основано на статистике .\n","you take a look at this , this is not based on statistics .\n","tf.Tensor([[  2  95  91   9 117 112 112  39 131 131 131 131  16   3]], shape=(1, 14), dtype=int64)\n","tf.Tensor(b\"so we ' re not not a very very very very .\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 1600 Loss 5.9165 Accuracy 0.1643\n","Epoch 1 Batch 1650 Loss 5.8846 Accuracy 0.1668\n","Epoch 1 Batch 1700 Loss 5.8552 Accuracy 0.1689\n","Epoch 1 Batch 1750 Loss 5.8253 Accuracy 0.1712\n","археология дает нам возможность изучать древние цивилизации и увидеть в чем они преуспели , а в чем потерпели неудачу .\n","because archaeology gives us an opportunity to study past civilizations , and see where they succeeded and where they failed .\n","tf.Tensor(\n","[[  2  85  91   9 117 139  86 110  39 210  87  84 157  14  85  91   9 117\n","  139  86 110 264  86 110 264  86 110 264  86 110 264  86 110 264  86 110\n","  264  86 110 264  86]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"and we ' re going to be a lot of the world , and we ' re going to be able to be able to be able to be able to be able to be able to be able to\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 1800 Loss 5.7975 Accuracy 0.1732\n","Epoch 1 Batch 1850 Loss 5.7722 Accuracy 0.1750\n","Epoch 1 Batch 1900 Loss 5.7477 Accuracy 0.1768\n","Epoch 1 Batch 1950 Loss 5.7229 Accuracy 0.1787\n","и когда он останавливается напротив дома , он останавливается напротив вашего дома .\n","and when he stops in front of a house , he stops in front of your house .\n","tf.Tensor(\n","[[  2  85 127  97  39 192 290  87  84 157  14  85 127  97  39 192 290  87\n","   84 157  16   3]], shape=(1, 22), dtype=int64)\n","tf.Tensor(b'and he was a little bit of the world , and he was a little bit of the world .', shape=(), dtype=string)\n","\n","Epoch 1 Batch 2000 Loss 5.6992 Accuracy 0.1805\n","Epoch 1 Batch 2050 Loss 5.6755 Accuracy 0.1824\n","Epoch 1 Batch 2100 Loss 5.6542 Accuracy 0.1839\n","Epoch 1 Batch 2150 Loss 5.6333 Accuracy 0.1856\n","потрясающая презентация карен армстронг напомнила мне о том , что религия в правильном понимании этого слова - это не убеждения , а поведение .\n","and i was reminded by karen armstrong ' s fantastic presentation that religion really properly understood is not about belief , but about behavior .\n","tf.Tensor(\n","[[  2  85  47   9  51 139  86 105  52   9  58 101  86 110  39 192 290  87\n","   84 157  14  85  47   9  51 139  86 110  39 192 290  87  84 157  16   3]], shape=(1, 36), dtype=int64)\n","tf.Tensor(b\"and i ' m going to do n ' t have to be a little bit of the world , and i ' m going to be a little bit of the world .\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 2200 Loss 5.6123 Accuracy 0.1872\n","Epoch 1 Batch 2250 Loss 5.5917 Accuracy 0.1888\n","Epoch 1 Batch 2300 Loss 5.5723 Accuracy 0.1903\n","Epoch 1 Batch 2350 Loss 5.5538 Accuracy 0.1917\n","есть очень много суперстимулов для сексуальности .\n","there ' s lots of supernormal stimuli for sexiness .\n","tf.Tensor([[  2  90   9  57  39 210  87 118  16   3]], shape=(1, 10), dtype=int64)\n","tf.Tensor(b\"it ' s a lot of people .\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 2400 Loss 5.5356 Accuracy 0.1931\n","Epoch 1 Batch 2450 Loss 5.5185 Accuracy 0.1944\n","Epoch 1 Batch 2500 Loss 5.5013 Accuracy 0.1957\n","Epoch 1 Batch 2550 Loss 5.4839 Accuracy 0.1971\n","поэтому даже если опухоль расположена не на поверхности , вы все равно можете видеть ее .\n","so even if the tumor is not right on the surface , you ' ll still be able to see it .\n","tf.Tensor([[  2  92 107 145  14  92   9 117 112  39 210  87  84 157  16   3]], shape=(1, 16), dtype=int64)\n","tf.Tensor(b\"you can see , you ' re not a lot of the world .\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 2600 Loss 5.4683 Accuracy 0.1983\n","Epoch 1 Batch 2650 Loss 5.4524 Accuracy 0.1995\n","Epoch 1 Batch 2700 Loss 5.4372 Accuracy 0.2006\n","Epoch 1 Batch 2750 Loss 5.4229 Accuracy 0.2016\n","но пока мы думали , что все шло хорошо , все снова было просто фантастическим , мы наткнулись еще на одну проблему . мужчины стали видеть явные изменения в своих женах .\n","but then while we were thinking everything was going well , once again everything was fantastic , we found our next setback : a lot of men started seeing the visible changes in their wife .\n","tf.Tensor(\n","[[  2  85  91   9 117 139  86 105  52   9  58 101  39 210  87 118  14  85\n","   91   9 117 139  86 105  94  14  85  91   9 117 139  86 105  94  14  85\n","   91   9 117 139  86]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"and we ' re going to do n ' t have a lot of people , and we ' re going to do this , and we ' re going to do this , and we ' re going to\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 2800 Loss 5.4085 Accuracy 0.2028\n","Epoch 1 Batch 2850 Loss 5.3942 Accuracy 0.2039\n","Epoch 1 Batch 2900 Loss 5.3800 Accuracy 0.2049\n","Epoch 1 Batch 2950 Loss 5.3659 Accuracy 0.2060\n","я так рада быть здесь .\n","i am so excited to be here .\n","tf.Tensor([[  2  47   9  51 139  86 110  39 192 290  16   3]], shape=(1, 12), dtype=int64)\n","tf.Tensor(b\"i ' m going to be a little bit .\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 3000 Loss 5.3524 Accuracy 0.2071\n","Epoch 1 Batch 3050 Loss 5.3399 Accuracy 0.2080\n","Epoch 1 Batch 3100 Loss 5.3270 Accuracy 0.2090\n","Epoch 1 Batch 3150 Loss 5.3141 Accuracy 0.2100\n","мы провели огромное исследование и опрашивали людеи с разными транспортными службами , пытаясь выяснить , кто же изменил [ мнение ] и куда он поехал ?\n","well , so we did this huge interview survey with lots of travel services , and tried to figure out who changed , and where did they go ?\n","tf.Tensor(\n","[[  2  95  14 103   9  57 139  86 105  14  85  91   9 117 139  86 155  86\n","  110 264  86 155  39 210  87  84 157  14  85 152  91   9 117 139  86 155\n","   86 110 264  86 155]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"so , what ' s going to do , and we ' re going to get to be able to get a lot of the world , and then we ' re going to get to be able to get\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 3200 Loss 5.3017 Accuracy 0.2110\n","Epoch 1 Batch 3250 Loss 5.2904 Accuracy 0.2118\n","Epoch 1 Batch 3300 Loss 5.2787 Accuracy 0.2127\n","Epoch 1 Batch 3350 Loss 5.2673 Accuracy 0.2135\n","в свете этого , поэзия деиствительно исключительно хорошо справляется с определенными вещами .\n","that said , poetry does seem to be especially good at certain things .\n","tf.Tensor([[  2  85  90   9  57  39 131 263 193  88   9  57  39 131 263  16   3]], shape=(1, 17), dtype=int64)\n","tf.Tensor(b\"and it ' s a very important thing that ' s a very important .\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 3400 Loss 5.2563 Accuracy 0.2143\n","Epoch 1 Batch 3450 Loss 5.2451 Accuracy 0.2151\n","Epoch 1 Batch 3500 Loss 5.2346 Accuracy 0.2160\n","Epoch 1 Batch 3550 Loss 5.2243 Accuracy 0.2167\n","( смех ) следующая история называется « коллекция хаверписа » . ничем не примечательныи склад , которыи на мгновение можно увидеть с трассы северного направления автомагистрали прикушко , используется как временное хранилище для коллекции хаверписа европеиских сухофруктов .\n","` ` ( laughter ) the next story is called ` ` ' ' the haverpiece collection ' ' ' ' a nondescript warehouse , visible for a moment from the northbound lanes of the prykushko expressway , serves as the temporary resting place for the haverpiece collection of european dried fruit . ' '\n","tf.Tensor(\n","[[  2  10 171  11  85  84 181 193  93  88  84 181 193  93  88  84 181 193\n","   93  88  84 181 193  93  88  84 181 193  93  88  84 181 193  93  88  84\n","  181 193  93  88  84]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b'( laughter ) and the first thing is that the first thing is that the first thing is that the first thing is that the first thing is that the first thing is that the first thing is that the', shape=(), dtype=string)\n","\n","Epoch 1 Batch 3600 Loss 5.2145 Accuracy 0.2174\n","Epoch 1 Batch 3650 Loss 5.2046 Accuracy 0.2181\n","Epoch 1 Batch 3700 Loss 5.1950 Accuracy 0.2189\n","Epoch 1 Batch 3750 Loss 5.1857 Accuracy 0.2196\n","что же мы видим ?\n","what do we find ?\n","tf.Tensor([[  2 135 107  91 105  31   3]], shape=(1, 7), dtype=int64)\n","tf.Tensor(b'how can we do ?', shape=(), dtype=string)\n","\n","Epoch 1 Batch 3800 Loss 5.1761 Accuracy 0.2203\n","Epoch 1 Batch 3850 Loss 5.1671 Accuracy 0.2210\n","Epoch 1 Batch 3900 Loss 5.1578 Accuracy 0.2217\n","Epoch 1 Batch 3950 Loss 5.1488 Accuracy 0.2224\n","которои продвигался огромными скачками . к 2030 - му году вычислительные возможности на единицу цены увеличатся в 1 миллион раз .\n","there have been huge leaps . there will be a million - fold improvement in what you can get for the same price in computing by 2030 .\n","tf.Tensor(\n","[[  2  84 181 193  93  88  84 181  87  84 181  87  84 181  87  84 494 450\n","   93  88  84 181  87  84  59  16  57  16  57  16  57  16  57  16  57  16\n","    3]], shape=(1, 37), dtype=int64)\n","tf.Tensor(b'the first thing is that the first of the first of the first of the united states is that the first of the u . s . s . s . s . s .', shape=(), dtype=string)\n","\n","Epoch 1 Batch 4000 Loss 5.1406 Accuracy 0.2230\n","Epoch 1 Batch 4050 Loss 5.1315 Accuracy 0.2236\n","Epoch 1 Batch 4100 Loss 5.1235 Accuracy 0.2242\n","Epoch 1 Batch 4150 Loss 5.1146 Accuracy 0.2249\n","измерения мы проводили с помощью шкалы , придуманнои другими психологами , в которои участников опрашивали , какова вероятность вызвать у них отвращение в различных приведенных ситуациях .\n","the way that we measured this was by a scale that was constructed by some other psychologists that simply asked people across a wide variety of situations how likely they are to feel disgust .\n","tf.Tensor(\n","[[  2  91   9 117 139  86 110 264  86 110 264  86 110 264  86 110 264  86\n","  110 264  86 110 264  86 110 264  86 110 264  86 110 264  86 110 264  86\n","  110 264  86 110 264]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"we ' re going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 4200 Loss 5.1060 Accuracy 0.2256\n","Epoch 1 Batch 4250 Loss 5.0976 Accuracy 0.2262\n","Epoch 1 Batch 4300 Loss 5.0898 Accuracy 0.2268\n","Epoch 1 Batch 4350 Loss 5.0820 Accuracy 0.2273\n","тем не менее , он запустил самое прогрессивное в мире преобразование страны .\n","but he nevertheless pulled off one of the most progressive transformations any country has ever seen .\n","tf.Tensor(\n","[[  2  90   9  57  39 210  87  84 157  14  85  90   9  57 112  39 210  87\n","   84 157  16   3]], shape=(1, 22), dtype=int64)\n","tf.Tensor(b\"it ' s a lot of the world , and it ' s not a lot of the world .\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 4400 Loss 5.0738 Accuracy 0.2279\n","Epoch 1 Batch 4450 Loss 5.0661 Accuracy 0.2285\n","Epoch 1 Batch 4500 Loss 5.0584 Accuracy 0.2291\n","Epoch 1 Batch 4550 Loss 5.0513 Accuracy 0.2296\n","эти фотографии прислали мне посетители .\n","these are some pictures visitors sent to me .\n","tf.Tensor([[  2  47   9  51 385 109 136  16   3]], shape=(1, 9), dtype=int64)\n","tf.Tensor(b\"i ' m talking about them .\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 4600 Loss 5.0436 Accuracy 0.2302\n","Epoch 1 Batch 4650 Loss 5.0361 Accuracy 0.2308\n","Epoch 1 Batch 4700 Loss 5.0287 Accuracy 0.2313\n","Epoch 1 Batch 4750 Loss 5.0213 Accuracy 0.2319\n","лекция сильвии эрл под названием < > обеспечит нас рычагами и возможностью затронуть сердца людеи , у которых почти нет представления о местах , находящихся за пределами их собственного мира обитания . но мы будем надеяться , что их заинтересуют жизненные циклы таких существ как морские черепахи , которые не смогут выжить без открытых мореи .\n","sylvia ' s wish provides us with that leverage , that access to the heart of human beings , you might say , who have rarely seen places beyond their own toes , but are now hopefully going to become interested in the full life - cycle of creatures like these sea turtles , who indeed spend most of their time in the high seas .\n","tf.Tensor(\n","[[  2  91   9 153 194  39 210  87 118 147 101  39 210  87 118 147 101  39\n","  210  87 118 147 101  39 210  87 118 147 101  39 210  87 118 147 101  39\n","  210  87 118  14  85]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"we ' ve got a lot of people who have a lot of people who have a lot of people who have a lot of people who have a lot of people who have a lot of people , and\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 4800 Loss 5.0147 Accuracy 0.2324\n","Epoch 1 Batch 4850 Loss 5.0078 Accuracy 0.2328\n","Epoch 1 Batch 4900 Loss 5.0013 Accuracy 0.2333\n","Epoch 1 Batch 4950 Loss 4.9946 Accuracy 0.2338\n","это много времени .\n","that is a lot of time .\n","tf.Tensor([[  2  90   9  57  39 210  87 156  16   3]], shape=(1, 10), dtype=int64)\n","tf.Tensor(b\"it ' s a lot of time .\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 5000 Loss 4.9876 Accuracy 0.2343\n","Epoch 1 Batch 5050 Loss 4.9807 Accuracy 0.2349\n","Epoch 1 Batch 5100 Loss 4.9740 Accuracy 0.2354\n","Epoch 1 Batch 5150 Loss 4.9676 Accuracy 0.2358\n","как я уже говорил , это были настоящие авантюристы .\n","as i said , they were adventurous people .\n","tf.Tensor(\n","[[  2  85  47   9  51 139  86 241  92  88  47   9  51 139  86 105  94  16\n","    3]], shape=(1, 19), dtype=int64)\n","tf.Tensor(b\"and i ' m going to tell you that i ' m going to do this .\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 5200 Loss 4.9613 Accuracy 0.2363\n","Epoch 1 Batch 5250 Loss 4.9552 Accuracy 0.2368\n","Epoch 1 Batch 5300 Loss 4.9489 Accuracy 0.2372\n","Epoch 1 Batch 5350 Loss 4.9425 Accuracy 0.2377\n","когда мы конструировали первые установки , я месяцами проводил половину своего времени в магазине электроники .\n","i spent half my life at our local hardware store during the months when we built these units originally .\n","tf.Tensor(\n","[[  2  91   9 117 139  86 176 198  86  84 181 228  14  85 152  91   9 117\n","  139  86 176 198  86  84 181 228  16   3]], shape=(1, 28), dtype=int64)\n","tf.Tensor(b\"we ' re going to go back to the first day , and then we ' re going to go back to the first day .\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 5400 Loss 4.9367 Accuracy 0.2381\n","Epoch 1 Batch 5450 Loss 4.9306 Accuracy 0.2386\n","Epoch 1 Batch 5500 Loss 4.9246 Accuracy 0.2391\n","Epoch 1 Batch 5550 Loss 4.9181 Accuracy 0.2396\n","аб : спасибо .\n","ab : thanks .\n","tf.Tensor([[  2 238  92  16   3]], shape=(1, 5), dtype=int64)\n","tf.Tensor(b'thank you .', shape=(), dtype=string)\n","\n","Epoch 1 Batch 5600 Loss 4.9119 Accuracy 0.2401\n","Epoch 1 Batch 5650 Loss 4.9062 Accuracy 0.2405\n","Epoch 1 Batch 5700 Loss 4.9005 Accuracy 0.2409\n","Epoch 1 Batch 5750 Loss 4.8945 Accuracy 0.2414\n","сбои компьютера , испорченныи провод , искрящии конвертор .\n","there was a computer spook , a broken wire , a converter that sparked .\n","tf.Tensor(\n","[[  2  90   9  57  39 210  87  84  54 311 379 646  14  85  90   9  57  39\n","  210  87  84  54 311 236  16   3]], shape=(1, 26), dtype=int64)\n","tf.Tensor(b\"it ' s a lot of the palig , and it ' s a lot of the paly .\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 5800 Loss 4.8889 Accuracy 0.2418\n","Epoch 1 Batch 5850 Loss 4.8837 Accuracy 0.2422\n","Epoch 1 Batch 5900 Loss 4.8778 Accuracy 0.2426\n","Epoch 1 Batch 5950 Loss 4.8723 Accuracy 0.2431\n","« я был бы не против жить в стране с исламским фундаментализмом » .\n","` ` ` ` i would n ' t mind living in a fundamentalist islamic state . ' ' ' '\n","tf.Tensor(\n","[[  2  38  38  47   9 153 173  39 413 745  89  84 157  14  85  47   9  51\n","  139  86 110  39 188 328  16   9   9   9   3]], shape=(1, 29), dtype=int64)\n","tf.Tensor(b\"` ` i ' ve been a young girl in the world , and i ' m going to be a new country . ' ' '\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 6000 Loss 4.8669 Accuracy 0.2435\n","Epoch 1 Batch 6050 Loss 4.8614 Accuracy 0.2439\n","Epoch 1 Batch 6100 Loss 4.8558 Accuracy 0.2444\n","Epoch 1 Batch 6150 Loss 4.8508 Accuracy 0.2448\n","но в процессе нашего анализа мы выяснили , что корень обеих проблем , мы выяснили , что корень обеих проблем , лежит в основах управления .\n","but as we were doing our analysis we realized that there was a common root cause to these two issues that relates , in fact , to the basic pillars of management .\n","tf.Tensor(\n","[[  2 102  91   9 153 173 330 104  84 157  14  85  91   9 153 194  39 210\n","   87 118 147  99 139  86 110 264  86 110 264  86 105  88  16   3]], shape=(1, 34), dtype=int64)\n","tf.Tensor(b\"but we ' ve been working on the world , and we ' ve got a lot of people who are going to be able to be able to do that .\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 6200 Loss 4.8455 Accuracy 0.2452\n","Epoch 1 Batch 6250 Loss 4.8401 Accuracy 0.2456\n","Epoch 1 Batch 6300 Loss 4.8349 Accuracy 0.2460\n","Epoch 1 Batch 6350 Loss 4.8298 Accuracy 0.2464\n","они – лучше всех .\n","singapore is the best one .\n","tf.Tensor([[  2  96   9 117 114 139  86 110 131 263  16   3]], shape=(1, 12), dtype=int64)\n","tf.Tensor(b\"they ' re all going to be very important .\", shape=(), dtype=string)\n","\n","Epoch 1 Batch 6400 Loss 4.8253 Accuracy 0.2468\n","Epoch 1 Batch 6450 Loss 4.8206 Accuracy 0.2472\n","Epoch 1 Batch 6500 Loss 4.8153 Accuracy 0.2476\n","выше нос ! посмотри на меня !\n","hold your head up . look at me .\n","tf.Tensor([[  2 116 571  14  96   9 117 112  16   3]], shape=(1, 10), dtype=int64)\n","tf.Tensor(b\"my friends , they ' re not .\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 0 Loss 4.0656 Accuracy 0.2946\n","Epoch 2 Batch 50 Loss 4.1762 Accuracy 0.2982\n","Epoch 2 Batch 100 Loss 4.1568 Accuracy 0.2990\n","Epoch 2 Batch 150 Loss 4.1723 Accuracy 0.2984\n","загвоздка заключалась в том , как они мне объяснили ситуацию , что создавать интерьеры надо посредством существующих технологии , и нет дополнительных средств для поточного производства .\n","so the problem became — and they set this dilemma to me — that you have to design the interior using only our existing technology , and there ' s no money for tooling or molding .\n","tf.Tensor(\n","[[  2  85  47   9  51 112 139  86 105  90  14  85  47   9  51 112 139  86\n","  110  39 208  87 166  86 105  90  14  85  96   9 117 112  39 208  87 166\n","   86 105  90  14  85]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"and i ' m not going to do it , and i ' m not going to be a kind of way to do it , and they ' re not a kind of way to do it , and\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 200 Loss 4.1554 Accuracy 0.3004\n","Epoch 2 Batch 250 Loss 4.1572 Accuracy 0.3003\n","Epoch 2 Batch 300 Loss 4.1596 Accuracy 0.2998\n","Epoch 2 Batch 350 Loss 4.1583 Accuracy 0.2999\n","напротив , те , кто деиствительно был в отеле , чьи тела деиствительно находились в пространстве отеля , подробно описывали пространственные признаки .\n","in contrast , the people that wrote the reviews that were actually there , their bodies actually entered the physical space , they talked a lot more about spatial information .\n","tf.Tensor(\n","[[   2   85   84  172  193   88   91    9  153  173  264   86  105   93\n","    88   84   41 3502 1198   87   84   41 3502 1198   87   84  368   14\n","    84   41 3502  633   14   84   41 3502  633   14   84   41 3502]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"and the other thing that we ' ve been able to do is that the chack of the chack of the city , the chap , the chap , the cha\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 400 Loss 4.1582 Accuracy 0.2998\n","Epoch 2 Batch 450 Loss 4.1606 Accuracy 0.2996\n","Epoch 2 Batch 500 Loss 4.1600 Accuracy 0.2996\n","Epoch 2 Batch 550 Loss 4.1594 Accuracy 0.2996\n","скажем , что должно случиться , чтобы началась пандемия ? »\n","to say ahh , if this happens then we are going to have a pandemic ?\n","tf.Tensor(\n","[[  2 103  93  84 300  88  93  88  84 300  93  88  84 357  93  84 179  31\n","    3]], shape=(1, 19), dtype=int64)\n","tf.Tensor(b'what is the question that is that the question is that the future is the right ?', shape=(), dtype=string)\n","\n","Epoch 2 Batch 600 Loss 4.1597 Accuracy 0.2996\n","Epoch 2 Batch 650 Loss 4.1559 Accuracy 0.3002\n","Epoch 2 Batch 700 Loss 4.1535 Accuracy 0.3004\n","Epoch 2 Batch 750 Loss 4.1494 Accuracy 0.3010\n","оно конечно . гармония - нет .\n","it is finite ; harmony is infinite .\n","tf.Tensor([[  2  90   9  57 112  39 192 290  16   3]], shape=(1, 10), dtype=int64)\n","tf.Tensor(b\"it ' s not a little bit .\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 800 Loss 4.1488 Accuracy 0.3013\n","Epoch 2 Batch 850 Loss 4.1471 Accuracy 0.3016\n","Epoch 2 Batch 900 Loss 4.1459 Accuracy 0.3016\n","Epoch 2 Batch 950 Loss 4.1461 Accuracy 0.3016\n","женщины участвуют в сборе средств .\n","and women do fundraising .\n","tf.Tensor([[  2  84 296 147 101 173  89  84 328  16   3]], shape=(1, 11), dtype=int64)\n","tf.Tensor(b'the women who have been in the country .', shape=(), dtype=string)\n","\n","Epoch 2 Batch 1000 Loss 4.1437 Accuracy 0.3018\n","Epoch 2 Batch 1050 Loss 4.1436 Accuracy 0.3018\n","Epoch 2 Batch 1100 Loss 4.1428 Accuracy 0.3018\n","Epoch 2 Batch 1150 Loss 4.1408 Accuracy 0.3020\n","почему ? они не доверяют законам . почему они не доверяют законам ?\n","and why not ? they do n ' t trust the law . why do n ' t they trust the law ?\n","tf.Tensor([[  2 213  31 213  31 213  31 213  31 213  31  96  99 112  88  31   3]], shape=(1, 17), dtype=int64)\n","tf.Tensor(b'why ? why ? why ? why ? why ? they are not that ?', shape=(), dtype=string)\n","\n","Epoch 2 Batch 1200 Loss 4.1389 Accuracy 0.3021\n","Epoch 2 Batch 1250 Loss 4.1373 Accuracy 0.3021\n","Epoch 2 Batch 1300 Loss 4.1343 Accuracy 0.3025\n","Epoch 2 Batch 1350 Loss 4.1325 Accuracy 0.3026\n","и вот что мы хотим сделать . представьте , что , читая лекцию , можно одновременно говорить с людьми на их родном языке .\n","so here ' s what we think we want to do : imagine giving a lecture and being able to talk to people in their own native language simultaneously .\n","tf.Tensor(\n","[[  2  95  14  91   9 117 139  86 105  88  14  85  91   9 117 139  86 105\n","   88  14  85  91   9 117 139  86 110 264  86 105  88  14  85  91   9 117\n","  139  86 110 264  86]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"so , we ' re going to do that , and we ' re going to do that , and we ' re going to be able to do that , and we ' re going to be able to\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 1400 Loss 4.1304 Accuracy 0.3029\n","Epoch 2 Batch 1450 Loss 4.1299 Accuracy 0.3031\n","Epoch 2 Batch 1500 Loss 4.1291 Accuracy 0.3030\n","Epoch 2 Batch 1550 Loss 4.1249 Accuracy 0.3034\n","большая часть нашего культурного наследия заставляет оглядываться назад , идеализируя прошлое .\n","most of our cultural heritage has tended to look backward , romanticizing the past .\n","tf.Tensor(\n","[[  2  91   9 153 194  39 210  87 118 147 101 173 264  86 105  90  14  85\n","   91   9 153 194  86 110  39 188 166  87  84 538  16   3]], shape=(1, 32), dtype=int64)\n","tf.Tensor(b\"we ' ve got a lot of people who have been able to do it , and we ' ve got to be a new way of the internet .\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 1600 Loss 4.1238 Accuracy 0.3035\n","Epoch 2 Batch 1650 Loss 4.1226 Accuracy 0.3036\n","Epoch 2 Batch 1700 Loss 4.1206 Accuracy 0.3038\n","Epoch 2 Batch 1750 Loss 4.1190 Accuracy 0.3040\n","глядя на это , я просто умираю со смеху , потому что знаю , что этот французскии мохер и все эти старинные немецкие ленты и шерсть я достал еще на мельнице в небраске и носил около 10 лет , а это древние китаиские юбки .\n","and i crack up at this piece , because when i see it i know that ' s french angora and all antique german ribbons and wool that i got in a nebraska mill and carried around for 10 years and then antique chinese skirts .\n","tf.Tensor(\n","[[  2  85  47   9  51 139  86 241  92  88  84 181 156  47   9  51 139  86\n","  145  88  84 181 193  93  88  84 200 193  47   9  51 139  86 105  93  88\n","   84 221 193  93  88]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"and i ' m going to tell you that the first time i ' m going to see that the first thing is that the only thing i ' m going to do is that the same thing is that\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 1800 Loss 4.1176 Accuracy 0.3042\n","Epoch 2 Batch 1850 Loss 4.1165 Accuracy 0.3043\n","Epoch 2 Batch 1900 Loss 4.1148 Accuracy 0.3044\n","Epoch 2 Batch 1950 Loss 4.1137 Accuracy 0.3045\n","с однои стороны , это звучит нелепо .\n","on the one hand , it sounds ridiculous .\n","tf.Tensor([[  2  85  84 200 193  93  88  90   9  57 112  39 192 290  16   3]], shape=(1, 16), dtype=int64)\n","tf.Tensor(b\"and the only thing is that it ' s not a little bit .\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 2000 Loss 4.1111 Accuracy 0.3048\n","Epoch 2 Batch 2050 Loss 4.1100 Accuracy 0.3049\n","Epoch 2 Batch 2100 Loss 4.1083 Accuracy 0.3050\n","Epoch 2 Batch 2150 Loss 4.1066 Accuracy 0.3052\n","это этическая концепция .\n","this is an ethical conception .\n","tf.Tensor([[  2  94  93  84 181 193  16   3]], shape=(1, 8), dtype=int64)\n","tf.Tensor(b'this is the first thing .', shape=(), dtype=string)\n","\n","Epoch 2 Batch 2200 Loss 4.1047 Accuracy 0.3054\n","Epoch 2 Batch 2250 Loss 4.1022 Accuracy 0.3057\n","Epoch 2 Batch 2300 Loss 4.1017 Accuracy 0.3057\n","Epoch 2 Batch 2350 Loss 4.1000 Accuracy 0.3059\n","спасибо за такую реакцию .\n","thank you for that reaction .\n","tf.Tensor([[  2 238  92  16   3]], shape=(1, 5), dtype=int64)\n","tf.Tensor(b'thank you .', shape=(), dtype=string)\n","\n","Epoch 2 Batch 2400 Loss 4.0992 Accuracy 0.3059\n","Epoch 2 Batch 2450 Loss 4.0982 Accuracy 0.3060\n","Epoch 2 Batch 2500 Loss 4.0962 Accuracy 0.3062\n","Epoch 2 Batch 2550 Loss 4.0953 Accuracy 0.3063\n","это говорит о том , что моцарту следовало быть осторожнее при выборе сексуальных партнеров .\n","this suggests that mozart should have bit more careful , perhaps , when choosing his sexual partners .\n","tf.Tensor(\n","[[  2  90   9  57  39 242 193  88   9  57  39 242 193  86 105 106  84 463\n","   87  84 463  16   3]], shape=(1, 23), dtype=int64)\n","tf.Tensor(b\"it ' s a great thing that ' s a great thing to do with the public of the public .\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 2600 Loss 4.0940 Accuracy 0.3064\n","Epoch 2 Batch 2650 Loss 4.0918 Accuracy 0.3067\n","Epoch 2 Batch 2700 Loss 4.0904 Accuracy 0.3068\n","Epoch 2 Batch 2750 Loss 4.0890 Accuracy 0.3069\n","таким образом , мы не знаем , зачем творить , но имеем много причин не делать этого .\n","we do n ' t know why we should be artists , but we have many reasons why we ca n ' t be .\n","tf.Tensor(\n","[[  2  85  91   9 117 112 139  86 110 131 215  14 102  91   9 117 112 126\n","  139  86 110 131 215  16   3]], shape=(1, 25), dtype=int64)\n","tf.Tensor(b\"and we ' re not going to be very good , but we ' re not just going to be very good .\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 2800 Loss 4.0873 Accuracy 0.3070\n","Epoch 2 Batch 2850 Loss 4.0857 Accuracy 0.3072\n","Epoch 2 Batch 2900 Loss 4.0848 Accuracy 0.3073\n","Epoch 2 Batch 2950 Loss 4.0832 Accuracy 0.3075\n","я расскажу вам историю человека на этои фотографии .\n","the guy in the picture here , i ' ll tell you his story .\n","tf.Tensor([[  2  47   9 223 241  92  39 278 109  84 278  87  84 274 115  16   3]], shape=(1, 17), dtype=int64)\n","tf.Tensor(b\"i ' ll tell you a story about the story of the next one .\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 3000 Loss 4.0818 Accuracy 0.3076\n","Epoch 2 Batch 3050 Loss 4.0804 Accuracy 0.3077\n","Epoch 2 Batch 3100 Loss 4.0791 Accuracy 0.3078\n","Epoch 2 Batch 3150 Loss 4.0779 Accuracy 0.3079\n","даваите ненадолго вернемся в 1819 год , в трудное положение команды китобоя эссекс .\n","well let ' s return to the year 1819 for a moment , to the situation facing the crew of the whaleship essex .\n","tf.Tensor(\n","[[  2  85  84 181 193  88  47   9  51 139  86 105  93  88  84 494 450  87\n","   84 494 450  93  88  84 494 450  93  52   9  58 139  86 110  84 181 416\n","  169  16   3]], shape=(1, 39), dtype=int64)\n","tf.Tensor(b\"and the first thing that i ' m going to do is that the united states of the united states is that the united states is n ' t going to be the first 20 years .\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 3200 Loss 4.0767 Accuracy 0.3081\n","Epoch 2 Batch 3250 Loss 4.0754 Accuracy 0.3082\n","Epoch 2 Batch 3300 Loss 4.0742 Accuracy 0.3083\n","Epoch 2 Batch 3350 Loss 4.0732 Accuracy 0.3084\n","представьте себе , сколько - же будет стоить упомянутыи 100 - долларовыи компьютер в 2020 году в качестве инструмента для обучения .\n","now , just imagine what that $ 100 computer will be in 2020 as a tool for education .\n","tf.Tensor(\n","[[  2  95  14 391  84 274 226  14  84 188 685 368  93  86 110 264  86 155\n","   86 110 264  86 155  39 188 166  86 155  39 188 166  86 155  39 188 166\n","   86 155  39 226  16]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b'so , imagine the next year , the new york city is to be able to get to be able to get a new way to get a new way to get a new way to get a year .', shape=(), dtype=string)\n","\n","Epoch 2 Batch 3400 Loss 4.0720 Accuracy 0.3085\n","Epoch 2 Batch 3450 Loss 4.0713 Accuracy 0.3086\n","Epoch 2 Batch 3500 Loss 4.0697 Accuracy 0.3088\n","Epoch 2 Batch 3550 Loss 4.0686 Accuracy 0.3089\n","агентство национальнои безопасности тоже заглядывает .\n","you can see the national security agency likes to come by .\n","tf.Tensor([[  2  84 172 166  88  84 157  93  39 242 292  16   3]], shape=(1, 13), dtype=int64)\n","tf.Tensor(b'the other way that the world is a great place .', shape=(), dtype=string)\n","\n","Epoch 2 Batch 3600 Loss 4.0672 Accuracy 0.3090\n","Epoch 2 Batch 3650 Loss 4.0656 Accuracy 0.3092\n","Epoch 2 Batch 3700 Loss 4.0639 Accuracy 0.3093\n","Epoch 2 Batch 3750 Loss 4.0632 Accuracy 0.3094\n","на нем был установлен windows 98 .\n","and the laptop was running windows 98 .\n","tf.Tensor([[  2  94  93  84 181 226  16   3]], shape=(1, 8), dtype=int64)\n","tf.Tensor(b'this is the first year .', shape=(), dtype=string)\n","\n","Epoch 2 Batch 3800 Loss 4.0617 Accuracy 0.3096\n","Epoch 2 Batch 3850 Loss 4.0607 Accuracy 0.3096\n","Epoch 2 Batch 3900 Loss 4.0593 Accuracy 0.3098\n","Epoch 2 Batch 3950 Loss 4.0586 Accuracy 0.3099\n","они знают , что им следовало бы делать , но они этого не делают .\n","they know what they ' re supposed to be doing , but they ' re not doing it .\n","tf.Tensor(\n","[[  2  96 105  52   9  58 138 103  96 105  14 102  96 105  52   9  58 138\n","  103  96 105  16   3]], shape=(1, 23), dtype=int64)\n","tf.Tensor(b\"they do n ' t know what they do , but they do n ' t know what they do .\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 4000 Loss 4.0575 Accuracy 0.3099\n","Epoch 2 Batch 4050 Loss 4.0562 Accuracy 0.3101\n","Epoch 2 Batch 4100 Loss 4.0548 Accuracy 0.3102\n","Epoch 2 Batch 4150 Loss 4.0540 Accuracy 0.3103\n","и если вы посмотрите , как слои складываются , вы обнаружите , что не имеет значения , как вы складываете сгибы и листы , лист не может проникнуть за сгиб .\n","and if you look at how the layers stack , you ' ll find that no matter how you stack folds and sheets , a sheet can never penetrate a fold .\n","tf.Tensor(\n","[[  2  85 121  92 189 113  84 221 156  14  92   9 153 194  86 145  84 221\n","  193  14  85 121  92   9 117 139  86 110 264  86 155  84 221 193  14  92\n","    9 117 139  86 145]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"and if you look at the same time , you ' ve got to see the same thing , and if you ' re going to be able to get the same thing , you ' re going to see\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 4200 Loss 4.0523 Accuracy 0.3104\n","Epoch 2 Batch 4250 Loss 4.0513 Accuracy 0.3105\n","Epoch 2 Batch 4300 Loss 4.0507 Accuracy 0.3106\n","Epoch 2 Batch 4350 Loss 4.0497 Accuracy 0.3107\n","хотя у них есть диван . если заити на кухню , то для женщины большои разницы между 1 и 10 долларами в день нет .\n","although there is a sofa , if you watch in the kitchen , you can see that the great difference for women does not come between one to 10 dollars .\n","tf.Tensor(\n","[[  2  85 152  14 121  92   9 117 112 139  86 155  39 210  87 344  14  92\n","    9 117 112 139  86 155  39 210  87 344  14  85  92   9 117 139  86 155\n","   39 210  87 344  16]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"and then , if you ' re not going to get a lot of money , you ' re not going to get a lot of money , and you ' re going to get a lot of money .\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 4400 Loss 4.0486 Accuracy 0.3108\n","Epoch 2 Batch 4450 Loss 4.0476 Accuracy 0.3108\n","Epoch 2 Batch 4500 Loss 4.0464 Accuracy 0.3110\n","Epoch 2 Batch 4550 Loss 4.0448 Accuracy 0.3112\n","итак , основы утилитаризма — я уверен , вы с ними как минимум знакомы .\n","so basis of utilitarianism — i ' m sure you ' re familiar at least .\n","tf.Tensor(\n","[[  2  95  14  47   9  51 139  86 110  39 215 193  14  85  47   9  51 139\n","   86 110 264  86 177 479  88  47   9  51 139  86 110  39 215 193  16   3]], shape=(1, 36), dtype=int64)\n","tf.Tensor(b\"so , i ' m going to be a good thing , and i ' m going to be able to make sure that i ' m going to be a good thing .\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 4600 Loss 4.0437 Accuracy 0.3113\n","Epoch 2 Batch 4650 Loss 4.0420 Accuracy 0.3114\n","Epoch 2 Batch 4700 Loss 4.0406 Accuracy 0.3116\n","Epoch 2 Batch 4750 Loss 4.0391 Accuracy 0.3117\n","итак , чтобы подвести итог — в чем урок этого всего ?\n","so just to conclude — what are the take - home messages from this ?\n","tf.Tensor([[  2  95 103 105  92 105  31   3]], shape=(1, 8), dtype=int64)\n","tf.Tensor(b'so what do you do ?', shape=(), dtype=string)\n","\n","Epoch 2 Batch 4800 Loss 4.0379 Accuracy 0.3119\n","Epoch 2 Batch 4850 Loss 4.0369 Accuracy 0.3120\n","Epoch 2 Batch 4900 Loss 4.0361 Accuracy 0.3120\n","Epoch 2 Batch 4950 Loss 4.0352 Accuracy 0.3121\n","представьте : мои первыи год работы учителем естественных наук в школе , я полон энергии .\n","it ' s my first year as a new high school science teacher , and i ' m so eager .\n","tf.Tensor(\n","[[  2  10 211  11  47   9  51 139  86 254 109  84 157   9  57 412  87  84\n","  157   9  57 412 438  87  84 157  16   3]], shape=(1, 28), dtype=int64)\n","tf.Tensor(b\"( applause ) i ' m going to talk about the world ' s health of the world ' s health care of the world .\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 5000 Loss 4.0342 Accuracy 0.3121\n","Epoch 2 Batch 5050 Loss 4.0333 Accuracy 0.3122\n","Epoch 2 Batch 5100 Loss 4.0318 Accuracy 0.3124\n","Epoch 2 Batch 5150 Loss 4.0304 Accuracy 0.3125\n","м . с . : и выяснить . . . а что бы вы выяснили ?\n","ms : and measure . and what would you measure ?\n","tf.Tensor(\n","[[  2 244  28 174  14  92   9 117 139  86 105  88  31  85 152  92   9 117\n","  139  86 176 198  16   3]], shape=(1, 24), dtype=int64)\n","tf.Tensor(b\"ca : well , you ' re going to do that ? and then you ' re going to go back .\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 5200 Loss 4.0296 Accuracy 0.3126\n","Epoch 2 Batch 5250 Loss 4.0285 Accuracy 0.3126\n","Epoch 2 Batch 5300 Loss 4.0271 Accuracy 0.3128\n","Epoch 2 Batch 5350 Loss 4.0264 Accuracy 0.3128\n","сеичас , когда брак — это романтическая договоренность , неверность угрожает нашеи эмоциональнои безопасности .\n","but now that marriage is a romantic arrangement , infidelity threatens our emotional security .\n","tf.Tensor(\n","[[  2  85  84 443  91   9 117 112 385 109  84 197 263 193  88  91   9 117\n","  385 109  93  88  84 197 263 193  91   9 117 139  86 110  89  84 157  16\n","    3]], shape=(1, 37), dtype=int64)\n","tf.Tensor(b\"and the reason we ' re not talking about the most important thing that we ' re talking about is that the most important thing we ' re going to be in the world .\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 5400 Loss 4.0252 Accuracy 0.3129\n","Epoch 2 Batch 5450 Loss 4.0244 Accuracy 0.3129\n","Epoch 2 Batch 5500 Loss 4.0235 Accuracy 0.3130\n","Epoch 2 Batch 5550 Loss 4.0224 Accuracy 0.3131\n","может быть , вообще не надо будет ходить в школу ?\n","could it be that we do n ' t need to go to school at all ?\n","tf.Tensor([[  2 168  52   9  58  92 101  86 110  39 215  31   3]], shape=(1, 13), dtype=int64)\n","tf.Tensor(b\"did n ' t you have to be a good ?\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 5600 Loss 4.0214 Accuracy 0.3132\n","Epoch 2 Batch 5650 Loss 4.0206 Accuracy 0.3133\n","Epoch 2 Batch 5700 Loss 4.0196 Accuracy 0.3134\n","Epoch 2 Batch 5750 Loss 4.0187 Accuracy 0.3134\n","и потом , если вы посмотрите внимательно , вы увидите все мелкие детали .\n","and then if you look carefully , there is all little things .\n","tf.Tensor(\n","[[  2  85 152  92 145  14  92 107 145  14  92 107 145  14  92 107 145  14\n","   92 145  14  92 145  14  92 145  14  92 145  14  92 145  14  92 145  14\n","   92 145  14  92 145]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b'and then you see , you can see , you can see , you can see , you see , you see , you see , you see , you see , you see , you see , you see', shape=(), dtype=string)\n","\n","Epoch 2 Batch 5800 Loss 4.0175 Accuracy 0.3135\n","Epoch 2 Batch 5850 Loss 4.0162 Accuracy 0.3136\n","Epoch 2 Batch 5900 Loss 4.0149 Accuracy 0.3137\n","Epoch 2 Batch 5950 Loss 4.0140 Accuracy 0.3138\n","используи свои опыт , черпаи из него .\n","use what you know . draw from it .\n","tf.Tensor([[  2  84 172 193  93  88  84 373  93  39 131 216 208  87  39 332  16   3]], shape=(1, 18), dtype=int64)\n","tf.Tensor(b'the other thing is that the body is a very different kind of a person .', shape=(), dtype=string)\n","\n","Epoch 2 Batch 6000 Loss 4.0132 Accuracy 0.3139\n","Epoch 2 Batch 6050 Loss 4.0124 Accuracy 0.3140\n","Epoch 2 Batch 6100 Loss 4.0112 Accuracy 0.3141\n","Epoch 2 Batch 6150 Loss 4.0104 Accuracy 0.3141\n","любому , кто заинтересован в этом в любои сфере медицинских услуг , мы будем рады помочь и рассказать , как мы этого достигли и как он сможет этого достигнуть . если мы будем это делать , то сможем изменить здравоохранение африки .\n","and anyone who is interested in doing it in any health care situation , we will be happy to assist you and tell you how we ' ve done it , and how you can do it . if we do this , we can change the face of health care in africa .\n","tf.Tensor(\n","[[  2  91   9 117 139  86 110 264  86 105  94  14  85  91   9 117 139  86\n","  105  88  14  85  91   9 117 139  86 105  88  14  85  91   9 117 139  86\n","  105  88  14  85  91]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"we ' re going to be able to do this , and we ' re going to do that , and we ' re going to do that , and we ' re going to do that , and we\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 6200 Loss 4.0095 Accuracy 0.3142\n","Epoch 2 Batch 6250 Loss 4.0085 Accuracy 0.3143\n","Epoch 2 Batch 6300 Loss 4.0077 Accuracy 0.3144\n","Epoch 2 Batch 6350 Loss 4.0068 Accuracy 0.3145\n","представьте , что можно обоитись одним суперпроводниковым кабелем , чтобы обеспечить работу всеи электростанции .\n","imagine you could back up a single power station with a single superconducting cable .\n","tf.Tensor(\n","[[  2  95 217   9  57 203  39 189 113  84 157  14  85  84 172 193  93  88\n","   84 343  87  84 368  93  86 177  39 667  16   3]], shape=(1, 30), dtype=int64)\n","tf.Tensor(b\"so let ' s take a look at the world , and the other thing is that the power of the city is to make a difference .\", shape=(), dtype=string)\n","\n","Epoch 2 Batch 6400 Loss 4.0061 Accuracy 0.3146\n","Epoch 2 Batch 6450 Loss 4.0053 Accuracy 0.3146\n","Epoch 2 Batch 6500 Loss 4.0045 Accuracy 0.3147\n","ничего не скрывается .\n","there ' s nothing underground about it .\n","tf.Tensor([[  2  90   9  57 112 361  16   3]], shape=(1, 8), dtype=int64)\n","tf.Tensor(b\"it ' s not enough .\", shape=(), dtype=string)\n","\n","Epoch 3 Batch 0 Loss 3.9336 Accuracy 0.3159\n","Epoch 3 Batch 50 Loss 3.8709 Accuracy 0.3282\n","Epoch 3 Batch 100 Loss 3.8663 Accuracy 0.3281\n","Epoch 3 Batch 150 Loss 3.8666 Accuracy 0.3271\n","однако то , в чем женщины согласны так это в их собственнои роли , и в том , что эта роль должна быть центральнои и активнои .\n","where women agree , however , is on their own role , and that it must be central and active .\n","tf.Tensor(\n","[[  2 102  84 897  93  88  84 118  99 112 139  86 110  39 215 193  14  85\n","   90   9  57  39 215 193  86 105  16   3]], shape=(1, 28), dtype=int64)\n","tf.Tensor(b\"but the truth is that the people are not going to be a good thing , and it ' s a good thing to do .\", shape=(), dtype=string)\n","\n","Epoch 3 Batch 200 Loss 3.8782 Accuracy 0.3268\n","Epoch 3 Batch 250 Loss 3.8733 Accuracy 0.3273\n","Epoch 3 Batch 300 Loss 3.8766 Accuracy 0.3267\n","Epoch 3 Batch 350 Loss 3.8725 Accuracy 0.3275\n","( аплодисменты )\n","( applause )\n","tf.Tensor([[  2  10 211  11   3]], shape=(1, 5), dtype=int64)\n","tf.Tensor(b'( applause )', shape=(), dtype=string)\n","\n","Epoch 3 Batch 400 Loss 3.8676 Accuracy 0.3277\n","Epoch 3 Batch 450 Loss 3.8655 Accuracy 0.3278\n","Epoch 3 Batch 500 Loss 3.8618 Accuracy 0.3281\n","Epoch 3 Batch 550 Loss 3.8619 Accuracy 0.3277\n","у машин есть светодиодные фары , светодиодные фонари , машины могут общаться друг с другом и предотвращать аварии с помощью обмена информациеи .\n","cars have led - based headlights , led - based back lights , and cars can communicate with each other and prevent accidents in the way that they exchange information .\n","tf.Tensor(\n","[[  2  84 321 193  93  88  84 621 107 177  39 188 208  87  39 188 208  87\n","   39 188 208  87  39 188 208  87  39 188 208  87  39 188 208  87  39 188\n","  208  87  39 188 208]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b'the whole thing is that the machine can make a new kind of a new kind of a new kind of a new kind of a new kind of a new kind of a new kind of a new kind', shape=(), dtype=string)\n","\n","Epoch 3 Batch 600 Loss 3.8620 Accuracy 0.3276\n","Epoch 3 Batch 650 Loss 3.8616 Accuracy 0.3276\n","Epoch 3 Batch 700 Loss 3.8598 Accuracy 0.3280\n","Epoch 3 Batch 750 Loss 3.8617 Accuracy 0.3276\n","сеичас его главная цель — любои ценои уехать из ливана , даже если для этого придется отправиться в опасныи путь с другими беженцами , переправляющимися в европу по средиземному морю .\n","his current obsession is to leave lebanon at any cost — even if it meant embarking on a hazardous journey along with refugees drifting towards europe today through the mediterranean .\n","tf.Tensor(\n","[[  2  85  89  84 428  87  84 494 450  14  92 107 391  88  84 780  87  84\n","  157  93 112 139  86 110 264  86 110 264  86 110 264  86 110 264  86 110\n","  264  86 105  88  14]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b'and in the case of the united states , you can imagine that the average of the world is not going to be able to be able to be able to be able to be able to do that ,', shape=(), dtype=string)\n","\n","Epoch 3 Batch 800 Loss 3.8640 Accuracy 0.3275\n","Epoch 3 Batch 850 Loss 3.8657 Accuracy 0.3272\n","Epoch 3 Batch 900 Loss 3.8664 Accuracy 0.3273\n","Epoch 3 Batch 950 Loss 3.8676 Accuracy 0.3271\n","что вы видите здесь ?\n","what do you see here ?\n","tf.Tensor([[  2 103  99  92 229  31   3]], shape=(1, 7), dtype=int64)\n","tf.Tensor(b'what are you doing ?', shape=(), dtype=string)\n","\n","Epoch 3 Batch 1000 Loss 3.8655 Accuracy 0.3274\n","Epoch 3 Batch 1050 Loss 3.8652 Accuracy 0.3275\n","Epoch 3 Batch 1100 Loss 3.8634 Accuracy 0.3276\n","Epoch 3 Batch 1150 Loss 3.8648 Accuracy 0.3274\n","а некоторые могут сказать : « послушаи , даже не пытаися . . . » но , что касается меня , я задался вопросом : « что ж , а откуда эти лидеры приходят ?\n","` ` and they might say , ` ` ' ' look , do n ' t even try . ' ' ' ' but , for me , i asked the question , ` ` ' ' well , where are these leaders coming from ? ' '\n","tf.Tensor(\n","[[  2  38  38  47   9  51 112 480  14  38  38   9   9  92 138  14  92 138\n","   14  92   9 117 112 139  86 110  39 215 193  16   9   9   9   9  85  47\n","    9  51 112 139  86]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"` ` i ' m not saying , ` ` ' ' you know , you know , you ' re not going to be a good thing . ' ' ' ' and i ' m not going to\", shape=(), dtype=string)\n","\n","Epoch 3 Batch 1200 Loss 3.8643 Accuracy 0.3275\n","Epoch 3 Batch 1250 Loss 3.8626 Accuracy 0.3277\n","Epoch 3 Batch 1300 Loss 3.8610 Accuracy 0.3280\n","Epoch 3 Batch 1350 Loss 3.8587 Accuracy 0.3283\n","когда я хожу по картиннои галерее , зал за залом , после 15 - 20 - ти минут я ловлю себя на мысли , что я уже не думаю о картинах .\n","when i ' m walking around an art gallery , rooms and rooms full of paintings , after about 15 or 20 minutes , i realize i ' m not thinking about the paintings .\n","tf.Tensor(\n","[[  2 129  47   9  51 139  86 287  92  39 192 290  87  39 192 290  87  39\n","  192 290  87  39 192 290  87  39 192 290  87  39 192 290  87  39 192 290\n","   87  39 192 290  87]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"when i ' m going to show you a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of\", shape=(), dtype=string)\n","\n","Epoch 3 Batch 1400 Loss 3.8594 Accuracy 0.3283\n","Epoch 3 Batch 1450 Loss 3.8597 Accuracy 0.3282\n","Epoch 3 Batch 1500 Loss 3.8585 Accuracy 0.3284\n","Epoch 3 Batch 1550 Loss 3.8573 Accuracy 0.3285\n","в музее горных пород , где мы работаем , хранятся четыре t . rex , соответственно я их смогу вскрыть .\n","and at the museum of the rockies where we work , i have four t . rexes , so i can cut a whole bunch of them .\n","tf.Tensor(\n","[[  2  85  91   9 153 194  39 210  87 940 170  88  91   9 153 173 330 104\n","   14  85  91   9 153 194  86 176  86  84 771  16   3]], shape=(1, 31), dtype=int64)\n","tf.Tensor(b\"and we ' ve got a lot of fun things that we ' ve been working on , and we ' ve got to go to the street .\", shape=(), dtype=string)\n","\n","Epoch 3 Batch 1600 Loss 3.8573 Accuracy 0.3284\n","Epoch 3 Batch 1650 Loss 3.8553 Accuracy 0.3286\n","Epoch 3 Batch 1700 Loss 3.8539 Accuracy 0.3287\n","Epoch 3 Batch 1750 Loss 3.8538 Accuracy 0.3288\n","ширина переднего края составляет 7 , 2 км . на этом снимке , если отступить назад , вы видите только около 2 , 4 км .\n","the calving face is four and a half miles across , and in this shot , as we pull back , you ' re only seeing about a mile and a half .\n","tf.Tensor(\n","[[  2  85  84 274 310 169  14  92 107 145  88  84 780  87  84 896  93  39\n","  192 290  87  39 192 290  87  39 192 290  87  39 192 290  87  39 226  16\n","    3]], shape=(1, 37), dtype=int64)\n","tf.Tensor(b'and the next 10 years , you can see that the average of the sun is a little bit of a little bit of a little bit of a little bit of a year .', shape=(), dtype=string)\n","\n","Epoch 3 Batch 1800 Loss 3.8528 Accuracy 0.3289\n","Epoch 3 Batch 1850 Loss 3.8507 Accuracy 0.3292\n","Epoch 3 Batch 1900 Loss 3.8504 Accuracy 0.3293\n","Epoch 3 Batch 1950 Loss 3.8504 Accuracy 0.3293\n","это называется контрольнои точкои , но это понятие несколько обманчивое , так как под этои точкои подразумевается диапазон в 4 - 9 килограмм .\n","this is called your set point , but that ' s a misleading term , because it ' s actually a range of about 10 or 15 pounds .\n","tf.Tensor(\n","[[  2  94  93  39 131 402 303  87  84 676  87  84  59  16  57  16  14  85\n","   84 200 193  93  88  84 115  15  86  15  39  15 184  15 226  15 297  15\n","  297  15 226  15 297]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b'this is a very simple example of the size of the u . s . , and the only thing is that the one - to - a - two - year - old - old - year - old', shape=(), dtype=string)\n","\n","Epoch 3 Batch 2000 Loss 3.8496 Accuracy 0.3294\n","Epoch 3 Batch 2050 Loss 3.8495 Accuracy 0.3295\n","Epoch 3 Batch 2100 Loss 3.8495 Accuracy 0.3295\n","Epoch 3 Batch 2150 Loss 3.8491 Accuracy 0.3295\n","и сегодня мы все вместе пришли сюда , чтобы стать свидетелями женщин , лишенных жизнеи .\n","together , we ' ve come together to bear witness to these women ' s lost lives .\n","tf.Tensor(\n","[[  2  85  91   9 153 194  86 110  39 215 278  14  85  91   9 153 194  86\n","  110 264  86 155  84 369 292  16   3]], shape=(1, 27), dtype=int64)\n","tf.Tensor(b\"and we ' ve got to be a good story , and we ' ve got to be able to get the best place .\", shape=(), dtype=string)\n","\n","Epoch 3 Batch 2200 Loss 3.8484 Accuracy 0.3296\n","Epoch 3 Batch 2250 Loss 3.8468 Accuracy 0.3297\n","Epoch 3 Batch 2300 Loss 3.8465 Accuracy 0.3298\n","Epoch 3 Batch 2350 Loss 3.8458 Accuracy 0.3298\n","в любое время я могу работать в отличном от вас ритме и темпе , и , тем не менее , поддерживать иллюзию того , что я поддерживаю с вами связь в реальном времени .\n","at all times , i can operate at a different rhythm and pace from you , while i sustain the illusion that i ' m tapped into you in real time .\n","tf.Tensor(\n","[[  2  47   9  51 139  86 110 264  86 105 182 119  39 192 290 140 186  39\n","  282 352  14  85  47   9  51 139  86 110 264  86 105 106  84 221 193  14\n","   85  47   9  51 139]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"i ' m going to be able to do something like a little bit more than a few times , and i ' m going to be able to do with the same thing , and i ' m going\", shape=(), dtype=string)\n","\n","Epoch 3 Batch 2400 Loss 3.8452 Accuracy 0.3299\n","Epoch 3 Batch 2450 Loss 3.8442 Accuracy 0.3300\n","Epoch 3 Batch 2500 Loss 3.8439 Accuracy 0.3301\n","Epoch 3 Batch 2550 Loss 3.8429 Accuracy 0.3302\n","если у государства позитивныи имидж , как , например , у германии , швеции и швеицарии , ему все дается легко и дешево .\n","if a country has a great , positive image , like germany has or sweden or switzerland , everything is easy and everything is cheap .\n","tf.Tensor(\n","[[   2   95   14  121   92  189  113   84  157   14   92    9  117   39\n","   131  351   15 2237   14   85   92    9  117  139   86  110   39  131\n","   297  349  744 6627 3902  277   14   85   92    9  117  139   86]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"so , if you look at the world , you ' re a very high - tech , and you ' re going to be a very old manufacturer , and you ' re going to\", shape=(), dtype=string)\n","\n","Epoch 3 Batch 2600 Loss 3.8422 Accuracy 0.3303\n","Epoch 3 Batch 2650 Loss 3.8421 Accuracy 0.3304\n","Epoch 3 Batch 2700 Loss 3.8416 Accuracy 0.3305\n","Epoch 3 Batch 2750 Loss 3.8408 Accuracy 0.3306\n","половина из них жертвовала через интернет .\n","half of them gave over the internet .\n","tf.Tensor([[  2 184 169 280  14  96 142 264  86 155  39 929  16   3]], shape=(1, 14), dtype=int64)\n","tf.Tensor(b'two years ago , they were able to get a chance .', shape=(), dtype=string)\n","\n","Epoch 3 Batch 2800 Loss 3.8399 Accuracy 0.3305\n","Epoch 3 Batch 2850 Loss 3.8389 Accuracy 0.3307\n","Epoch 3 Batch 2900 Loss 3.8384 Accuracy 0.3307\n","Epoch 3 Batch 2950 Loss 3.8380 Accuracy 0.3308\n","просто как в сказке .\n","what a fabulous environment .\n","tf.Tensor([[  2  92 107 145  84 597  16   3]], shape=(1, 8), dtype=int64)\n","tf.Tensor(b'you can see the sound .', shape=(), dtype=string)\n","\n","Epoch 3 Batch 3000 Loss 3.8379 Accuracy 0.3308\n","Epoch 3 Batch 3050 Loss 3.8371 Accuracy 0.3308\n","Epoch 3 Batch 3100 Loss 3.8369 Accuracy 0.3309\n","Epoch 3 Batch 3150 Loss 3.8359 Accuracy 0.3310\n","изобразительное искусство — украшение поверхностеи и тел — является универсальным человеческим своиством .\n","visual arts — decoration of surfaces and bodies — appears to be a human universal .\n","tf.Tensor(\n","[[  2  84 197 782 157  93  39 131 216 208  87  39 666  87  39 666  87  39\n","  666  87  39 666  16   3]], shape=(1, 24), dtype=int64)\n","tf.Tensor(b'the most complex world is a very different kind of a culture of a culture of a culture of a culture .', shape=(), dtype=string)\n","\n","Epoch 3 Batch 3200 Loss 3.8353 Accuracy 0.3311\n","Epoch 3 Batch 3250 Loss 3.8353 Accuracy 0.3311\n","Epoch 3 Batch 3300 Loss 3.8351 Accuracy 0.3311\n","Epoch 3 Batch 3350 Loss 3.8342 Accuracy 0.3312\n","ткань и швы могут просто разорваться .\n","the fabric and the stitching could just pull apart .\n","tf.Tensor([[   2   90  107  110  264   86  177   90 1693   16    3]], shape=(1, 11), dtype=int64)\n","tf.Tensor(b'it can be able to make it easier .', shape=(), dtype=string)\n","\n","Epoch 3 Batch 3400 Loss 3.8334 Accuracy 0.3313\n","Epoch 3 Batch 3450 Loss 3.8332 Accuracy 0.3313\n","Epoch 3 Batch 3500 Loss 3.8331 Accuracy 0.3313\n","Epoch 3 Batch 3550 Loss 3.8327 Accuracy 0.3314\n","но это не значит , что люди понимают , что глобальное потепление наиболее разрушительно отражается на самых бедных и слабых .\n","now , that does n ' t mean that people understand that global warming hurts the poorest and the weakest the most .\n","tf.Tensor(\n","[[  2  85  84 443 213  84 118 147  99 112 139  86 110  84 197 263 193  88\n","   91   9 117 229  93  88  84 197 263 193  88  93  88  84 197 263  93  88\n","   84 118  99 112  84]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"and the reason why the people who are not going to be the most important thing that we ' re doing is that the most important thing that is that the most important is that the people are not the\", shape=(), dtype=string)\n","\n","Epoch 3 Batch 3600 Loss 3.8324 Accuracy 0.3314\n","Epoch 3 Batch 3650 Loss 3.8320 Accuracy 0.3315\n","Epoch 3 Batch 3700 Loss 3.8311 Accuracy 0.3316\n","Epoch 3 Batch 3750 Loss 3.8303 Accuracy 0.3317\n","я думаю , что нет ничего лучше кризиса , чтобы показать , чтo деиствительно важно . ураган « сэнди » помог мне понять , что устроиства и их возможности также важны для нас , как еда и кров .\n","i think there ' s nothing like a crisis to tell you what ' s really important and what ' s not , and sandy made me realize that our devices and their connectivity matter to us right up there with food and shelter .\n","tf.Tensor(\n","[[  2  47 143  88  91   9 117 112 139  86 110 264  86 105  94  14 102  47\n","  143  88  91   9 117 139  86 110 264  86 105 182  88   9  57 139  86 110\n","   84 197 263 193  88]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"i think that we ' re not going to be able to do this , but i think that we ' re going to be able to do something that ' s going to be the most important thing that\", shape=(), dtype=string)\n","\n","Epoch 3 Batch 3800 Loss 3.8296 Accuracy 0.3318\n","Epoch 3 Batch 3850 Loss 3.8287 Accuracy 0.3319\n","Epoch 3 Batch 3900 Loss 3.8285 Accuracy 0.3319\n","Epoch 3 Batch 3950 Loss 3.8285 Accuracy 0.3319\n","научныи прорыв , такои , которыи потенциально может спасать жизни , иногда может лежать прямо на поверхности , ожидая открытия , в развившеися , накопленнои массе человеческих истории , или в проверенных временем приспособлениях , которые мы наблюдаем в природе вокруг нас .\n","scientific breakthrough , the kind that can potentially save lives , can sometimes be lying right out in the open for us to discover , in the evolved , accumulated body of human anecdote , for example , or in the time - tested adaptations that we observe in the natural world around us .\n","tf.Tensor(\n","[[  2  89 246  14  91 101  39 210  87  84 221 166  88  91   9 117 139  86\n","  110 264  86 105 106  84 166  91   9 117 139  86 110 264  86 245  39 376\n","   87 135  91   9 117]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"in fact , we have a lot of the same way that we ' re going to be able to do with the way we ' re going to be able to find a sense of how we ' re\", shape=(), dtype=string)\n","\n","Epoch 3 Batch 4000 Loss 3.8286 Accuracy 0.3319\n","Epoch 3 Batch 4050 Loss 3.8280 Accuracy 0.3320\n","Epoch 3 Batch 4100 Loss 3.8270 Accuracy 0.3321\n","Epoch 3 Batch 4150 Loss 3.8269 Accuracy 0.3321\n","в принципе , это могло продолжаться бесконечно . при полном безбрачии носителеи\n","and , in principle , it could ' ve gone on forever , with perfect celibacy on the part of the hosts .\n","tf.Tensor(\n","[[  2  90   9  57  39 131 402 193  86 105 106  84 470  14  85  90   9  57\n","   39 131 402 193  16   3]], shape=(1, 24), dtype=int64)\n","tf.Tensor(b\"it ' s a very simple thing to do with the car , and it ' s a very simple thing .\", shape=(), dtype=string)\n","\n","Epoch 3 Batch 4200 Loss 3.8263 Accuracy 0.3322\n","Epoch 3 Batch 4250 Loss 3.8261 Accuracy 0.3322\n","Epoch 3 Batch 4300 Loss 3.8254 Accuracy 0.3323\n","Epoch 3 Batch 4350 Loss 3.8247 Accuracy 0.3323\n","` ` это не так . когда он был еще совсем молодым , около 30 , он написал ` ` ' ' десять заповедеи дирижера ' ' ' ' . ' '\n","` ` it ' s not true . when he was a young man of about 30 , he wrote what he called ` ` the ten commandments for conductors . ' ' ' '\n","tf.Tensor(\n","[[  2  38  38  90   9  57 112  39 131 263 349  14 102  90   9  57 233  38\n","   38   9   9  84   9   9   9   9   9  75  10 171  11  38  38   9   9  84\n","  197 263 193  93  16]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"` ` it ' s not a very important man , but it ' s called ` ` ' ' the ' ' ' ' ' \\xe2\\x80\\x94 ( laughter ) ` ` ' ' the most important thing is .\", shape=(), dtype=string)\n","\n","Epoch 3 Batch 4400 Loss 3.8238 Accuracy 0.3324\n","Epoch 3 Batch 4450 Loss 3.8228 Accuracy 0.3325\n","Epoch 3 Batch 4500 Loss 3.8221 Accuracy 0.3326\n","Epoch 3 Batch 4550 Loss 3.8221 Accuracy 0.3326\n","я не считаю , что подобные соединения ненатуральными .\n","i do n ' t believe that chemicals are unnatural .\n","tf.Tensor([[  2  47   9  51 112 385 109  84 246  88  47   9  51 112 385 109  16   3]], shape=(1, 18), dtype=int64)\n","tf.Tensor(b\"i ' m not talking about the fact that i ' m not talking about .\", shape=(), dtype=string)\n","\n","Epoch 3 Batch 4600 Loss 3.8218 Accuracy 0.3326\n","Epoch 3 Batch 4650 Loss 3.8216 Accuracy 0.3326\n","Epoch 3 Batch 4700 Loss 3.8207 Accuracy 0.3328\n","Epoch 3 Batch 4750 Loss 3.8202 Accuracy 0.3328\n","теперь это выросло во что - то большее , потому что я использую броски разных амплитуд , по которым летят шары , в то время как я слежу за временем .\n","now , this has expanded into a much bigger piece , because i use ramps of different parabolas that i roll the balls on while i ' m keeping time with this .\n","tf.Tensor(\n","[[  2  85  47   9 153 173 264  86 145  88  84 157   9  57 197 263  14  85\n","   47   9 153 173 264  86 145  84 166  88  84 157   9  57 173 264  86 145\n","   84 166  88  96   9]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"and i ' ve been able to see that the world ' s most important , and i ' ve been able to see the way that the world ' s been able to see the way that they '\", shape=(), dtype=string)\n","\n","Epoch 3 Batch 4800 Loss 3.8194 Accuracy 0.3329\n","Epoch 3 Batch 4850 Loss 3.8186 Accuracy 0.3330\n","Epoch 3 Batch 4900 Loss 3.8181 Accuracy 0.3330\n","Epoch 3 Batch 4950 Loss 3.8176 Accuracy 0.3331\n","` ` он спросил : ` ` ' ' кому ты желаешь зла ? ' ' ' ' мне пришлось признаться , что я желала , чтобы игроки ` ` ' ' нью - иорк янкиз ' ' ' ' переломали себе все руки и ноги — ( смех ) чтобы бруклин доджерс смогли выиграть в чемпионате сша по беисболу . ' '\n","` ` and he said , ` ` ' ' to whom did you wish harm ? ' ' ' ' and i had to say that i wished that various new york yankees players would break arms , legs and ankles — ( laughter ) — so that the brooklyn dodgers could win their first world series . ' '\n","tf.Tensor(\n","[[   2   38   38   95   14   47  190   14   38   38    9    9  174   14\n","    47    9   51  139   86  110   39  192  290   87   39  192  290   87\n","    39  192  290   87   39  192  290   87   39  654 1755  464   87]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"` ` so , i said , ` ` ' ' well , i ' m going to be a little bit of a little bit of a little bit of a little bit of acupation of\", shape=(), dtype=string)\n","\n","Epoch 3 Batch 5000 Loss 3.8176 Accuracy 0.3331\n","Epoch 3 Batch 5050 Loss 3.8169 Accuracy 0.3331\n","Epoch 3 Batch 5100 Loss 3.8166 Accuracy 0.3332\n","Epoch 3 Batch 5150 Loss 3.8160 Accuracy 0.3332\n","тот доклад , что попал на стол президенту джонсону , когда мне было два года — было это в 1965 году .\n","that report that landed on president johnson ' s desk when i was two years old — 1965 .\n","tf.Tensor(\n","[[  2  85  84 181 156  47  97  39 888  89  84 561  87  84 157  14  85  47\n","   97  39 888  89  84 561  87  84 226  16   3]], shape=(1, 29), dtype=int64)\n","tf.Tensor(b'and the first time i was a kid in the middle of the world , and i was a kid in the middle of the year .', shape=(), dtype=string)\n","\n","Epoch 3 Batch 5200 Loss 3.8153 Accuracy 0.3333\n","Epoch 3 Batch 5250 Loss 3.8148 Accuracy 0.3333\n","Epoch 3 Batch 5300 Loss 3.8143 Accuracy 0.3334\n","Epoch 3 Batch 5350 Loss 3.8136 Accuracy 0.3335\n","я готов доказать , в противовес широко распространенному мнению , что мы знаем , как выполнять все эти функции . какои специалист мог подумать , что германия станет в наши дни и объединеннои , и демократическои , если исходить из информации , имевшеися в оксфорде в 1943 - м году ? но специалисты из оксфорда готовили почву\n","the poverty of our knowledge must become the first basis of moving forward , and not imposition of the framework that works on the basis of mathematical modeling , for which i have enormous respect .\n","tf.Tensor(\n","[[  2  47 299  14  47 143  14  89  84 494 450  14  91   9 153 173 264  86\n","  105  94 106  39 210  87 118 147  99 139  86 110 264  86 105  94  14  85\n","   47 143  14  89 246]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"i mean , i think , in the united states , we ' ve been able to do this with a lot of people who are going to be able to do this , and i think , in fact\", shape=(), dtype=string)\n","\n","Epoch 3 Batch 5400 Loss 3.8128 Accuracy 0.3335\n","Epoch 3 Batch 5450 Loss 3.8122 Accuracy 0.3336\n","Epoch 3 Batch 5500 Loss 3.8116 Accuracy 0.3337\n","Epoch 3 Batch 5550 Loss 3.8109 Accuracy 0.3338\n","сначала мы думали , что марс похож на луну : много кратеров , пыльная пустыня — геологически он мертв .\n","well , mars we thought was initially moon - like : full of craters , arid and a dead world .\n","tf.Tensor(\n","[[  2  95  14  91   9 153 173 264  86 143 109  84 181 156  14 130  84 181\n","  193  91   9 153 173 229  93  14  91   9 153 173 264  86 105  39 210  87\n","  399  16   3]], shape=(1, 39), dtype=int64)\n","tf.Tensor(b\"so , we ' ve been able to think about the first time , because the first thing we ' ve been doing is , we ' ve been able to do a lot of stuff .\", shape=(), dtype=string)\n","\n","Epoch 3 Batch 5600 Loss 3.8102 Accuracy 0.3338\n","Epoch 3 Batch 5650 Loss 3.8097 Accuracy 0.3339\n","Epoch 3 Batch 5700 Loss 3.8091 Accuracy 0.3339\n","Epoch 3 Batch 5750 Loss 3.8090 Accuracy 0.3339\n","я сомневаюсь , что он говорил именно это , потому что никто не знает точно , что говорил гиппократ , но мы точно знаем , что один из величаиших греческих врачеи сказал следующее , и это было записано в однои из книг , автором которои считается гиппократ , а название этои книги - « наставления » . я прочитаю эту цитату .\n","` ` i suspect he never really said this , because we do n ' t know what hippocrates really said , but we do know for sure that one of the great greek physicians said the following , and it has been recorded in one of the books attributed to hippocrates , and the book is called ` ` ' ' precepts . ' ' ' ' and i ' ll read you what it is . ' '\n","tf.Tensor(\n","[[   2   38   38   85   47    9   51   39  131 1320  530   14   85  127\n","   190   14   38   38    9    9   47    9   51  112   39  215  764   14\n","   130  127    9   57   39  215  764   14   85  127    9   57   39]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"` ` and i ' m a very famous guy , and he said , ` ` ' ' i ' m not a good friend , because he ' s a good friend , and he ' s a\", shape=(), dtype=string)\n","\n","Epoch 3 Batch 5800 Loss 3.8087 Accuracy 0.3339\n","Epoch 3 Batch 5850 Loss 3.8083 Accuracy 0.3340\n","Epoch 3 Batch 5900 Loss 3.8079 Accuracy 0.3340\n","Epoch 3 Batch 5950 Loss 3.8073 Accuracy 0.3340\n","мы постоянно судим о людях по их внешности .\n","we make judgments on people ' s faces all the time .\n","tf.Tensor([[  2  91 101  39 210  87 118 147  99 326  86 309 146 255  16   3]], shape=(1, 16), dtype=int64)\n","tf.Tensor(b'we have a lot of people who are trying to understand their own .', shape=(), dtype=string)\n","\n","Epoch 3 Batch 6000 Loss 3.8069 Accuracy 0.3341\n","Epoch 3 Batch 6050 Loss 3.8067 Accuracy 0.3341\n","Epoch 3 Batch 6100 Loss 3.8062 Accuracy 0.3342\n","Epoch 3 Batch 6150 Loss 3.8058 Accuracy 0.3342\n","вы заходите в кабинку , берете интервью у своеи бабушки или любого родственника , записывая его , и отправляете в библиотеку конгресса .\n","you go into these booths , you interview your grandmother or relative , you leave with a copy of the interview and an interview goes into the library of congress .\n","tf.Tensor(\n","[[   2   92  138   14   84  332  147    9   57  139   86  110   89   84\n","   561   87   84  771   14   84   41 3502 3907  158   14   84   41 3502\n","  3907  158   14   84   41  490 2594  236   14   84   41  490 2594]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"you know , the person who ' s going to be in the middle of the street , the charming , the charming , the chrony , the chron\", shape=(), dtype=string)\n","\n","Epoch 3 Batch 6200 Loss 3.8057 Accuracy 0.3342\n","Epoch 3 Batch 6250 Loss 3.8051 Accuracy 0.3343\n","Epoch 3 Batch 6300 Loss 3.8046 Accuracy 0.3343\n","Epoch 3 Batch 6350 Loss 3.8043 Accuracy 0.3343\n","но эти люди сподвигли восточно - индиискую компанию , которая пришла сюда ради бизнеса , весьма грязного бизнеса . . .\n","but such people , compelled to the east india company , which came here for business , a very dirty kind of business . . .\n","tf.Tensor(\n","[[  2 102  90   9  57  39 131 263 559  14  85  90   9  57  39 131 263 559\n","   14  85  90   9  57  39 559 233  84 368  14  85  90   9  57  39 559 233\n","   84 368  16   3]], shape=(1, 40), dtype=int64)\n","tf.Tensor(b\"but it ' s a very important company , and it ' s a very important company , and it ' s a company called the city , and it ' s a company called the city .\", shape=(), dtype=string)\n","\n","Epoch 3 Batch 6400 Loss 3.8039 Accuracy 0.3344\n","Epoch 3 Batch 6450 Loss 3.8034 Accuracy 0.3344\n","Epoch 3 Batch 6500 Loss 3.8029 Accuracy 0.3345\n","также я хотел избежать сложных технологии .\n","or neither with including complex technology .\n","tf.Tensor([[  2  47   9 153 173 264  86 346  39 210  87 285  16   3]], shape=(1, 14), dtype=int64)\n","tf.Tensor(b\"i ' ve been able to create a lot of technology .\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 0 Loss 3.6355 Accuracy 0.3698\n","Epoch 4 Batch 50 Loss 3.7612 Accuracy 0.3358\n","Epoch 4 Batch 100 Loss 3.7486 Accuracy 0.3386\n","Epoch 4 Batch 150 Loss 3.7478 Accuracy 0.3388\n","и что произоидет тогда ?\n","at that point , what ' s going to happen ?\n","tf.Tensor([[  2  85 103   9  57 139 104 149  31   3]], shape=(1, 10), dtype=int64)\n","tf.Tensor(b\"and what ' s going on here ?\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 200 Loss 3.7498 Accuracy 0.3390\n","Epoch 4 Batch 250 Loss 3.7446 Accuracy 0.3402\n","Epoch 4 Batch 300 Loss 3.7438 Accuracy 0.3406\n","Epoch 4 Batch 350 Loss 3.7381 Accuracy 0.3412\n","он вытаскивает любую карту и заставляет группу следовать инструкциям на неи .\n","he ' ll draw one at random , and he ' ll make the band follow the instructions on the card .\n","tf.Tensor(\n","[[  2 127   9  57  39 292 167 127   9  57 139  86 110 264  86 155  84 221\n","  335 120  84 172 421  87  84 157  16   3]], shape=(1, 28), dtype=int64)\n","tf.Tensor(b\"he ' s a place where he ' s going to be able to get the same information from the other side of the world .\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 400 Loss 3.7401 Accuracy 0.3409\n","Epoch 4 Batch 450 Loss 3.7388 Accuracy 0.3410\n","Epoch 4 Batch 500 Loss 3.7371 Accuracy 0.3412\n","Epoch 4 Batch 550 Loss 3.7354 Accuracy 0.3417\n","не верите ?\n","you do n ' t believe me ?\n","tf.Tensor([[  2 179  31   3]], shape=(1, 4), dtype=int64)\n","tf.Tensor(b'right ?', shape=(), dtype=string)\n","\n","Epoch 4 Batch 600 Loss 3.7345 Accuracy 0.3418\n","Epoch 4 Batch 650 Loss 3.7355 Accuracy 0.3417\n","Epoch 4 Batch 700 Loss 3.7354 Accuracy 0.3416\n","Epoch 4 Batch 750 Loss 3.7368 Accuracy 0.3414\n","те , кто живет не в лондоне ,\n","for those of you live outside london in the u . k .\n","tf.Tensor([[  2 108   9  57 175 166  86 315  89  84 494 450  16   3]], shape=(1, 14), dtype=int64)\n","tf.Tensor(b\"there ' s no way to live in the united states .\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 800 Loss 3.7359 Accuracy 0.3416\n","Epoch 4 Batch 850 Loss 3.7363 Accuracy 0.3414\n","Epoch 4 Batch 900 Loss 3.7365 Accuracy 0.3415\n","Epoch 4 Batch 950 Loss 3.7365 Accuracy 0.3415\n","но сможем ли мы извлечь максимум из наших игр ?\n","but will we make the most of our playfulness ?\n","tf.Tensor(\n","[[   2  102  135  105   91  227   39  188  947   86   84  240 1343   31\n","     3]], shape=(1, 15), dtype=int64)\n","tf.Tensor(b'but how do we use a new approach to the human beings ?', shape=(), dtype=string)\n","\n","Epoch 4 Batch 1000 Loss 3.7385 Accuracy 0.3413\n","Epoch 4 Batch 1050 Loss 3.7373 Accuracy 0.3414\n","Epoch 4 Batch 1100 Loss 3.7353 Accuracy 0.3417\n","Epoch 4 Batch 1150 Loss 3.7344 Accuracy 0.3419\n","существует показатель , которыи говорит , что в сша на двух третьих земли , которая когда - то была покрыта лесами и затем вырублена , снова стали расти леса , как только лесорубы и фермеры отступили , особенно из восточнои части страны .\n","there ' s one estimate which suggests that in the united states , two thirds of the land which was once forested and then cleared has become reforested as loggers and farmers have retreated , particularly from the eastern half of the country .\n","tf.Tensor(\n","[[  2  85  84 443  88  84 780 472  93  88  84 780 269  87  84 157  93  84\n","  200 166  86 155  84 198  87  84 157   9  57 603  14  84 780 673  87  84\n","  157  14  84 780 673]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"and the reason that the average government is that the average part of the world is the only way to get the back of the world ' s house , the average area of the world , the average area\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 1200 Loss 3.7346 Accuracy 0.3418\n","Epoch 4 Batch 1250 Loss 3.7328 Accuracy 0.3421\n","Epoch 4 Batch 1300 Loss 3.7333 Accuracy 0.3419\n","Epoch 4 Batch 1350 Loss 3.7323 Accuracy 0.3420\n","но многие человеческие недуги — это болезни сердца , ума и духа .\n","but many human afflictions are diseases of the heart , the mind and the spirit .\n","tf.Tensor(\n","[[  2 102  84 197 263 193 109  84 240 373  93  88  84 240 373  93 112  39\n","  240 224  16   3]], shape=(1, 22), dtype=int64)\n","tf.Tensor(b'but the most important thing about the human body is that the human body is not a human being .', shape=(), dtype=string)\n","\n","Epoch 4 Batch 1400 Loss 3.7304 Accuracy 0.3422\n","Epoch 4 Batch 1450 Loss 3.7282 Accuracy 0.3425\n","Epoch 4 Batch 1500 Loss 3.7275 Accuracy 0.3426\n","Epoch 4 Batch 1550 Loss 3.7274 Accuracy 0.3426\n","может быть , 4 вечера на неделе читаите им сказки на ночь . и три вечера рассказываите им истории .\n","maybe four nights out of the week read them bedtime stories and three nights of the week have them tell stories .\n","tf.Tensor(\n","[[  2  92   9 153 194  86 110  39 471  14  39 282 429 436  14  39 282 429\n","  436  14  39 282  87 136  14  39 282  87 136  14  39 282  87 136  14  39\n","  282  87 136  16   3]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"you ' ve got to be a child , a few days later , a few days later , a few of them , a few of them , a few of them , a few of them .\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 1600 Loss 3.7284 Accuracy 0.3426\n","Epoch 4 Batch 1650 Loss 3.7282 Accuracy 0.3427\n","Epoch 4 Batch 1700 Loss 3.7277 Accuracy 0.3427\n","Epoch 4 Batch 1750 Loss 3.7271 Accuracy 0.3427\n","господа , вы можете купить книгу билла клинтона « моя жизнь » у нас в книжном магазине здесь , в ted .\n","` ` and folks , you can buy a copy of bill clinton ' s ` ` ' ' my life ' ' ' ' from the bookstore here at ted . ' '\n","tf.Tensor(\n","[[  2  38  38  38  38   9   9  92   9 117 139  86 110  39 649 649 649 649\n","  649  14   9   9   9   9 238  92  98  84 253 226  14  85  47   9  51 139\n","   86 287  92  39 192]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"` ` ` ` ' ' you ' re going to be a ted ted ted ted ted , ' ' ' ' thank you for the last year , and i ' m going to show you a little\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 1800 Loss 3.7265 Accuracy 0.3428\n","Epoch 4 Batch 1850 Loss 3.7273 Accuracy 0.3427\n","Epoch 4 Batch 1900 Loss 3.7274 Accuracy 0.3427\n","Epoch 4 Batch 1950 Loss 3.7259 Accuracy 0.3429\n","значит , практически каждыи из вас встречался с тем , через что проходят ежегодно три миллиарда людеи .\n","well , it turns out that you share that experience with more than three billion people every year .\n","tf.Tensor(\n","[[  2  85 152  14  89  84 253 310 169  14  96   9 153 173 264  86 155 118\n","   89  84 157  14  85  96   9 117 139  86 110 264  86 315  89  39 444 118\n","   16   3]], shape=(1, 38), dtype=int64)\n","tf.Tensor(b\"and then , in the last 10 years , they ' ve been able to get people in the world , and they ' re going to be able to live in a billion people .\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 2000 Loss 3.7251 Accuracy 0.3430\n","Epoch 4 Batch 2050 Loss 3.7247 Accuracy 0.3430\n","Epoch 4 Batch 2100 Loss 3.7241 Accuracy 0.3430\n","Epoch 4 Batch 2150 Loss 3.7232 Accuracy 0.3431\n","стоп . надо заняться чем - то другим ” .\n","stop everything . let me do something else .\n","tf.Tensor([[  2  43  28  92   9 117 139  86 101  39 210  87 150 202  16   3]], shape=(1, 16), dtype=int64)\n","tf.Tensor(b\"e : you ' re going to have a lot of your work .\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 2200 Loss 3.7233 Accuracy 0.3432\n","Epoch 4 Batch 2250 Loss 3.7228 Accuracy 0.3432\n","Epoch 4 Batch 2300 Loss 3.7232 Accuracy 0.3431\n","Epoch 4 Batch 2350 Loss 3.7230 Accuracy 0.3432\n","что делать , если то , чем вы занимаетесь , работа , которую вы любите , становится на вкус как пыль ?\n","so what do you do when the thing you do , the work you love , starts to taste like dust ?\n","tf.Tensor(\n","[[  2 103 121  92   9 117  39 215 193 119  88  14  92   9 117 139  86 110\n","  264  86 105 182 119  88  31   3]], shape=(1, 26), dtype=int64)\n","tf.Tensor(b\"what if you ' re a good thing like that , you ' re going to be able to do something like that ?\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 2400 Loss 3.7225 Accuracy 0.3432\n","Epoch 4 Batch 2450 Loss 3.7214 Accuracy 0.3434\n","Epoch 4 Batch 2500 Loss 3.7212 Accuracy 0.3434\n","Epoch 4 Batch 2550 Loss 3.7208 Accuracy 0.3435\n","или же вы желаете увидеть мир настолько ясно , насколько это возможно ?\n","or do you yearn to see the world as clearly as you possibly can ?\n","tf.Tensor(\n","[[  2  85 103 105  92 143 109  88  31 103 107  92 105 121  92   9 117  89\n","   39 166  31   3]], shape=(1, 22), dtype=int64)\n","tf.Tensor(b\"and what do you think about that ? what can you do if you ' re in a way ?\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 2600 Loss 3.7199 Accuracy 0.3436\n","Epoch 4 Batch 2650 Loss 3.7193 Accuracy 0.3437\n","Epoch 4 Batch 2700 Loss 3.7193 Accuracy 0.3437\n","Epoch 4 Batch 2750 Loss 3.7190 Accuracy 0.3437\n","мое первое свидание было с колином .\n","my first date was colin .\n","tf.Tensor([[  2 116 181 156  97  39 349  16   3]], shape=(1, 9), dtype=int64)\n","tf.Tensor(b'my first time was a man .', shape=(), dtype=string)\n","\n","Epoch 4 Batch 2800 Loss 3.7187 Accuracy 0.3438\n","Epoch 4 Batch 2850 Loss 3.7184 Accuracy 0.3438\n","Epoch 4 Batch 2900 Loss 3.7176 Accuracy 0.3439\n","Epoch 4 Batch 2950 Loss 3.7177 Accuracy 0.3439\n","из - за отрицательнои гравитации невидимои энергии в космосе — теперь мы называем ее темнои энергиеи , но я сделал ее дымчато - белои , чтобы вам было видно — отрицательная гравитация этои энергии может заставить все галактики отталкиваться друг от друга , заставить расширение ускоряться , а не замедляться .\n","because the repulsive gravity of an invisible energy in space — we now call it dark energy , but i ' ve made it smokey white here so you can see it — its repulsive gravity would cause each galaxy to push against every other , driving expansion to speed up , not slow down .\n","tf.Tensor(\n","[[  2  85  47   9  51 139  86 287  92  39 210  87  84 157   9  57 378  14\n","   85  90   9  57  39 192 290 119  94  14  85  90   9  57  39 192 290 119\n","   39 210  87 378  14]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"and i ' m going to show you a lot of the world ' s energy , and it ' s a little bit like this , and it ' s a little bit like a lot of energy ,\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 3000 Loss 3.7173 Accuracy 0.3439\n","Epoch 4 Batch 3050 Loss 3.7170 Accuracy 0.3440\n","Epoch 4 Batch 3100 Loss 3.7165 Accuracy 0.3440\n","Epoch 4 Batch 3150 Loss 3.7167 Accuracy 0.3440\n","у младшего поколения нет .\n","younger people do n ' t .\n","tf.Tensor([[  2 122 870 159 175 357  16   3]], shape=(1, 8), dtype=int64)\n","tf.Tensor(b'our generation has no future .', shape=(), dtype=string)\n","\n","Epoch 4 Batch 3200 Loss 3.7168 Accuracy 0.3440\n","Epoch 4 Batch 3250 Loss 3.7170 Accuracy 0.3439\n","Epoch 4 Batch 3300 Loss 3.7163 Accuracy 0.3440\n","Epoch 4 Batch 3350 Loss 3.7160 Accuracy 0.3440\n","замедляются примерно на 5 миль / час ( 8 км / ч ) затем мы возвращаем ногу на обратно педаль .\n","they last for about five miles , in which case we put our foot back on the pedal .\n","tf.Tensor(\n","[[  2  91   9 117 139  86 176  86  84 561  14  85  91   9 117 139  86 176\n","   86  84 561  87  84 226  14  85  91   9 117 139  86 176  86  84 509 310\n","   14 262 837 624 994]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"we ' re going to go to the middle , and we ' re going to go to the middle of the year , and we ' re going to go to the top 10 , 000 miles per hour\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 3400 Loss 3.7163 Accuracy 0.3440\n","Epoch 4 Batch 3450 Loss 3.7159 Accuracy 0.3440\n","Epoch 4 Batch 3500 Loss 3.7157 Accuracy 0.3441\n","Epoch 4 Batch 3550 Loss 3.7149 Accuracy 0.3442\n","у них есть все решения в мире .\n","they have all the solutions in the world .\n","tf.Tensor([[  2  96   9 117 114  89  84 157  16   3]], shape=(1, 10), dtype=int64)\n","tf.Tensor(b\"they ' re all in the world .\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 3600 Loss 3.7147 Accuracy 0.3442\n","Epoch 4 Batch 3650 Loss 3.7146 Accuracy 0.3442\n","Epoch 4 Batch 3700 Loss 3.7140 Accuracy 0.3443\n","Epoch 4 Batch 3750 Loss 3.7138 Accuracy 0.3443\n","дело принимает серьезныи оборот , когда вы видите что - то типа этого . оk ?\n","it really only gets serious when you look at something like this . ok ?\n","tf.Tensor(\n","[[  2  92 145  14  90   9  57  39 192 290 119  94  14  85  92 107 145 103\n","  434 129  92 189 113  90  31   3]], shape=(1, 26), dtype=int64)\n","tf.Tensor(b\"you see , it ' s a little bit like this , and you can see what happens when you look at it ?\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 3800 Loss 3.7135 Accuracy 0.3443\n","Epoch 4 Batch 3850 Loss 3.7129 Accuracy 0.3444\n","Epoch 4 Batch 3900 Loss 3.7122 Accuracy 0.3445\n","Epoch 4 Batch 3950 Loss 3.7119 Accuracy 0.3445\n","не могли бы представители пакистана сеичас встать ?\n","would the pakistanis please just stand up please ?\n","tf.Tensor([[  2 105  52   9  58  92 101  86 176  86  84 494 450  31   3]], shape=(1, 15), dtype=int64)\n","tf.Tensor(b\"do n ' t you have to go to the united states ?\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 4000 Loss 3.7119 Accuracy 0.3446\n","Epoch 4 Batch 4050 Loss 3.7117 Accuracy 0.3446\n","Epoch 4 Batch 4100 Loss 3.7114 Accuracy 0.3447\n","Epoch 4 Batch 4150 Loss 3.7113 Accuracy 0.3446\n","впрочем , я думаю он позднее так и сделал . просто все это свидетельствовало о состоянии души .\n","and i ' m sure he did that later . ( laughter ) but that just indicates the state of mind , you know .\n","tf.Tensor(\n","[[  2  85  47 143  90   9  57  39 131 402 193  14  85  47   9  51 139  86\n","  287  92  84 221 193  14  85  47   9  51 139  86 105  90  16   3]], shape=(1, 34), dtype=int64)\n","tf.Tensor(b\"and i think it ' s a very simple thing , and i ' m going to show you the same thing , and i ' m going to do it .\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 4200 Loss 3.7113 Accuracy 0.3447\n","Epoch 4 Batch 4250 Loss 3.7106 Accuracy 0.3448\n","Epoch 4 Batch 4300 Loss 3.7103 Accuracy 0.3448\n","Epoch 4 Batch 4350 Loss 3.7102 Accuracy 0.3448\n","я знала , что мир далек от идеала , но определенно не каждая геи - история была трагичнои .\n","i knew the world was far from perfect , but surely not every gay story was tragic .\n","tf.Tensor(\n","[[  2  47  97 112  39 413 349  14 102  47  97  39 413 349  14  85  47 143\n","   90  97  39 131 387 193  16   3]], shape=(1, 26), dtype=int64)\n","tf.Tensor(b'i was not a young man , but i was a young man , and i think it was a very interesting thing .', shape=(), dtype=string)\n","\n","Epoch 4 Batch 4400 Loss 3.7101 Accuracy 0.3448\n","Epoch 4 Batch 4450 Loss 3.7096 Accuracy 0.3449\n","Epoch 4 Batch 4500 Loss 3.7094 Accuracy 0.3449\n","Epoch 4 Batch 4550 Loss 3.7091 Accuracy 0.3450\n","ему провели все виды стандартного лечения .\n","he received the standard treatments .\n","tf.Tensor(\n","[[  2 127   9  57 173 330 106  84 118 147 101 173 330 106  84 221 193  16\n","    3]], shape=(1, 19), dtype=int64)\n","tf.Tensor(b\"he ' s been working with the people who have been working with the same thing .\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 4600 Loss 3.7086 Accuracy 0.3450\n","Epoch 4 Batch 4650 Loss 3.7085 Accuracy 0.3450\n","Epoch 4 Batch 4700 Loss 3.7084 Accuracy 0.3450\n","Epoch 4 Batch 4750 Loss 3.7081 Accuracy 0.3450\n","здесь не так много мужчин , но тем не менее , послушаите меня .\n","now i know there are n ' t a lot of men here , but bear with me .\n","tf.Tensor(\n","[[  2  47   9  51 112 479  16  47   9  51 112 479  16  47   9  51 112 661\n","   16   3]], shape=(1, 20), dtype=int64)\n","tf.Tensor(b\"i ' m not sure . i ' m not sure . i ' m not happy .\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 4800 Loss 3.7079 Accuracy 0.3450\n","Epoch 4 Batch 4850 Loss 3.7076 Accuracy 0.3451\n","Epoch 4 Batch 4900 Loss 3.7076 Accuracy 0.3450\n","Epoch 4 Batch 4950 Loss 3.7075 Accuracy 0.3451\n","и эти отношения могут быть скомбинированы в сотни тысяч , потенциально , в миллионы разных комбинации .\n","and those relationships can in fact be constructed in hundreds of thousands , potentially millions of ways .\n","tf.Tensor(\n","[[  2  85 108  99 769  87 608  87 118 147 107 110 264  86 245 188 128 188\n","  128 188 128 188 128 188 128 188 128 188 128 188 609  16   3]], shape=(1, 33), dtype=int64)\n","tf.Tensor(b'and there are hundreds of thousands of people who can be able to find new or new or new or new or new or new or new or new ones .', shape=(), dtype=string)\n","\n","Epoch 4 Batch 5000 Loss 3.7071 Accuracy 0.3451\n","Epoch 4 Batch 5050 Loss 3.7068 Accuracy 0.3451\n","Epoch 4 Batch 5100 Loss 3.7062 Accuracy 0.3452\n","Epoch 4 Batch 5150 Loss 3.7060 Accuracy 0.3452\n","сеичас я вам расскажу , как этого избежать .\n","so now i ' m going to tell you how to get out of that .\n","tf.Tensor([[  2  47   9  51 139  86 254 109 103  47   9  51 139  86 254 109  16   3]], shape=(1, 18), dtype=int64)\n","tf.Tensor(b\"i ' m going to talk about what i ' m going to talk about .\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 5200 Loss 3.7059 Accuracy 0.3453\n","Epoch 4 Batch 5250 Loss 3.7058 Accuracy 0.3453\n","Epoch 4 Batch 5300 Loss 3.7056 Accuracy 0.3453\n","Epoch 4 Batch 5350 Loss 3.7054 Accuracy 0.3453\n","затем нужно подумать о москитах , создать их модель , и модель их появления и исчезновения .\n","you then have to introduce the mosquitoes , and you have to model that and how they come and go .\n","tf.Tensor(\n","[[  2  85 152  91   9 117 139  86 105  94  14  85 152  91   9 117 139  86\n","  105 182 119  94  14  85 152  91   9 117 139  86 105 182 119  94  16   3]], shape=(1, 36), dtype=int64)\n","tf.Tensor(b\"and then we ' re going to do this , and then we ' re going to do something like this , and then we ' re going to do something like this .\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 5400 Loss 3.7051 Accuracy 0.3454\n","Epoch 4 Batch 5450 Loss 3.7046 Accuracy 0.3454\n","Epoch 4 Batch 5500 Loss 3.7044 Accuracy 0.3454\n","Epoch 4 Batch 5550 Loss 3.7042 Accuracy 0.3454\n","увижу ли я семью или умру одна ? увижу ли я семью или умру одна ?\n","will i see my family or die alone ? will i see my family or die alone ?\n","tf.Tensor(\n","[[  2 128  99  47  31  47   9  51  39 332 128  39 332 128  39 403 128  39\n","  332  31   3]], shape=(1, 21), dtype=int64)\n","tf.Tensor(b\"or are i ? i ' m a person or a person or a family or a person ?\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 5600 Loss 3.7039 Accuracy 0.3455\n","Epoch 4 Batch 5650 Loss 3.7034 Accuracy 0.3455\n","Epoch 4 Batch 5700 Loss 3.7029 Accuracy 0.3456\n","Epoch 4 Batch 5750 Loss 3.7025 Accuracy 0.3456\n","10 % больных в нашеи сети принимали литии .\n","ten percent of the people in our system took lithium .\n","tf.Tensor([[  2 310 234  87  84 118 147 101 173  89  84 357  16   3]], shape=(1, 14), dtype=int64)\n","tf.Tensor(b'10 percent of the people who have been in the future .', shape=(), dtype=string)\n","\n","Epoch 4 Batch 5800 Loss 3.7023 Accuracy 0.3457\n","Epoch 4 Batch 5850 Loss 3.7023 Accuracy 0.3457\n","Epoch 4 Batch 5900 Loss 3.7022 Accuracy 0.3457\n","Epoch 4 Batch 5950 Loss 3.7019 Accuracy 0.3457\n","но эта система также используется теми , кто работает против нас и наших союзников .\n","but it ' s also used by people who are working against us and our allies .\n","tf.Tensor(\n","[[  2 102  90   9  57 187  84 200 193  88  91   9 117 229 106 122 255 272\n","   16   3]], shape=(1, 20), dtype=int64)\n","tf.Tensor(b\"but it ' s also the only thing that we ' re doing with our own system .\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 6000 Loss 3.7016 Accuracy 0.3458\n","Epoch 4 Batch 6050 Loss 3.7013 Accuracy 0.3457\n","Epoch 4 Batch 6100 Loss 3.7012 Accuracy 0.3457\n","Epoch 4 Batch 6150 Loss 3.7008 Accuracy 0.3458\n","не произошло вообще ничего , кроме желтухи от одного из этих препаратов .\n","nothing happened except that i got jaundiced from one of these things .\n","tf.Tensor(\n","[[  2 108   9  57 175 115 319 430  89  84 221 166  88  84 470  97  89  84\n","  561  16   3]], shape=(1, 21), dtype=int64)\n","tf.Tensor(b\"there ' s no one ever seen in the same way that the car was in the middle .\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 6200 Loss 3.7006 Accuracy 0.3458\n","Epoch 4 Batch 6250 Loss 3.7002 Accuracy 0.3458\n","Epoch 4 Batch 6300 Loss 3.7000 Accuracy 0.3459\n","Epoch 4 Batch 6350 Loss 3.6998 Accuracy 0.3459\n","поднимите руки , у скольких из вас есть книги , cd , dvd или видео - кассеты , разбросанные по всему дому , которыми вы , вероятно , никогда больше не воспользуетесь , но вы все равно не можете заставить себя выкинуть их ?\n","hands up — how many of you have books , cds , dvds , or videos lying around your house that you probably wo n ' t use again , but you ca n ' t quite bring yourself to throw away ?\n","tf.Tensor(\n","[[  2 107  92 391  39 282 772 128  39 282 128 225  15 226  15 297  14 128\n","   39 282 128 225  15 226  15 297  14 128 107  92 391 121  92   9 117 112\n","  139  86 110 264  86]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"can you imagine a few weeks or a few or three - year - old , or a few or three - year - old , or can you imagine if you ' re not going to be able to\", shape=(), dtype=string)\n","\n","Epoch 4 Batch 6400 Loss 3.6995 Accuracy 0.3459\n","Epoch 4 Batch 6450 Loss 3.6993 Accuracy 0.3459\n","Epoch 4 Batch 6500 Loss 3.6989 Accuracy 0.3460\n","( аплодисменты )\n","( applause )\n","tf.Tensor([[  2  10 211  11   3]], shape=(1, 5), dtype=int64)\n","tf.Tensor(b'( applause )', shape=(), dtype=string)\n","\n","Epoch 5 Batch 0 Loss 3.4671 Accuracy 0.3700\n","Epoch 5 Batch 50 Loss 3.6803 Accuracy 0.3429\n","Epoch 5 Batch 100 Loss 3.6689 Accuracy 0.3457\n","Epoch 5 Batch 150 Loss 3.6609 Accuracy 0.3469\n","это одноклеточныи организм , широко распространенныи в океане .\n","that ' s a unicellular organism ubiquitous in the oceans .\n","tf.Tensor(\n","[[   2   94   93   39  131  562  342   87 1340   89   84  157   14   85\n","    90    9   57   39  131  340  710   87  301   16    3]], shape=(1, 25), dtype=int64)\n","tf.Tensor(b\"this is a very large number of stars in the world , and it ' s a very small amount of water .\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 200 Loss 3.6618 Accuracy 0.3472\n","Epoch 5 Batch 250 Loss 3.6662 Accuracy 0.3467\n","Epoch 5 Batch 300 Loss 3.6664 Accuracy 0.3473\n","Epoch 5 Batch 350 Loss 3.6636 Accuracy 0.3480\n","вы видите рождение новои эры .\n","you are witnessing the birth of a new era .\n","tf.Tensor([[  2  92 107 145  84 667 295  84 157  16   3]], shape=(1, 11), dtype=int64)\n","tf.Tensor(b'you can see the difference between the world .', shape=(), dtype=string)\n","\n","Epoch 5 Batch 400 Loss 3.6644 Accuracy 0.3483\n","Epoch 5 Batch 450 Loss 3.6601 Accuracy 0.3488\n","Epoch 5 Batch 500 Loss 3.6559 Accuracy 0.3496\n","Epoch 5 Batch 550 Loss 3.6534 Accuracy 0.3499\n","мы разрабатываем эти приборы , но мы бесплатно распространяем их по всему миру , так что люди могут работать с ними и пытаться лечить нарушения .\n","we ' re developing these tools , but we share them freely with hundreds of groups all over the world , so people can study and try to treat different disorders .\n","tf.Tensor(\n","[[  2  91   9 117 139  86 110 264  86 105 170  88  99 224 291  86 110 264\n","   86 105 170  88  99 224 291  86 110 264  86 105 170  88  99 224 291  86\n","  110 264  86 105 170]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"we ' re going to be able to do things that are being used to be able to do things that are being used to be able to do things that are being used to be able to do things\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 600 Loss 3.6494 Accuracy 0.3508\n","Epoch 5 Batch 650 Loss 3.6482 Accuracy 0.3509\n","Epoch 5 Batch 700 Loss 3.6513 Accuracy 0.3506\n","Epoch 5 Batch 750 Loss 3.6514 Accuracy 0.3504\n","по профессии я дизаинер товаров .\n","i ' m a product designer by trade .\n","tf.Tensor(\n","[[  2  47   9  51  39 473  15  89  15  84  15  47  15  47  15  47  15  47\n","   15  47  15  84  15  47  15  47  15  47  15  84  15  47  15  47  15 356\n","   16   3]], shape=(1, 38), dtype=int64)\n","tf.Tensor(b\"i ' m a business - in - the - i - i - i - i - i - the - i - i - i - the - i - i - design .\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 800 Loss 3.6521 Accuracy 0.3502\n","Epoch 5 Batch 850 Loss 3.6550 Accuracy 0.3499\n","Epoch 5 Batch 900 Loss 3.6512 Accuracy 0.3506\n","Epoch 5 Batch 950 Loss 3.6511 Accuracy 0.3506\n","она будет интересна 2 000 треинспоттерам в норвегии .\n","it will fit for the 2 , 000 train spotters in norway .\n","tf.Tensor(\n","[[  2  90   9  57  39 210  87 344  89  84 494 450  14  85  90   9  57 109\n","  511  14 262 397  16   3]], shape=(1, 24), dtype=int64)\n","tf.Tensor(b\"it ' s a lot of money in the united states , and it ' s about 100 , 000 dollars .\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 1000 Loss 3.6499 Accuracy 0.3508\n","Epoch 5 Batch 1050 Loss 3.6522 Accuracy 0.3504\n","Epoch 5 Batch 1100 Loss 3.6510 Accuracy 0.3506\n","Epoch 5 Batch 1150 Loss 3.6507 Accuracy 0.3505\n","а называется он « черная вдова » , потому что самка паука съедает самца ; люди ее не особо интересуют .\n","and its a black widow because the female spider eats the male ; it does n ' t care about you .\n","tf.Tensor(\n","[[  2  38  38  90   9  57 233  38  38   9   9  84 701 349  16   9   9   9\n","    9 127 454  14  38  38   9   9 175  14 175  14 175  14 175  14 175  14\n","  175  14 175  14 175]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"` ` it ' s called ` ` ' ' the white man . ' ' ' ' he says , ` ` ' ' no , no , no , no , no , no , no , no\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 1200 Loss 3.6513 Accuracy 0.3505\n","Epoch 5 Batch 1250 Loss 3.6515 Accuracy 0.3506\n","Epoch 5 Batch 1300 Loss 3.6508 Accuracy 0.3506\n","Epoch 5 Batch 1350 Loss 3.6507 Accuracy 0.3506\n","однако такие вещи происходят и в новом свете , а япцы все еще используют образ этих камнеи .\n","but things like this happen in the western world as well , and the yap actually still use a form of these stones .\n","tf.Tensor(\n","[[  2 102  47   9  51 187 752  89  84 188  85 216 699  87  84 157  14  85\n","   47   9  51 187 139  86 287  92  84 221 193  16   3]], shape=(1, 31), dtype=int64)\n","tf.Tensor(b\"but i ' m also interested in the new and different parts of the world , and i ' m also going to show you the same thing .\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 1400 Loss 3.6514 Accuracy 0.3505\n","Epoch 5 Batch 1450 Loss 3.6507 Accuracy 0.3506\n","Epoch 5 Batch 1500 Loss 3.6491 Accuracy 0.3508\n","Epoch 5 Batch 1550 Loss 3.6496 Accuracy 0.3508\n","и уже после , я , ирано - американец группы .\n","and then there was me , the iranian - american of the group .\n","tf.Tensor([[  2  85 152  47   9  51  89  84 494 450  16   3]], shape=(1, 12), dtype=int64)\n","tf.Tensor(b\"and then i ' m in the united states .\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 1600 Loss 3.6500 Accuracy 0.3507\n","Epoch 5 Batch 1650 Loss 3.6498 Accuracy 0.3508\n","Epoch 5 Batch 1700 Loss 3.6497 Accuracy 0.3508\n","Epoch 5 Batch 1750 Loss 3.6488 Accuracy 0.3509\n","этот опыт длится 6 часов .\n","but it ' s six hours , the experience .\n","tf.Tensor([[  2  90   9  57  39 192 290  87  39 471  16   3]], shape=(1, 12), dtype=int64)\n","tf.Tensor(b\"it ' s a little bit of a child .\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 1800 Loss 3.6495 Accuracy 0.3508\n","Epoch 5 Batch 1850 Loss 3.6500 Accuracy 0.3508\n","Epoch 5 Batch 1900 Loss 3.6497 Accuracy 0.3509\n","Epoch 5 Batch 1950 Loss 3.6493 Accuracy 0.3510\n","начнем с первого этапа .\n","okay , we ' re going to start with the first stage .\n","tf.Tensor([[  2 217   9  57 203  84 181 747  16   3]], shape=(1, 10), dtype=int64)\n","tf.Tensor(b\"let ' s take the first step .\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 2000 Loss 3.6477 Accuracy 0.3512\n","Epoch 5 Batch 2050 Loss 3.6468 Accuracy 0.3512\n","Epoch 5 Batch 2100 Loss 3.6466 Accuracy 0.3513\n","Epoch 5 Batch 2150 Loss 3.6457 Accuracy 0.3514\n","мы , как показывают исследования , становимся умнее .\n","all the research now shows us that this actually makes us smarter .\n","tf.Tensor([[  2  91   9 117 139  86 309 135  91   9 117 229 170  16   3]], shape=(1, 15), dtype=int64)\n","tf.Tensor(b\"we ' re going to understand how we ' re doing things .\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 2200 Loss 3.6443 Accuracy 0.3516\n","Epoch 5 Batch 2250 Loss 3.6447 Accuracy 0.3515\n","Epoch 5 Batch 2300 Loss 3.6446 Accuracy 0.3515\n","Epoch 5 Batch 2350 Loss 3.6449 Accuracy 0.3515\n","и я сделал еще круг , и во второи раз ко мне пришел другои вопрос , которыи принес куда больше пользы — а почему я вообще хочу , чтобы меня помнили ?\n","and i did another stroll around , and the second time , another question came to me , which did me better , which was , why do i want to be remembered at all ?\n","tf.Tensor(\n","[[  2  85  47 190  14 174  14 103 105  47 105 109  94  31  47   9  51 139\n","   86 393 501  14  85  47   9  51 139  86 393 501  14 103  93  84 300  47\n","    9 153 194  86 105]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"and i said , well , what do i do about this ? i ' m going to ask myself , and i ' m going to ask myself , what is the question i ' ve got to do\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 2400 Loss 3.6446 Accuracy 0.3515\n","Epoch 5 Batch 2450 Loss 3.6435 Accuracy 0.3517\n","Epoch 5 Batch 2500 Loss 3.6434 Accuracy 0.3518\n","Epoch 5 Batch 2550 Loss 3.6429 Accuracy 0.3518\n","это возможно изменит человеческую продолжительность жизни .\n","it ' s going to probably change the human lifespan .\n","tf.Tensor([[  2  90 107 110  84 197 468 166  86 243  84 157  16   3]], shape=(1, 14), dtype=int64)\n","tf.Tensor(b'it can be the most possible way to change the world .', shape=(), dtype=string)\n","\n","Epoch 5 Batch 2600 Loss 3.6426 Accuracy 0.3518\n","Epoch 5 Batch 2650 Loss 3.6425 Accuracy 0.3518\n","Epoch 5 Batch 2700 Loss 3.6421 Accuracy 0.3519\n","Epoch 5 Batch 2750 Loss 3.6421 Accuracy 0.3519\n","вот изображение мозга девушки рори сэиреса .\n","this is a picture of , actually rory sayres ' girlfriend ' s brain .\n","tf.Tensor(\n","[[  2  94  93  39 437  87  39 437  87  39 437  87  39 437  87  39 437  87\n","   39 437  87  39 437  87  39 437  87  39 437  16   3]], shape=(1, 31), dtype=int64)\n","tf.Tensor(b'this is a picture of a picture of a picture of a picture of a picture of a picture of a picture of a picture of a picture .', shape=(), dtype=string)\n","\n","Epoch 5 Batch 2800 Loss 3.6424 Accuracy 0.3519\n","Epoch 5 Batch 2850 Loss 3.6423 Accuracy 0.3519\n","Epoch 5 Batch 2900 Loss 3.6425 Accuracy 0.3519\n","Epoch 5 Batch 2950 Loss 3.6419 Accuracy 0.3519\n","если меня откровенно спросить , то я отвечу : « женщина - пилот это круто » . но оказывается , когда дела начинают идти не по плану , немного рискованно , то я склонна к предрассудку , о существовании которого я не подозревала .\n","` ` if you ask me explicitly , i would say , ` ` ' ' female pilot : awesome . ' ' ' ' but it appears that when things get funky and a little troublesome , a little risky , i lean on a bias that i did n ' t even know that i had . ' '\n","tf.Tensor(\n","[[  2  38  38 129  47 190  14  38  38   9   9  47   9  51 139  86 110  39\n","  192 290  87  39 290  87  39 210  87 940  14 102  47   9  51 139  86 206\n","   14  38  38   9   9]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"` ` when i said , ` ` ' ' i ' m going to be a little bit of a bit of a lot of fun , but i ' m going to say , ` ` ' '\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 3000 Loss 3.6423 Accuracy 0.3519\n","Epoch 5 Batch 3050 Loss 3.6421 Accuracy 0.3519\n","Epoch 5 Batch 3100 Loss 3.6425 Accuracy 0.3518\n","Epoch 5 Batch 3150 Loss 3.6423 Accuracy 0.3518\n","иными словами , если мы уделяем внимание кому - то , то мы автоматически сопереживаем им , сочувствуем .\n","that is to say , if we attend to the other person , we automatically empathize , we automatically feel with them .\n","tf.Tensor(\n","[[  2 121  91   9 117 139  86 110 264  86 155 118  14  91   9 117 139  86\n","  110 264  86 155 118  86  84 221 332  14  85  91   9 117 139  86 110 264\n","   86 155  84 221 332]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"if we ' re going to be able to get people , we ' re going to be able to get people to the same person , and we ' re going to be able to get the same person\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 3200 Loss 3.6417 Accuracy 0.3519\n","Epoch 5 Batch 3250 Loss 3.6412 Accuracy 0.3519\n","Epoch 5 Batch 3300 Loss 3.6409 Accuracy 0.3520\n","Epoch 5 Batch 3350 Loss 3.6412 Accuracy 0.3520\n","переводить деньги за границу и в другую валюту очень дорого . это раздражает .\n","transferring money across borders and across currencies is really expensive : friction .\n","tf.Tensor(\n","[[   2   90    9   57  139   86  110   39  251   14  251   14  251   14\n","   251   14  251   14 1356   14   85   90    9   57  139   86  110   39\n","   131  215  292   16    3]], shape=(1, 33), dtype=int64)\n","tf.Tensor(b\"it ' s going to be a big , big , big , big , big , expensive , and it ' s going to be a very good place .\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 3400 Loss 3.6411 Accuracy 0.3520\n","Epoch 5 Batch 3450 Loss 3.6408 Accuracy 0.3520\n","Epoch 5 Batch 3500 Loss 3.6402 Accuracy 0.3521\n","Epoch 5 Batch 3550 Loss 3.6403 Accuracy 0.3521\n","это не микробы , которых медики научились побеждать ; это совсем иное определение здоровья . здоровье , которое имеет значительное преимущество , потому что оно внешнее , оно общее , и мы можем на него повлиять , в отличии от внутреннего , генетически предопределенного или индивидуализированного здоровья .\n","this is not the germs that medicos were trained to deal with ; this is a different definition of health , health that has a great advantage because it ' s external , it ' s shared , we can do something about it , as opposed to internal , genetically predetermined or individualized .\n","tf.Tensor(\n","[[   2   90    9   57  112  126  109   84  246   88   91    9  117  139\n","    86  101   39  265   87   84  240 1343   14  102  187   84  200  166\n","    91    9  117  139   86  110  264   86  874   84  265   87   84]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"it ' s not just about the fact that we ' re going to have a problem of the human beings , but also the only way we ' re going to be able to solve the problem of the\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 3600 Loss 3.6402 Accuracy 0.3521\n","Epoch 5 Batch 3650 Loss 3.6400 Accuracy 0.3521\n","Epoch 5 Batch 3700 Loss 3.6399 Accuracy 0.3522\n","Epoch 5 Batch 3750 Loss 3.6399 Accuracy 0.3522\n","раввины описывают это как быть царем , которыи имеет красивую и хрупкую стеклянную вазу .\n","the rabbis describe this as being like a king who has a beautiful , fragile glass bowl .\n","tf.Tensor(\n","[[   2   84  252   93   88   84   40 6933  311 7382   93   39  292  167\n","    84  470   93   39  292  167   84  470   93   39  292   89   39  375\n","    16    3]], shape=(1, 30), dtype=int64)\n","tf.Tensor(b'the idea is that the buffalcon is a place where the car is a place where the car is a place in a building .', shape=(), dtype=string)\n","\n","Epoch 5 Batch 3800 Loss 3.6397 Accuracy 0.3523\n","Epoch 5 Batch 3850 Loss 3.6394 Accuracy 0.3523\n","Epoch 5 Batch 3900 Loss 3.6391 Accuracy 0.3524\n","Epoch 5 Batch 3950 Loss 3.6380 Accuracy 0.3525\n","я получила степень доктора в колумбииском университете .\n","i earned my doctorate at columbia university .\n","tf.Tensor([[   2   47   97   39 1874  113   84  955   87 1481  955   16    3]], shape=(1, 13), dtype=int64)\n","tf.Tensor(b'i was a professor at the university of london university .', shape=(), dtype=string)\n","\n","Epoch 5 Batch 4000 Loss 3.6380 Accuracy 0.3525\n","Epoch 5 Batch 4050 Loss 3.6378 Accuracy 0.3525\n","Epoch 5 Batch 4100 Loss 3.6374 Accuracy 0.3526\n","Epoch 5 Batch 4150 Loss 3.6373 Accuracy 0.3526\n","я думаю , на данном этапе нужно ввести моратории .\n","i believe at this time we need a moratorium .\n","tf.Tensor([[  2  47 143  88   9  57 103  91 205  86 105  16   3]], shape=(1, 13), dtype=int64)\n","tf.Tensor(b\"i think that ' s what we need to do .\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 4200 Loss 3.6372 Accuracy 0.3526\n","Epoch 5 Batch 4250 Loss 3.6368 Accuracy 0.3526\n","Epoch 5 Batch 4300 Loss 3.6362 Accuracy 0.3527\n","Epoch 5 Batch 4350 Loss 3.6360 Accuracy 0.3527\n","мы можем сохранять энергию , используя суперпроводники , потому что нет потери энергии .\n","but we can also store energy using superconductors , because we have no dissipation .\n","tf.Tensor([[  2  91 107 227  84 378 378 378  14 130  91 107 227  84 378 378  16   3]], shape=(1, 18), dtype=int64)\n","tf.Tensor(b'we can use the energy energy energy , because we can use the energy energy .', shape=(), dtype=string)\n","\n","Epoch 5 Batch 4400 Loss 3.6364 Accuracy 0.3527\n","Epoch 5 Batch 4450 Loss 3.6366 Accuracy 0.3527\n","Epoch 5 Batch 4500 Loss 3.6366 Accuracy 0.3527\n","Epoch 5 Batch 4550 Loss 3.6366 Accuracy 0.3527\n","они придают человеческое лицо проблемам , которые издалека могут показаться абстрактными , идеологическими или огромными по своему глобальному влиянию .\n","it puts a human face on issues which , from afar , can appear abstract or ideological or monumental in their global impact .\n","tf.Tensor(\n","[[  2  96   9 117 114  84 118 147  99 415  89  39 292 167  96   9 117 139\n","   86 110  84 221 111  84 343  87  84 240 224  14  84 221  14  84 221 128\n","   84 343  87  84 240]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"they ' re all the people who are living in a place where they ' re going to be the same as the power of the human being , the same , the same or the power of the human\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 4600 Loss 3.6368 Accuracy 0.3527\n","Epoch 5 Batch 4650 Loss 3.6365 Accuracy 0.3527\n","Epoch 5 Batch 4700 Loss 3.6360 Accuracy 0.3528\n","Epoch 5 Batch 4750 Loss 3.6354 Accuracy 0.3528\n","также есть художники , которые извлекают анатомию из мира медицины и искусства и переносят ее прямо на улицы .\n","then there are artists who are extracting anatomy from both the medical world and the art world and are placing it directly on the streets .\n","tf.Tensor(\n","[[  2  85  90   9  57  39 292 167  84 368  93  39 292 167  84 368  93 112\n","   39 292  86 346  39 341  85  39 188 666  16   3]], shape=(1, 30), dtype=int64)\n","tf.Tensor(b\"and it ' s a place where the city is a place where the city is not a place to create a space and a new culture .\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 4800 Loss 3.6352 Accuracy 0.3529\n","Epoch 5 Batch 4850 Loss 3.6349 Accuracy 0.3529\n","Epoch 5 Batch 4900 Loss 3.6345 Accuracy 0.3529\n","Epoch 5 Batch 4950 Loss 3.6345 Accuracy 0.3529\n","я пришел туда , куда должен был приземлиться его вертолет .\n","i went to the place where his helicopter was about to land .\n","tf.Tensor(\n","[[  2  47  97 139  86 176  86  84 603  14  85  47  97 139  86 176  86  84\n","  603  16   3]], shape=(1, 21), dtype=int64)\n","tf.Tensor(b'i was going to go to the house , and i was going to go to the house .', shape=(), dtype=string)\n","\n","Epoch 5 Batch 5000 Loss 3.6338 Accuracy 0.3530\n","Epoch 5 Batch 5050 Loss 3.6334 Accuracy 0.3530\n","Epoch 5 Batch 5100 Loss 3.6332 Accuracy 0.3531\n","Epoch 5 Batch 5150 Loss 3.6331 Accuracy 0.3531\n","в каком - то смысле это — сущность вычислении .\n","there is in a sense a computing essence .\n","tf.Tensor([[  2  85  84 645  93  88  90   9  57  39 314 645  16   3]], shape=(1, 14), dtype=int64)\n","tf.Tensor(b\"and the reality is that it ' s a real reality .\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 5200 Loss 3.6333 Accuracy 0.3531\n","Epoch 5 Batch 5250 Loss 3.6331 Accuracy 0.3531\n","Epoch 5 Batch 5300 Loss 3.6326 Accuracy 0.3531\n","Epoch 5 Batch 5350 Loss 3.6325 Accuracy 0.3531\n","трое из них получили специальность повара .\n","we have about three fathers who have been trained to cook .\n","tf.Tensor([[   2   85  108  142   39  210   87  136   89   84 1093   16    3]], shape=(1, 13), dtype=int64)\n","tf.Tensor(b'and there were a lot of them in the hospital .', shape=(), dtype=string)\n","\n","Epoch 5 Batch 5400 Loss 3.6327 Accuracy 0.3531\n","Epoch 5 Batch 5450 Loss 3.6326 Accuracy 0.3531\n","Epoch 5 Batch 5500 Loss 3.6322 Accuracy 0.3532\n","Epoch 5 Batch 5550 Loss 3.6320 Accuracy 0.3532\n","тод : дэн , исполни нам свое произведение « моя орлиная песня » .\n","` ` tm : ok , now dan will play his piece ` ` ' ' my eagle song ' ' ' ' for you . ' '\n","tf.Tensor(\n","[[   2   38   38   95   14  116 1112 1260   93   14   38   38    9    9\n","    47    9   51  139   86  420   39 1260   16    9    9    9    9   10\n","   365   11   95   16    9    9    3]], shape=(1, 35), dtype=int64)\n","tf.Tensor(b\"` ` so , my favorite song is , ` ` ' ' i ' m going to play a song . ' ' ' ' ( music ) so . ' '\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 5600 Loss 3.6319 Accuracy 0.3532\n","Epoch 5 Batch 5650 Loss 3.6316 Accuracy 0.3532\n","Epoch 5 Batch 5700 Loss 3.6314 Accuracy 0.3533\n","Epoch 5 Batch 5750 Loss 3.6313 Accuracy 0.3533\n","такое уже происходило . где - то 12 000 лет назад в америке массово умирали млекопитающие , и полагают , что это была какая - то зараза .\n","that ' s happened before . about 12 , 000 years ago , there was a massive wave of mammal extinctions in the americas , and that is thought to have been a virulent disease .\n","tf.Tensor(\n","[[  2  90  97  39 131  14 131  14 131  14 131  14 131  14 131  14 131  14\n","  131  14 131  14 131  14 131  14 131  14 131  14 131  14 131  14 131  14\n","  131  14 131  14 131]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b'it was a very , very , very , very , very , very , very , very , very , very , very , very , very , very , very , very , very , very , very', shape=(), dtype=string)\n","\n","Epoch 5 Batch 5800 Loss 3.6310 Accuracy 0.3533\n","Epoch 5 Batch 5850 Loss 3.6311 Accuracy 0.3533\n","Epoch 5 Batch 5900 Loss 3.6308 Accuracy 0.3533\n","Epoch 5 Batch 5950 Loss 3.6309 Accuracy 0.3533\n","вот карта мира .\n","this is a map of the entire world .\n","tf.Tensor([[  2 149   9  57  84 923  87  84 157  16   3]], shape=(1, 11), dtype=int64)\n","tf.Tensor(b\"here ' s the map of the world .\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 6000 Loss 3.6303 Accuracy 0.3534\n","Epoch 5 Batch 6050 Loss 3.6300 Accuracy 0.3534\n","Epoch 5 Batch 6100 Loss 3.6296 Accuracy 0.3535\n","Epoch 5 Batch 6150 Loss 3.6292 Accuracy 0.3535\n","но для того чтобы не выити за рамки двух градусов для сохранения комфортнои жизни на земле , мгэик , межправительственная группа экспертов по изменению климата , установила допустимыи порог со2 на уровне 1 000 миллиардов тонн до конца нашего столетия .\n","but in order to get to this limit of two degrees , which is possible for us to survive , the ipcc , the intergovernmental panel on climate change , defines that we have a budget of emissions of 1 , 000 billion tons of co2 from now until the end of the century .\n","tf.Tensor(\n","[[  2  85  95  14  89  84 307  87  84 253 416 169  14  91   9 117 139  86\n","  101  39 188 535  87 378  14  85  91   9 117 139  86 101  39 131 562  14\n","  251  14 251  14 251]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"and so , in the end of the last 20 years , we ' re going to have a new species of energy , and we ' re going to have a very large , big , big , big\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 6200 Loss 3.6289 Accuracy 0.3536\n","Epoch 5 Batch 6250 Loss 3.6289 Accuracy 0.3536\n","Epoch 5 Batch 6300 Loss 3.6287 Accuracy 0.3536\n","Epoch 5 Batch 6350 Loss 3.6286 Accuracy 0.3536\n","мы знаем далеко не все о том , на что она влияет в человеческом мозгу , потому что исследования игры недостаточно финансируются .\n","we do n ' t know a whole lot about what it does for the human brain , because funding has not been exactly heavy for research on play .\n","tf.Tensor(\n","[[  2  91 105  52   9  58 138 135  86 105  88 130  90   9  57 112 126 130\n","   90   9  57  39 131 263 269  87  84 289  14 130  90   9  57 112 126  39\n","  131 263 269  87  84]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"we do n ' t know how to do that because it ' s not just because it ' s a very important part of the brain , because it ' s not just a very important part of the\", shape=(), dtype=string)\n","\n","Epoch 5 Batch 6400 Loss 3.6285 Accuracy 0.3536\n","Epoch 5 Batch 6450 Loss 3.6282 Accuracy 0.3537\n","Epoch 5 Batch 6500 Loss 3.6281 Accuracy 0.3537\n","проблема заключается в том , что мы по - прежнему не рассуждаем о нем в современном ключе .\n","now the problem is that we ' re not thinking about it in very innovative ways .\n","tf.Tensor(\n","[[  2  84 265  93  88  91   9 117 112 126 139  86 110 131 263  14 102  90\n","    9  57  39 265  16   3]], shape=(1, 24), dtype=int64)\n","tf.Tensor(b\"the problem is that we ' re not just going to be very important , but it ' s a problem .\", shape=(), dtype=string)\n","\n","Epoch 6 Batch 0 Loss 3.5569 Accuracy 0.3798\n","Epoch 6 Batch 50 Loss 3.6261 Accuracy 0.3508\n","Epoch 6 Batch 100 Loss 3.6312 Accuracy 0.3497\n","Epoch 6 Batch 150 Loss 3.6133 Accuracy 0.3532\n","хорошо , большои финиш .\n","all right , big finish .\n","tf.Tensor([[  2 433  14  95 149   9  57  39 242 303  16   3]], shape=(1, 12), dtype=int64)\n","tf.Tensor(b\"okay , so here ' s a great example .\", shape=(), dtype=string)\n","\n","Epoch 6 Batch 200 Loss 3.5988 Accuracy 0.3550\n","Epoch 6 Batch 250 Loss 3.5958 Accuracy 0.3553\n","Epoch 6 Batch 300 Loss 3.5957 Accuracy 0.3557\n","Epoch 6 Batch 350 Loss 3.5990 Accuracy 0.3556\n","дх : прямо сеичас ?\n","dh : right now ?\n","tf.Tensor([[   2 3191   28   95  167   99   91  139   31    3]], shape=(1, 10), dtype=int64)\n","tf.Tensor(b'pm : so where are we going ?', shape=(), dtype=string)\n","\n","Epoch 6 Batch 400 Loss 3.5928 Accuracy 0.3563\n","Epoch 6 Batch 450 Loss 3.5876 Accuracy 0.3573\n","Epoch 6 Batch 500 Loss 3.5863 Accuracy 0.3577\n","Epoch 6 Batch 550 Loss 3.5879 Accuracy 0.3574\n","он был очень великодушен , как многие из афганцев , с которыми я находился .\n","he was very generous , like many of the afghans i stayed with .\n","tf.Tensor(\n","[[  2  90  97  39 131 216 208  87 193  47  97 385 109  14  85  47  97  39\n","  210  87 118  16   3]], shape=(1, 23), dtype=int64)\n","tf.Tensor(b'it was a very different kind of thing i was talking about , and i was a lot of people .', shape=(), dtype=string)\n","\n","Epoch 6 Batch 600 Loss 3.5886 Accuracy 0.3575\n","Epoch 6 Batch 650 Loss 3.5907 Accuracy 0.3573\n","Epoch 6 Batch 700 Loss 3.5920 Accuracy 0.3574\n","Epoch 6 Batch 750 Loss 3.5912 Accuracy 0.3576\n","его отец спускался в подвал и стучал по бокам бочек с вином , чтобы определить , сколько вина осталось , и нужно ли заказывать еще .\n","and his father used to go down into the basement to tap on the sides of casks of wine to determine how much wine was left and whether to reorder .\n","tf.Tensor(\n","[[   2  127   97   39  349  147   97   39  349  147   97   39  349  147\n","    97   39  349  147   97   52    9   58   39 1157   14   85  127   97\n","   264   86  155  199  702   85  199  716   97  264   86  155  199]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"he was a man who was a man who was a man who was a man who was n ' t a doctor , and he was able to get his hands and his father was able to get his\", shape=(), dtype=string)\n","\n","Epoch 6 Batch 800 Loss 3.5916 Accuracy 0.3577\n","Epoch 6 Batch 850 Loss 3.5931 Accuracy 0.3576\n","Epoch 6 Batch 900 Loss 3.5949 Accuracy 0.3575\n","Epoch 6 Batch 950 Loss 3.5963 Accuracy 0.3574\n","наша вселенная не мыслит категориями нулеи и единиц , правды или лжи , черного или белого .\n","our universe does n ' t think in terms of zero or one , true or false , or black or white .\n","tf.Tensor(\n","[[  2  91   9 117 112 385 109  84 240 128  84 128 759 128  84 240 128  84\n","  240 128  84 240 128  84 307  87  84 607  16   3]], shape=(1, 30), dtype=int64)\n","tf.Tensor(b\"we ' re not talking about the human or the orth or the human or the human or the human or the end of the universe .\", shape=(), dtype=string)\n","\n","Epoch 6 Batch 1000 Loss 3.5946 Accuracy 0.3576\n","Epoch 6 Batch 1050 Loss 3.5931 Accuracy 0.3579\n","Epoch 6 Batch 1100 Loss 3.5918 Accuracy 0.3580\n","Epoch 6 Batch 1150 Loss 3.5925 Accuracy 0.3580\n","например , это крупная птица малаискии гомраи .\n","for example , this here is a big bird , a rhinoceros hornbill .\n","tf.Tensor(\n","[[  2  95  14  94  93  39 519 437  87  84  40 353 744 505  87  84  40 353\n","  744 505  16   3]], shape=(1, 22), dtype=int64)\n","tf.Tensor(b'so , this is a beautiful picture of the bouk of the bouk .', shape=(), dtype=string)\n","\n","Epoch 6 Batch 1200 Loss 3.5924 Accuracy 0.3579\n","Epoch 6 Batch 1250 Loss 3.5915 Accuracy 0.3581\n","Epoch 6 Batch 1300 Loss 3.5906 Accuracy 0.3582\n","Epoch 6 Batch 1350 Loss 3.5910 Accuracy 0.3580\n","и женщины , которых я имела честь встретить , рассказывали истории о том , как среди выживших их осталось только трое , и они лежали в коиках в лагерях для беженцев .\n","and the women , who i was so privileged to meet when there were three survivors , told these stories about lying in their cots in the refugee camps .\n","tf.Tensor(\n","[[   2   85   89   84  181  156   14   47   97   39  413  349  147   97\n","    89   84 1110   14   85   47   97  394   88   84  118  147  142   89\n","    84  561   87   84  467  142   89   84  561   87   84  467   85]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b'and in the first time , i was a young man who was in the village , and i was told that the people who were in the middle of the community were in the middle of the community and', shape=(), dtype=string)\n","\n","Epoch 6 Batch 1400 Loss 3.5913 Accuracy 0.3580\n","Epoch 6 Batch 1450 Loss 3.5900 Accuracy 0.3582\n","Epoch 6 Batch 1500 Loss 3.5897 Accuracy 0.3582\n","Epoch 6 Batch 1550 Loss 3.5898 Accuracy 0.3581\n","то , что вы видите , если вы видите название , задержание машины премьер - министра . первыи раз в истории премьер - министру индии был выписан штраф за неправильную парковку .\n","` ` what you see , if you see the title called ` ` ' ' pm ' s car held . ' ' ' ' this was the first time a prime minister of india was given a parking ticket . ' '\n","tf.Tensor(\n","[[   2   92  138   14   89   84  622    9 3308   14   84  181  193   92\n","     9  117  139   86  145   93   88   84  181  193   92    9  117  139\n","    86  145   93   84  181  332   89   84  494  450   14   84  181]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"you know , in the early ' 60s , the first thing you ' re going to see is that the first thing you ' re going to see is the first person in the united states , the first\", shape=(), dtype=string)\n","\n","Epoch 6 Batch 1600 Loss 3.5895 Accuracy 0.3582\n","Epoch 6 Batch 1650 Loss 3.5899 Accuracy 0.3582\n","Epoch 6 Batch 1700 Loss 3.5899 Accuracy 0.3582\n","Epoch 6 Batch 1750 Loss 3.5896 Accuracy 0.3582\n","вот та же вещь на пальце , чтобы показать , как она выглядит .\n","there ' s an example of the same thing on a finger , showing you basically what it looks like .\n","tf.Tensor([[  2  95  94  93 103  90 499 119  86 287  92 135  90 545  16   3]], shape=(1, 16), dtype=int64)\n","tf.Tensor(b'so this is what it looks like to show you how it works .', shape=(), dtype=string)\n","\n","Epoch 6 Batch 1800 Loss 3.5898 Accuracy 0.3581\n","Epoch 6 Batch 1850 Loss 3.5886 Accuracy 0.3583\n","Epoch 6 Batch 1900 Loss 3.5878 Accuracy 0.3584\n","Epoch 6 Batch 1950 Loss 3.5866 Accuracy 0.3586\n","сеичас все замечательно , линии перпендикулярны .\n","everything is nice and fine and perpendicular .\n","tf.Tensor([[  2 149   9  57  84 221 193  16  90   9  57  84 221  16   3]], shape=(1, 15), dtype=int64)\n","tf.Tensor(b\"here ' s the same thing . it ' s the same .\", shape=(), dtype=string)\n","\n","Epoch 6 Batch 2000 Loss 3.5866 Accuracy 0.3585\n","Epoch 6 Batch 2050 Loss 3.5859 Accuracy 0.3586\n","Epoch 6 Batch 2100 Loss 3.5857 Accuracy 0.3587\n","Epoch 6 Batch 2150 Loss 3.5853 Accuracy 0.3587\n","таким образом , разум помогает нам делать мир лучше .\n","and it ' s in this way that reason helps us create a better world .\n","tf.Tensor([[  2  95  14  84 140  91 143 109  84 157  14  84 140  91 143  16   3]], shape=(1, 17), dtype=int64)\n","tf.Tensor(b'so , the more we think about the world , the more we think .', shape=(), dtype=string)\n","\n","Epoch 6 Batch 2200 Loss 3.5849 Accuracy 0.3588\n","Epoch 6 Batch 2250 Loss 3.5842 Accuracy 0.3589\n","Epoch 6 Batch 2300 Loss 3.5844 Accuracy 0.3589\n","Epoch 6 Batch 2350 Loss 3.5840 Accuracy 0.3590\n","во всех этих примерах присутствует определенная идеальная форма , потому что они были задуманы с позиции лежащеи в их основе конструкции .\n","in all these examples , there ' s one ideal form , because these are thought in terms of structure .\n","tf.Tensor(\n","[[  2  84 166  88  96   9 153 173 229  93  86 145  84 801  87  84 375  14\n","   84 375  14  84 375  14  84 131 782  14 131  14 131 709  14 131 709  14\n","  131 709  16   3]], shape=(1, 40), dtype=int64)\n","tf.Tensor(b\"the way that they ' ve been doing is to see the structure of the building , the building , the building , the very complex , very , very powerful , very powerful , very powerful .\", shape=(), dtype=string)\n","\n","Epoch 6 Batch 2400 Loss 3.5845 Accuracy 0.3589\n","Epoch 6 Batch 2450 Loss 3.5850 Accuracy 0.3589\n","Epoch 6 Batch 2500 Loss 3.5854 Accuracy 0.3588\n","Epoch 6 Batch 2550 Loss 3.5853 Accuracy 0.3589\n","можно наити незанятую недвижимость ,\n","they can also see vacant property .\n","tf.Tensor(\n","[[  2  92 107 112 110 264  86 110 264  86 110 264  86 110 264  86 110 264\n","   86 110 264  86 110  39 192 290  87  39 192 290  87  39 192 290  87  39\n","  192 290  87  39 290]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b'you can not be able to be able to be able to be able to be able to be able to be a little bit of a little bit of a little bit of a little bit of a bit', shape=(), dtype=string)\n","\n","Epoch 6 Batch 2600 Loss 3.5860 Accuracy 0.3588\n","Epoch 6 Batch 2650 Loss 3.5862 Accuracy 0.3588\n","Epoch 6 Batch 2700 Loss 3.5856 Accuracy 0.3588\n","Epoch 6 Batch 2750 Loss 3.5862 Accuracy 0.3588\n","она еще не утонула .\n","it was not drowned yet .\n","tf.Tensor([[  2 183   9  57 112  39 131 216 947  16   3]], shape=(1, 11), dtype=int64)\n","tf.Tensor(b\"she ' s not a very different approach .\", shape=(), dtype=string)\n","\n","Epoch 6 Batch 2800 Loss 3.5856 Accuracy 0.3588\n","Epoch 6 Batch 2850 Loss 3.5851 Accuracy 0.3589\n","Epoch 6 Batch 2900 Loss 3.5845 Accuracy 0.3591\n","Epoch 6 Batch 2950 Loss 3.5842 Accuracy 0.3591\n","почему ?\n","why is that ?\n","tf.Tensor([[  2 213  31   3]], shape=(1, 4), dtype=int64)\n","tf.Tensor(b'why ?', shape=(), dtype=string)\n","\n","Epoch 6 Batch 3000 Loss 3.5841 Accuracy 0.3592\n","Epoch 6 Batch 3050 Loss 3.5842 Accuracy 0.3592\n","Epoch 6 Batch 3100 Loss 3.5842 Accuracy 0.3592\n","Epoch 6 Batch 3150 Loss 3.5839 Accuracy 0.3592\n","это рецепты которые дети учат на поварских уроках .\n","those are the recipes that the kids learn in my cooking classes .\n","tf.Tensor([[  2  94  93  39 400  87  39 504  87 617  16   3]], shape=(1, 12), dtype=int64)\n","tf.Tensor(b'this is a video of a group of students .', shape=(), dtype=string)\n","\n","Epoch 6 Batch 3200 Loss 3.5835 Accuracy 0.3592\n","Epoch 6 Batch 3250 Loss 3.5834 Accuracy 0.3592\n","Epoch 6 Batch 3300 Loss 3.5831 Accuracy 0.3593\n","Epoch 6 Batch 3350 Loss 3.5831 Accuracy 0.3594\n","на самом деле . . .\n","well , the thing is . . .\n","tf.Tensor([[  2  88   9  57 526  16   3]], shape=(1, 7), dtype=int64)\n","tf.Tensor(b\"that ' s true .\", shape=(), dtype=string)\n","\n","Epoch 6 Batch 3400 Loss 3.5827 Accuracy 0.3594\n","Epoch 6 Batch 3450 Loss 3.5828 Accuracy 0.3594\n","Epoch 6 Batch 3500 Loss 3.5826 Accuracy 0.3595\n","Epoch 6 Batch 3550 Loss 3.5826 Accuracy 0.3594\n","где и как мы можем провести черту ?\n","where and how can we draw the line ?\n","tf.Tensor([[  2 135 105  91 105  88  31   3]], shape=(1, 8), dtype=int64)\n","tf.Tensor(b'how do we do that ?', shape=(), dtype=string)\n","\n","Epoch 6 Batch 3600 Loss 3.5829 Accuracy 0.3594\n","Epoch 6 Batch 3650 Loss 3.5830 Accuracy 0.3594\n","Epoch 6 Batch 3700 Loss 3.5828 Accuracy 0.3594\n","Epoch 6 Batch 3750 Loss 3.5825 Accuracy 0.3595\n","( аплодисменты )\n","( applause )\n","tf.Tensor([[  2  10 211  11   3]], shape=(1, 5), dtype=int64)\n","tf.Tensor(b'( applause )', shape=(), dtype=string)\n","\n","Epoch 6 Batch 3800 Loss 3.5824 Accuracy 0.3595\n","Epoch 6 Batch 3850 Loss 3.5823 Accuracy 0.3595\n","Epoch 6 Batch 3900 Loss 3.5815 Accuracy 0.3597\n","Epoch 6 Batch 3950 Loss 3.5815 Accuracy 0.3597\n","если бы мы были за пределами ее , это было бы практически бессмысленно , вроде как до начала времени .\n","if we were outside this , it would almost be meaningless , in the sense as before time .\n","tf.Tensor(\n","[[  2 121  91 162 110 264  86 391  88  84 200 156  97  86 110 264  86 110\n","  264  86 110 264  86 110 264  86 110 264  86 110 264  86 110 264  86 110\n","  264  86 110 264  86]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b'if we could be able to imagine that the only time was to be able to be able to be able to be able to be able to be able to be able to be able to be able to', shape=(), dtype=string)\n","\n","Epoch 6 Batch 4000 Loss 3.5814 Accuracy 0.3597\n","Epoch 6 Batch 4050 Loss 3.5811 Accuracy 0.3597\n","Epoch 6 Batch 4100 Loss 3.5808 Accuracy 0.3598\n","Epoch 6 Batch 4150 Loss 3.5809 Accuracy 0.3598\n","размещалась в углублении загрязненного болота .\n","and it was set in a wider watery ooze .\n","tf.Tensor(\n","[[   2   90   97   39  192  290  119   39   57  236  901 6247  677   16\n","     3]], shape=(1, 15), dtype=int64)\n","tf.Tensor(b'it was a little bit like a synthesized .', shape=(), dtype=string)\n","\n","Epoch 6 Batch 4200 Loss 3.5802 Accuracy 0.3598\n","Epoch 6 Batch 4250 Loss 3.5803 Accuracy 0.3598\n","Epoch 6 Batch 4300 Loss 3.5805 Accuracy 0.3598\n","Epoch 6 Batch 4350 Loss 3.5802 Accuracy 0.3598\n","и у нас есть деньги , чтобы расширять круг .\n","but the money is there to reach others .\n","tf.Tensor([[  2  85  91   9 117 139  86 155 344  16   3]], shape=(1, 11), dtype=int64)\n","tf.Tensor(b\"and we ' re going to get money .\", shape=(), dtype=string)\n","\n","Epoch 6 Batch 4400 Loss 3.5798 Accuracy 0.3598\n","Epoch 6 Batch 4450 Loss 3.5794 Accuracy 0.3599\n","Epoch 6 Batch 4500 Loss 3.5795 Accuracy 0.3599\n","Epoch 6 Batch 4550 Loss 3.5794 Accuracy 0.3599\n","спасибо .\n","thank you .\n","tf.Tensor([[  2 238  92  16   3]], shape=(1, 5), dtype=int64)\n","tf.Tensor(b'thank you .', shape=(), dtype=string)\n","\n","Epoch 6 Batch 4600 Loss 3.5797 Accuracy 0.3599\n","Epoch 6 Batch 4650 Loss 3.5795 Accuracy 0.3599\n","Epoch 6 Batch 4700 Loss 3.5793 Accuracy 0.3600\n","Epoch 6 Batch 4750 Loss 3.5795 Accuracy 0.3600\n","` ` это все реальные проекты которые , мы надеемся , ученики смогут осуществить и сказать : ` ` это построил я и горжусь этим . ' ' ' '\n","` ` so these are real visible projects that hopefully the students can point to and say , ` ` i built that , and i ' m proud of it . ' ' ' '\n","tf.Tensor(\n","[[  2  95  94  93 103  47   9  51 139  86 105  14  85  47   9  51 139  86\n","  105  94  14  85  47   9  51 139  86 287  92 160  87 124 170  88  91   9\n","  117 229  16   3]], shape=(1, 40), dtype=int64)\n","tf.Tensor(b\"so this is what i ' m going to do , and i ' m going to do this , and i ' m going to show you some of these things that we ' re doing .\", shape=(), dtype=string)\n","\n","Epoch 6 Batch 4800 Loss 3.5795 Accuracy 0.3599\n","Epoch 6 Batch 4850 Loss 3.5792 Accuracy 0.3600\n","Epoch 6 Batch 4900 Loss 3.5791 Accuracy 0.3600\n","Epoch 6 Batch 4950 Loss 3.5792 Accuracy 0.3600\n","если бы единственное , что решали деньги , был доступ к яхтам , модным каникулам и машинам bmw , то неравенство не имело бы большого значения .\n","if the only thing that money determined was access to yachts or fancy vacations or bmws , then inequality would n ' t matter very much .\n","tf.Tensor(\n","[[   2  121   47   97   39 1926   14   47  144  101   39  215  128   39\n","   215  128   39  215  128   39 1290   14   85   47  144  101   39  258\n","   802   86   84  343   87   84  767   14   47  144  101   39  215]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b'if i was a leader , i would have a good or a good or a good or a bank , and i would have a better access to the power of the poor , i would have a good', shape=(), dtype=string)\n","\n","Epoch 6 Batch 5000 Loss 3.5792 Accuracy 0.3600\n","Epoch 6 Batch 5050 Loss 3.5793 Accuracy 0.3600\n","Epoch 6 Batch 5100 Loss 3.5790 Accuracy 0.3600\n","Epoch 6 Batch 5150 Loss 3.5791 Accuracy 0.3600\n","я не был удивлен , когда в возрасте 77 лет он выпустил диск и намеренно присвоил ему совсем уж непривлекательное название « старые идеи » . [ англ . — “ old ideas ” ] альбом возглавил чарты в 17 странах , попал в первую пятерку еще в девяти .\n","` ` and i was n ' t entirely surprised when the record that he released at the age of 77 , to which he gave the deliberately unsexy title of ` ` ' ' old ideas , ' ' ' ' went to number one in the charts in 17 nations in the world , hit the top five in nine others . ' '\n","tf.Tensor(\n","[[   2   38   38   85   47    9  153  173   89   84 3204 1455 1455 1455\n","    14   85  127  190   14   38   38    9    9   47    9   51  112   39\n","   888   14  102  127    9   57   39  349  147    9   57   39  349]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"` ` and i ' ve been in the 19777 , and he said , ` ` ' ' i ' m not a kid , but he ' s a man who ' s a man\", shape=(), dtype=string)\n","\n","Epoch 6 Batch 5200 Loss 3.5787 Accuracy 0.3600\n","Epoch 6 Batch 5250 Loss 3.5783 Accuracy 0.3601\n","Epoch 6 Batch 5300 Loss 3.5781 Accuracy 0.3601\n","Epoch 6 Batch 5350 Loss 3.5780 Accuracy 0.3601\n","когда мы думаем , что экономическии рост может остановиться , мы думаем , что это невозможно , потому что экономическое развитие настолько неотъемлемая часть нашего общества , что оно редко подвергается сомнению .\n","` ` when we think about economic growth stopping , we go , ` ` ' ' that ' s not possible , ' ' ' ' because economic growth is so essential to our society that is is rarely questioned . ' '\n","tf.Tensor(\n","[[  2 130  91 138  88 121  91 143  88  84 736  93 112 130  91 107 243  84\n","  166  91 107 243  84 166  91 107 243  84 166  91 107 243  84 166  91 107\n","  243  84 157  16   3]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b'because we know that if we think that the economy is not because we can change the way we can change the way we can change the way we can change the way we can change the world .', shape=(), dtype=string)\n","\n","Epoch 6 Batch 5400 Loss 3.5775 Accuracy 0.3601\n","Epoch 6 Batch 5450 Loss 3.5773 Accuracy 0.3602\n","Epoch 6 Batch 5500 Loss 3.5769 Accuracy 0.3602\n","Epoch 6 Batch 5550 Loss 3.5769 Accuracy 0.3602\n","на протяжении дня , на протяжении всеи вашеи жизни , как только вы увидите человека , чья работа – убирать за вами , обратите на него внимание .\n","so in the flow of your days , in the flow of your lives , next time you see someone whose job is to clean up after you , take a moment to acknowledge them .\n","tf.Tensor(\n","[[  2  89  84 274 282 429  14  92   9 117 139  86 110 264  86 155  39 192\n","  290  87  39 471  14  85  92   9 117 139  86 110 264  86 155  39 192 290\n","   87  39 192 290  87]], shape=(1, 41), dtype=int64)\n","tf.Tensor(b\"in the next few days , you ' re going to be able to get a little bit of a child , and you ' re going to be able to get a little bit of a little bit of\", shape=(), dtype=string)\n","\n","Epoch 6 Batch 5600 Loss 3.5770 Accuracy 0.3602\n","Epoch 6 Batch 5650 Loss 3.5771 Accuracy 0.3601\n","Epoch 6 Batch 5700 Loss 3.5773 Accuracy 0.3601\n"],"name":"stdout"},{"output_type":"stream","text":["Exception ignored in: <function IteratorResourceDeleter.__del__ at 0x7fa04eec7830>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 546, in __del__\n","    handle=self._handle, deleter=self._deleter)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1264, in delete_iterator\n","    _ctx, \"DeleteIterator\", name, handle, deleter)\n","KeyboardInterrupt: \n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-74-76672713419d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# inp -> russian, tar -> english\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-73-846c545bcb47>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(inp, tar, batch)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# print(gradients[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    666\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moptimizer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         return self._distributed_apply(strategy, grads_and_vars, name,\n\u001b[0;32m--> 668\u001b[0;31m                                        apply_state)\n\u001b[0m\u001b[1;32m    669\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         return distribute_ctx.get_replica_context().merge_call(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, name, apply_state)\u001b[0m\n\u001b[1;32m    713\u001b[0m               var.op.name):\n\u001b[1;32m    714\u001b[0m             update_op = distribution.extended.update(\n\u001b[0;32m--> 715\u001b[0;31m                 var, apply_grad_to_update_var, args=(grad,), group=False)\n\u001b[0m\u001b[1;32m    716\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdistribute_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_cross_replica_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m               \u001b[0;31m# In cross-replica context, extended.update returns a list of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2574\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   2575\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2576\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2577\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2578\u001b[0m       return self._replica_ctx_update(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3620\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3622\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3624\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   3630\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3631\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3632\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3634\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mread_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_local_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m    867\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       expand_composites=expand_composites)\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mpack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites)\u001b[0m\n\u001b[1;32m    753\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msortable\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m   \"\"\"\n\u001b[0;32m--> 755\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_pack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    606\u001b[0m   \u001b[0;34m\"\"\"Implements sequence packing, with the option to alter the structure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m   \u001b[0mis_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_sequence_or_composite\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexpand_composites\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mis_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m   \u001b[0msequence_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_fn\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sequence_like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0mvalue_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"hUeNf3n8ulho"},"source":["# Evaluate"]},{"cell_type":"code","metadata":{"id":"oHRn3rVkulfP"},"source":["def evaluate(sentence, max_length=40):\n","    # inp sentence is russian, hence adding the start and end token\n","    sentence = tf.convert_to_tensor([sentence])\n","    sentence = tokenizers.ru.tokenize(sentence).to_tensor()\n","\n","    encoder_input = sentence\n","\n","    # as the target is english, the first word to the transformer should be the\n","    # english start token.\n","    start, end = tokenizers.en.tokenize([''])[0]\n","    output = tf.convert_to_tensor([start])\n","    output = tf.expand_dims(output, 0)\n","\n","    for i in range(max_length):\n","        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n","            encoder_input, output)\n","\n","        # predictions.shape == (batch_size, seq_len, vocab_size)\n","        predictions, attention_weights = transformer(encoder_input,\n","                                                    output,\n","                                                    False,\n","                                                    enc_padding_mask,\n","                                                    combined_mask,\n","                                                    dec_padding_mask)\n","\n","        # select the last word from the seq_len dimension\n","        predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n","\n","        predicted_id = tf.argmax(predictions, axis=-1)\n","\n","        # concatentate the predicted_id to the output which is given to the decoder\n","        # as its input.\n","        output = tf.concat([output, predicted_id], axis=-1)\n","\n","        # return the result if the predicted_id is equal to the end token\n","        if predicted_id == end:\n","            break\n","\n","    # output.shape (1, tokens)\n","    print(output)\n","    text = tokenizers.en.detokenize(output)[0]  # shape: ()\n","\n","    tokens = tokenizers.en.lookup(output)[0]\n","\n","    return text, tokens, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0xEZZEJMjbKe"},"source":["tokenizers.en.tokenize([''])[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IsAi9L_zulcx"},"source":["def print_translation(sentence, tokens, ground_truth):\n","    print(f'{\"Input:\":15s}: {sentence}')\n","    print(f'{\"Prediction\":15s}: {tokens.numpy().decode(\"utf-8\")}')\n","    print(f'{\"Ground truth\":15s}: {ground_truth}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bGk87osbulad"},"source":["sentence = \"Автомобиль, припаркованный на углу, черный\"\n","ground_truth = \"The car parked at the corner is black.\"\n","\n","translated_text, translated_tokens, attention_weights = evaluate(sentence)\n","print_translation(sentence, translated_text, ground_truth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NfUvay6RiOrU"},"source":["for (batch, (inp, tar)) in enumerate(train_batches):\n","    print(inp)\n","    print(tar)\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QMJEZGkqiopS"},"source":["round_trip = reloaded_tokenizers.ru.detokenize(inp)\n","print(round_trip.numpy()[0].decode('utf-8'))\n","\n","round_trip = reloaded_tokenizers.en.detokenize(tar)\n","print(round_trip.numpy()[0].decode('utf-8'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b1slya5pulYA"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SNakVtsUulVk"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WVacU1AEulSs"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FnVmaaYokT7K"},"source":[""],"execution_count":null,"outputs":[]}]}