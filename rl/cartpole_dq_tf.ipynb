{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04873255, 0.00151558, 0.00790912, 0.03975826])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 possible actions.\n"
     ]
    }
   ],
   "source": [
    "action_space = env.action_space.n\n",
    "print(f\"There are {action_space} possible actions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory():\n",
    "    def __init__(self, max_size):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "\n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        buffer_size = len(self.buffer)\n",
    "        index = np.random.choice(np.arange(buffer_size),\n",
    "                                 size=batch_size,\n",
    "                                 replace=False)\n",
    "        return [self.buffer[i] for i in index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 6, 9, 7]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem = Memory(10)\n",
    "[mem.add(i) for i in np.arange(10)]\n",
    "mem.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMORY_SIZE = 600\n",
    "pretrain_length = 10\n",
    "memory = Memory(max_size=MEMORY_SIZE)\n",
    "\n",
    "state = env.reset() #env.decode(env.reset()))\n",
    "\n",
    "done = False\n",
    "step_limit = 600\n",
    "step = 0\n",
    "while step < step_limit:\n",
    "    \n",
    "    random_action = env.action_space.sample()\n",
    "    new_state, reward, done, info = env.step(random_action)\n",
    "    \n",
    "    \n",
    "    memory.add((state, random_action, new_state, reward, done, info))\n",
    "    \n",
    "    if done:\n",
    "        state = env.reset() \n",
    "        \n",
    "    else:\n",
    "        state = new_state\n",
    "        \n",
    "    step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 0.16259643,  0.44354756, -0.20166342, -0.99535918]),\n",
       "  0,\n",
       "  array([ 0.17146738,  0.25160983, -0.2215706 , -0.77217508]),\n",
       "  1.0,\n",
       "  True,\n",
       "  {}),\n",
       " (array([ 0.22522695,  1.34652498,  0.0434256 , -0.75930645]),\n",
       "  1,\n",
       "  array([ 0.25215745,  1.54102252,  0.02823947, -1.03801462]),\n",
       "  1.0,\n",
       "  False,\n",
       "  {}),\n",
       " (array([-0.0213989 ,  0.22315138,  0.02583269, -0.04648624]),\n",
       "  0,\n",
       "  array([-0.01693587,  0.02766871,  0.02490296,  0.25423389]),\n",
       "  1.0,\n",
       "  False,\n",
       "  {})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.sample(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[-0.08752951,  0.36651555],\n",
       "       [-0.04168215,  0.14394209],\n",
       "       [-0.02554925,  0.16529503]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the Q value of each action given the state\n",
    "inputs = layers.Input(shape=(4,))\n",
    "x = layers.Dense(50, activation=\"relu\")(inputs)\n",
    "x = layers.Dense(50, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(2, activation=\"linear\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model_target = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model.output_shape\n",
    "model(tf.random.uniform((3,4),-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(episode, model, state, min_epsilon, max_epsilon, decay_rate):\n",
    "\n",
    "    # random number for explore/exploit trade-off\n",
    "    epsilon = np.random.rand()\n",
    "\n",
    "    # current ee prob\n",
    "    explore_prob = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay_rate*episode)\n",
    "\n",
    "    if epsilon < explore_prob:\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        q_vals = model(tf.expand_dims(state, axis=0))\n",
    "        action = np.argmax(q_vals)\n",
    "\n",
    "    return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "[select_action(1, model, tf.random.normal((4,)), 0.0, 0.0, 0.01) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1.3121494, 1.060068 , 1.       ], dtype=float32)>,\n",
       " array([[ 0.0277234 ,  0.35306355, -0.01217392, -0.59877353],\n",
       "        [-0.03926528,  0.04129011,  0.03298711, -0.01916819],\n",
       "        [ 0.11184638,  0.18972477, -0.19914572, -0.66553929]]),\n",
       " [1, 0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_minibatch(model, memory, gamma, batch_size):\n",
    "\n",
    "    # memory structure: (state, action, new_state, reward, done, info)\n",
    "\n",
    "    batch = memory.sample(batch_size)\n",
    "    states = np.array([each[0] for each in batch])\n",
    "    actions =[each[1] for each in batch]\n",
    "    next_states = np.array([each[2] for each in batch])\n",
    "    rewards = [each[3] for each in batch]\n",
    "    dones = tf.constant([each[4] for each in batch], dtype=tf.float32)\n",
    "\n",
    "    # get q values from target model\n",
    "    q_target = model(next_states)\n",
    "    \n",
    "    q_target = tf.reduce_max(q_target, axis=1)\n",
    "    # set done q_target = reward and discount the others\n",
    "    q_target = rewards + gamma * (1. - dones) * q_target\n",
    "\n",
    "    return q_target, states, actions\n",
    "\n",
    "get_minibatch(model, memory, 0.99, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_episodes = 1000       # Total number of training episodes\n",
    "max_steps = 200               # Max steps per episode\n",
    "batch_size = 64\n",
    "\n",
    "learning_rate = 0.01          # Learning rate\n",
    "gamma = 0.9                  # Discounting rate\n",
    "\n",
    "# Exploration parameters\n",
    "epsilon = 1.0               # Exploration rate\n",
    "max_epsilon = 1             # Exploration probability at start\n",
    "min_epsilon = .1            # Minimum exploration probability \n",
    "decay_rate = 0.003          # Exponential decay rate for exploration prob\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjuUlEQVR4nO3deXhV1b3/8fc3JyHzBAkhkDATICAIRAYnggOCVWkdUKyzFLVy61Tv1XpbrbX9abXO2oLVWkecUBERelEiagEBZR7DPBoIEEgYQ9bvj3O0EUFCOMnOOefzep48OXvvdTjflZ3nw87aa+9tzjlERCT0RXldgIiIBIcCXUQkTCjQRUTChAJdRCRMKNBFRMJEtFcfnJGR4Vq3bl2r91ZUVJCYmBjcgho49TkyqM+R4Xj6PHv27K3OuczDbfMs0Fu3bs2sWbNq9d6ioiIKCwuDW1ADpz5HBvU5MhxPn81szZG2achFRCRMKNBFRMKEAl1EJEwo0EVEwoQCXUQkTBw10M3sBTMrMbMFR9huZvakmRWb2Twz6xn8MkVE5GhqcoT+IjDoR7YPBjoEvkYAfz3+skRE5FgdNdCdc1OBbT/SZAjwkvObDqSZWXawCjzUgg1lvLV0P7rtr4jI9wXjwqIWwLpqy+sD6zYd2tDMRuA/iicrK4uioqJj/rDJaw7w4aoDdBn7CflNfLUqOBSVl5fX6ucVytTnyKA+B0+9XinqnBsNjAYoKChwtblSqu+Bg4x/YBJTtsRz04X9MLMgV9kw6Wq6yKA+R4a66nMwZrlsAHKrLecE1tWJuBgf57WNYebq7fx7RWldfYyISMgJRqCPA64KzHbpC5Q5534w3BJMp+dE0ywljscnL9NYuohIQE2mLb4OTAM6mtl6M7vezG40sxsDTSYAK4Fi4Dngl3VWbUAjn/HLAe10lC4iUs1Rx9Cdc8OOst0BNwetohoaWpDLs1NW8PjkZZzcrknEjKWLiBxJyF4pGhfj01G6iEg1IRvoAJeelEuzlDge+z+NpYuIhHSgx0b7uHlAO2at2c4XxTpKF5HIFtKBDjA0cJSuGS8iEulCPtCrH6VPXb7V63JERDwT8oEO/qP0FmnxPDJpqY7SRSRihUWgx0b7uO3sPOZvKOOjBZu9LkdExBNhEegAP+vRgg5Nk3jkX0upPFjldTkiIvUubALdF2XcMbAjK7dUMParOruVjIhIgxU2gQ5wTpcsuuek8vjkZew9cNDrckRE6lVYBbqZcec5ndhYtpfXZqz1uhwRkXoVVoEOcGqHDE5u14RnphRTvq/S63JEROpN2AU6wJ3ndKS0Yj8vfL7K61JEROpNWAZ6j5bpDMzP4rmpK9lesd/rckRE6kVYBjrAr8/pSMX+Sp76pNjrUkRE6kXYBnpeVjKX9Mrl5emrWVNa4XU5IiJ1LmwDHeD2gXlER0Xx54lLvS5FRKTOhXWgZ6XEMeL0tnw4fxOz12z3uhwRkToV1oEOMOL0tmQmx/KnCYt14y4RCWthH+iJsdHccXYes9dsZ6Ju3CUiYSzsAx3gkoJcOmYl8+DEJeyv1I27RCQ8RUSg+6KMu8/txJrS3bwyfY3X5YiI1ImICHSA/nmZnNYhgyc/WU7Z7gNelyMiEnQRE+hmxt2DO1O25wBPfbLc63JERIIuYgIdIL95CkN75fLiv1dTXFLudTkiIkEVUYEOcOegjsTH+PjD+EWaxigiYSXiAj0jKZZbzurAp8u28MmSEq/LEREJmogLdICrT25Nu8xE/jB+Efsq9WQjEQkPERnoMb4o7j2/C6tLd/PC56u9LkdEJCgiMtABTs/L5KzOWTz9yXJKdu71uhwRkeMWsYEO8NvzOnPgoOPBiUu8LkVE5LhFdKC3apLI8NPaMParDXy1VndjFJHQFtGBDnDzgPZkpcRy7/sLOVilaYwiEroiPtATY6O55yf5zN9QxqszdJ8XEQldER/oAOd3y+bU9hk8PHEpJbt0glREQpMCHf99Xu4f0oV9lVX88cPFXpcjIlIrCvSAtplJ3FjYjvfnbOSL4q1elyMicsxqFOhmNsjMlppZsZnddZjtLc1sipl9bWbzzOzc4Jda935Z2I5WTRL47XsLdAWpiIScowa6mfmAZ4DBQD4wzMzyD2n2v8CbzrkewGXAs8EutD7Exfi4f0hXVm6tYNSnK70uR0TkmNTkCL03UOycW+mc2w+MAYYc0sYBKYHXqcDG4JVYv/rnZfKTbtk8PaWYNaUVXpcjIlJjdrRbyJrZxcAg59zwwPKVQB/n3MhqbbKBfwHpQCJwlnNu9mH+rRHACICsrKxeY8aMqVXR5eXlJCUl1eq9NbF9bxV3f7aH9uk+7ugVi5nV2WfVVF33uSFSnyOD+nxsBgwYMNs5V3C4bdHHVdV/DANedM79xcz6AS+bWVfn3PeeyOycGw2MBigoKHCFhYW1+rCioiJq+96a2pG8it9/sIiytDx+2qNFnX5WTdRHnxsa9TkyqM/BU5Mhlw1AbrXlnMC66q4H3gRwzk0D4oCMYBTolav6taZHyzR+/8FCSsv3eV2OiMhR1STQZwIdzKyNmTXCf9Jz3CFt1gJnAphZZ/yBviWYhdY3X5Tx0EXdKN9Xye8/WOR1OSIiR3XUQHfOVQIjgUnAYvyzWRaa2f1mdkGg2R3AL8xsLvA6cI0Lg+e75WUlM3JAB8bN3cjHi7/xuhwRkR9VozF059wEYMIh635X7fUi4JTgltYw3FTYjgnzN3HPuwvo3aYxyXExXpckInJYulL0KBpFR/HQxd0o2bWXBz/SfdNFpOFSoNfAiblpXHtKG16dsZYZK0u9LkdE5LAU6DV0x8A8chvHc9fY+ew9oNsCiEjDo0CvoYRG0Tx4YTdWba3g4UlLvS5HROQHFOjH4JT2GVzZtxUvfLGK6Rp6EZEGRoF+jO4a3ImWjRO48+25lO+r9LocEZHvKNCPUWJsNI9c0p312/fwpwl6GIaINBwK9Fo4qXVjfnFaW16bsZZPl4X0BbEiEkYU6LV0+9l5tG+axP+8PY+y3Qe8LkdERIFeW3ExPh4d2p0t5fv4/QcLvS5HRESBfjy65aRx84D2jP16Ax/N3+R1OSIS4RTox+m/zmhPt5xU7ho7n01le7wuR0QimAL9OMX4onjish4cOFjF7W/M5WBVyN9kUkRClAI9CNpkJHLf+V2YtrKUUVNXeF2OiEQoBXqQXFKQw09OyObRfy1j7rodXpcjIhFIgR4kZsaffnYCTZNjufWNOVToKlIRqWcK9CBKTYjh0UtPZHVphaYyiki9U6AHWd+2TfhlYTvenLWe8fM2el2OiEQQBXoduPWsPHq0TOOud+azemuF1+WISIRQoNeBGF8UT1/ek2if8ctXv9IDMUSkXijQ60iLtHgeHdqdRZt28ofxi7wuR0QigAK9Dp3RKYsb+rfl1RlreX/OBq/LEZEwp0CvY78e2JGCVun8Zux8Vmwp97ocEQljCvQ6FuOL4qnLexAb4+NmjaeLSB1SoNeD7FT/ePqSzbu4933NTxeRuqFAryeFHZsyckB73pi1jte/XOt1OSIShhTo9ei2s/M4PS+Te99fyFdrt3tdjoiEGQV6PfJFGU9ediJZqbHc9MpsSnbt9bokEQkjCvR6lpbQiNFXFrBzTyU3v/oV+yurvC5JRMKEAt0DnbNTeOjibsxcvZ0/fqiLjkQkOKK9LiBSXdC9OfPX7+C5z1bRtUUqlxTkel2SiIQ4HaF76H8GdeLkdk24570FeiiGiBw3BbqHogM38cpMiuUXL81ic5lOkopI7SnQPdY4sRHPX1NAxb5Khr80k9379aQjEakdBXoD0KlZCk9d3oNFG3dy+xtzqapyXpckIiFIgd5AnNEpi9+c25mJCzfzl/9b6nU5IhKCNMulAbn+1Das2FLOM1NW0C4ziQt75nhdkoiEEB2hNyBmxv1DutKvbRPuemc+s1Zv87okEQkhNQp0MxtkZkvNrNjM7jpCm6FmtsjMFprZa8EtM3LE+KL46xU9aZEez4iXZ+uZpCJSY0cNdDPzAc8Ag4F8YJiZ5R/SpgNwN3CKc64LcGvwS40caQmNeOGak3DOcfU/vmRr+T6vSxKREFCTI/TeQLFzbqVzbj8wBhhySJtfAM8457YDOOdKgltm5GmTkcjz15zENzv3cv2LM9lXqZkvIvLjanJStAWwrtryeqDPIW3yAMzsC8AH3Oecm3joP2RmI4ARAFlZWRQVFdWiZCgvL6/1e0PNDSfE8ORXZTxZ4YiOmoIvyrwuqd5E0n7+lvocGeqqz8Ga5RINdAAKgRxgqpmd4JzbUb2Rc240MBqgoKDAFRYW1urDioqKqO17Q00hkNlyDf/73gIm72jCn352AmaREeqRtJ+/pT5Hhrrqc02GXDYA1e8clRNYV916YJxz7oBzbhWwDH/ASxBc0bcV57WN4fUv1/Hkx8VelyMiDVRNAn0m0MHM2phZI+AyYNwhbd7DfzCJmWXgH4JZGbwy5aIOMVzYswWPTV6mR9iJyGEddcjFOVdpZiOBSfjHx19wzi00s/uBWc65cYFtA81sEXAQuNM5V1qXhUcaM+Ohi7pRWr6f37w7n+S4aM7r1tzrskSkAanRGLpzbgIw4ZB1v6v22gG3B76kjsT4ovjbFb246oUZ3PbGHJJioyns2NTrskSkgdCVoiEmvpGP5685ibysZG58ZTYzdTWpiAQo0ENQSlwM/7yuN83T4rnuHzNZsKHM65JEpAFQoIeojKRYXrm+DynxMVz9wpes2FLudUki4jEFeghrnhbPy9f3xgyu+PsM1pbu9rokEfGQAj3Etc1M4uXr+7DnwEGGPTedddsU6iKRSoEeBjpnp/Dq8D6U76vkstHTWb9doS4SiRToYaJL81ReHd6HXXsPcNno6WzYscfrkkSkninQw0jXFqm8MrwPZXsOMGz0dDYq1EUiigI9zHTLSeOV6/uwvWI/w56bzuayvV6XJCL1RIEehrrnpvHS9b0pLd/P0FHTdKJUJEIo0MNUj5bpvHx9b3bs3s+lo6axUvPURcKeAj2M9WiZzpgR/dhXWcXQUdNZunmX1yWJSB1SoIe5/OYpvHFDX3xRcOnoacxfr9sEiIQrBXoEaN80mbduOJmk2Gguf246s3RDL5GwpECPEC2bJPDmDf3ITI7lyue/5LPlW7wuSUSCTIEeQZqnxfPGDf1o1SSB616cyftzDn2SoIiEMgV6hMlMjuWNG/rRs2U6t4yZw98/05MCRcKFAj0Cpcb776c+uGszHvhwMX+asJiqKud1WSJynBToESouxsfTl/fkyr6tGD11JXe8NZcDB6u8LktEjkONnikq4ckXZdw/pAtZKbE88q9llFbs59mf9yQpVr8WIqFIR+gRzswYeUYHHrroBL4o3solf5vGpjLd1EskFCnQBYBLT2rJ81cXsG7bboY8/YUuQBIJQQp0+U5hx6a8c9PJxPiiGDpqGpMWbva6JBE5Bgp0+Z6OzZJ59+aTyWuWzI2vzOa5qStxTjNgREKBAl1+oGlyHG+M6Mu5XbP544TF/Obd+eyv1AwYkYZO0xnksOJifDw1rAetMxJ4ZsoKikvKefbnvchMjvW6NBE5Ah2hyxFFRRl3ntOJJ4f1YP6GMs5/6nPmrtvhdVkicgQKdDmqC7o3552bTsYXZVwyahpvz17vdUkichgKdKmRLs1T+eC/TqWgVTq/fmsu941bqCtLRRoYBbrUWOPERrx0XW+uP7UNL/57NVc+P4Mtu/Z5XZaIBCjQ5ZhE+6L47Xn5PDq0O3PW7eDcJz9j+spSr8sSERToUksX9szhvZtPITnO/xSkZ6YU646NIh5ToEutdWqWwriRp/KTbs15eNJSrn1xJtsq9ntdlkjEUqDLcUmKjebJy07kgZ92ZdqKUn7y5GfMXqNnlop4QYEux83MuKJvK8b+0n8fmEtH+YdgDmoIRqReKdAlaLq2SGX8r05lUNdmPDxpKZc/N52NO3QrXpH6okCXoEqJi+GpYT145JLuLNhQxqDHpzJ+3kavyxKJCDUKdDMbZGZLzazYzO76kXYXmZkzs4LglSihxsy4uFcOE245jbaZSYx87Wt+/dZcyvdVel2aSFg7aqCbmQ94BhgM5APDzCz/MO2SgVuAGcEuUkJTqyaJvHVjP351RnvGfrWec5/QCVORulSTI/TeQLFzbqVzbj8wBhhymHZ/AB4C9gaxPglxMb4obh/YkTdu6EeVc1z8t2n88cNF7D1w0OvSRMKOHe3hBWZ2MTDIOTc8sHwl0Mc5N7Jam57APc65i8ysCPi1c27WYf6tEcAIgKysrF5jxoypVdHl5eUkJSXV6r2hKhz6vKfS8ebS/UxZV0mzRGP4CbG0T/MdsX049PlYqc+R4Xj6PGDAgNnOucMOax/3/dDNLAp4FLjmaG2dc6OB0QAFBQWusLCwVp9ZVFREbd8bqsKlz4PPgs+Xb+V/3pnHn2bs4Rent+W2s/KIi/lhsIdLn4+F+hwZ6qrPNRly2QDkVlvOCaz7VjLQFSgys9VAX2CcTozKkZzaIYOJt57GpSe1ZNSnKznvqc/5eu12r8sSCXk1CfSZQAcza2NmjYDLgHHfbnTOlTnnMpxzrZ1zrYHpwAWHG3IR+VZyXAz/78ITeOm63uzeV8mFf/03976/gF17D3hdmkjIOmqgO+cqgZHAJGAx8KZzbqGZ3W9mF9R1gRLeTs/LZNJtp3NV31a8NH0NZz86lUkLN3tdlkhIqtEYunNuAjDhkHW/O0LbwuMvSyJJclwMvx/SlZ/2aMHdY+dzw8uzGZifxaCmeoCGyLHQlaLSYPRomc4H/3Uqdw3uxNTlW/jNZ3t48YtVVOrJSCI1okCXBiXGF8WN/dvxr1v70z7Nx30fLOL8p7/gy1W6IEnkaBTo0iC1bJLAHQWxPPvznpTt3s/QUdO4ZczXbC7TdWsiR6JAlwbLzDj3hGw+vqOQX53Rno8WbOaMvxTx16IV7KvUlaYih1KgS4MX38jH7QM7Mvm2/pzSPoOHJi5h0OOfMWVJCUe70lkkkijQJWS0bJLAc1cV8OK1J2HAtS/O5IrnZ7BwY5nXpYk0CAp0CTmFHZsy8dbTuff8fBZt3Ml5T33O7W/O0cM0JOIp0CUkNYqO4tpT2lB05wBGnN6W8fM2MeCRIv48cYmuNpWIpUCXkJYaH8PdgzvzyR39Gdy1Gc8WraD/w0W88Pkq3aJXIo4CXcJCTnoCj1/Wg3EjT6FjVjL3j1/EgEeKeG3GWg7owiSJEAp0CSvdctJ4fURfXhveh2apcfzm3fmc+ZdPeWf2eg5WaUaMhDcFuoSlk9tnMPamk/nHNSeRHBfNHW/NZeBjnzJ+3kaqFOwSphToErbMjAGdmvLByFP52xU9iTJj5GtfM+iJqbw/Z4PuESNhR4EuYS8qyhjUNZuJt57OE5edCMAtY+Zw5qOfMubLteyvVLBLeFCgS8TwRRlDTmzBxFtO529X9CIlLoa7xs6n8OEpvPiFZsVI6FOgS8TxH7E3Y9zIU/jndb3JSU/gvg8WcepDn/BsUTFluzWPXULTcT8kWiRUmRn98zLpn5fJl6u28fSUYv48cSlPf1LM0IJcrj2lNa2aJHpdpkiNKdBFgN5tGvNSm94s3rSTv3+2ildnrOGf01ZzTn4zhp/Whl6t0jEzr8sU+VEKdJFqOmen8Jeh3fnvQR15adpqXpm+lokLN3